{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Estimation of Obesity Levels Based On Eating Habits and Physical Condition**"
      ],
      "metadata": {
        "id": "haLwHWTmRpAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 10 Machine Learning\n",
        "\n",
        "Raihana Fawaz (1103210102)"
      ],
      "metadata": {
        "id": "eVUqca5TRuls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ls5Vpui7Ry79"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "iK5QhrmwRiLJ",
        "outputId": "b66a26d9-89c5-4ef9-93d2-7e639255b485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
              "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
              "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
              "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
              "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
              "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
              "\n",
              "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
              "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
              "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
              "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
              "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
              "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
              "\n",
              "                  MTRANS           NObeyesdad  \n",
              "0  Public_Transportation        Normal_Weight  \n",
              "1  Public_Transportation        Normal_Weight  \n",
              "2  Public_Transportation        Normal_Weight  \n",
              "3                Walking   Overweight_Level_I  \n",
              "4  Public_Transportation  Overweight_Level_II  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b056475-a555-4935-a23a-f7912481f23a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>64.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>56.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>77.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>87.0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Walking</td>\n",
              "      <td>Overweight_Level_I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.78</td>\n",
              "      <td>89.8</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Overweight_Level_II</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b056475-a555-4935-a23a-f7912481f23a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b056475-a555-4935-a23a-f7912481f23a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b056475-a555-4935-a23a-f7912481f23a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a429a89b-e546-46ea-b685-b011e0d74718\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a429a89b-e546-46ea-b685-b011e0d74718')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a429a89b-e546-46ea-b685-b011e0d74718 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2111,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.3459682737322405,\n        \"min\": 14.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 1402,\n        \"samples\": [\n          25.526746,\n          26.740655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09330481986792,\n        \"min\": 1.45,\n        \"max\": 1.98,\n        \"num_unique_values\": 1574,\n        \"samples\": [\n          1.760175,\n          1.688436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.191171745204688,\n        \"min\": 39.0,\n        \"max\": 173.0,\n        \"num_unique_values\": 1525,\n        \"samples\": [\n          120.702935,\n          64.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_history_with_overweight\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAVC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FCVC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5339265785033023,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 810,\n        \"samples\": [\n          2.987148,\n          2.939727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7780386488418594,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 635,\n        \"samples\": [\n          1.468948,\n          2.9948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CAEC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Frequently\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMOKE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CH2O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6129534517968702,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1268,\n        \"samples\": [\n          2.395387,\n          1.983973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8505924308367011,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1190,\n        \"samples\": [\n          1.655488,\n          2.433918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TUE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6089272596763761,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1129,\n        \"samples\": [\n          1.416353,\n          0.878258\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CALC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Sometimes\",\n          \"Always\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MTRANS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Walking\",\n          \"Bike\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NObeyesdad\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Normal_Weight\",\n          \"Overweight_Level_I\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Memuat dataset\n",
        "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT2Zf4uLSKSu",
        "outputId": "9c49edf7-5b79-4b8e-ff2e-22b9dfe94708"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2111 entries, 0 to 2110\n",
            "Data columns (total 17 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Gender                          2111 non-null   object \n",
            " 1   Age                             2111 non-null   float64\n",
            " 2   Height                          2111 non-null   float64\n",
            " 3   Weight                          2111 non-null   float64\n",
            " 4   family_history_with_overweight  2111 non-null   object \n",
            " 5   FAVC                            2111 non-null   object \n",
            " 6   FCVC                            2111 non-null   float64\n",
            " 7   NCP                             2111 non-null   float64\n",
            " 8   CAEC                            2111 non-null   object \n",
            " 9   SMOKE                           2111 non-null   object \n",
            " 10  CH2O                            2111 non-null   float64\n",
            " 11  SCC                             2111 non-null   object \n",
            " 12  FAF                             2111 non-null   float64\n",
            " 13  TUE                             2111 non-null   float64\n",
            " 14  CALC                            2111 non-null   object \n",
            " 15  MTRANS                          2111 non-null   object \n",
            " 16  NObeyesdad                      2111 non-null   object \n",
            "dtypes: float64(8), object(9)\n",
            "memory usage: 280.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "pweAscXFSPnb",
        "outputId": "e418e96e-fafa-44c1-eac8-0965593e815a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Age       Height       Weight         FCVC          NCP  \\\n",
              "count  2111.000000  2111.000000  2111.000000  2111.000000  2111.000000   \n",
              "mean     24.312600     1.701677    86.586058     2.419043     2.685628   \n",
              "std       6.345968     0.093305    26.191172     0.533927     0.778039   \n",
              "min      14.000000     1.450000    39.000000     1.000000     1.000000   \n",
              "25%      19.947192     1.630000    65.473343     2.000000     2.658738   \n",
              "50%      22.777890     1.700499    83.000000     2.385502     3.000000   \n",
              "75%      26.000000     1.768464   107.430682     3.000000     3.000000   \n",
              "max      61.000000     1.980000   173.000000     3.000000     4.000000   \n",
              "\n",
              "              CH2O          FAF          TUE  \n",
              "count  2111.000000  2111.000000  2111.000000  \n",
              "mean      2.008011     1.010298     0.657866  \n",
              "std       0.612953     0.850592     0.608927  \n",
              "min       1.000000     0.000000     0.000000  \n",
              "25%       1.584812     0.124505     0.000000  \n",
              "50%       2.000000     1.000000     0.625350  \n",
              "75%       2.477420     1.666678     1.000000  \n",
              "max       3.000000     3.000000     2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35fc01b7-7465-49b2-8b2a-3cc22648d866\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24.312600</td>\n",
              "      <td>1.701677</td>\n",
              "      <td>86.586058</td>\n",
              "      <td>2.419043</td>\n",
              "      <td>2.685628</td>\n",
              "      <td>2.008011</td>\n",
              "      <td>1.010298</td>\n",
              "      <td>0.657866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.345968</td>\n",
              "      <td>0.093305</td>\n",
              "      <td>26.191172</td>\n",
              "      <td>0.533927</td>\n",
              "      <td>0.778039</td>\n",
              "      <td>0.612953</td>\n",
              "      <td>0.850592</td>\n",
              "      <td>0.608927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>19.947192</td>\n",
              "      <td>1.630000</td>\n",
              "      <td>65.473343</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.658738</td>\n",
              "      <td>1.584812</td>\n",
              "      <td>0.124505</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.777890</td>\n",
              "      <td>1.700499</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>2.385502</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.768464</td>\n",
              "      <td>107.430682</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.477420</td>\n",
              "      <td>1.666678</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.980000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35fc01b7-7465-49b2-8b2a-3cc22648d866')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35fc01b7-7465-49b2-8b2a-3cc22648d866 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35fc01b7-7465-49b2-8b2a-3cc22648d866');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f21bebc-c39f-41e4-919d-64c4ae630093\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f21bebc-c39f-41e4-919d-64c4ae630093')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f21bebc-c39f-41e4-919d-64c4ae630093 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 737.7175023586611,\n        \"min\": 6.3459682737322405,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          24.312599908574136,\n          22.77789,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.8299972253056,\n        \"min\": 0.09330481986792,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.7016773533870204,\n          1.700499,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 718.4335873262646,\n        \"min\": 26.191171745204688,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          86.58605812648035,\n          83.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FCVC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.6275281444425,\n        \"min\": 0.5339265785033023,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          2.4190430615821885,\n          2.385502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.4871624512587,\n        \"min\": 0.7780386488418594,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          2.6856280497394596,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CH2O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.7109998154965,\n        \"min\": 0.6129534517968702,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.0080114040738986,\n          2.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.9653105606202,\n        \"min\": 0.0,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.0102976958787304,\n          1.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TUE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 746.1043827244515,\n        \"min\": 0.0,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          0.657865923732828,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Gog_xlBrSTP0",
        "outputId": "096ab3a9-f082-4608-fb11-6dd5ab980939"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gender                            0\n",
              "Age                               0\n",
              "Height                            0\n",
              "Weight                            0\n",
              "family_history_with_overweight    0\n",
              "FAVC                              0\n",
              "FCVC                              0\n",
              "NCP                               0\n",
              "CAEC                              0\n",
              "SMOKE                             0\n",
              "CH2O                              0\n",
              "SCC                               0\n",
              "FAF                               0\n",
              "TUE                               0\n",
              "CALC                              0\n",
              "MTRANS                            0\n",
              "NObeyesdad                        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAVC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FCVC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NCP</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CAEC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOKE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CH2O</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TUE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CALC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MTRANS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NObeyesdad</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoWjOP0XSVsX",
        "outputId": "bf866001-c377-47d7-9740-df2e73831106"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight',\n",
              "       'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE',\n",
              "       'CALC', 'MTRANS', 'NObeyesdad'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan encoding pada kolom kategorikal menggunakan LabelEncoder\n",
        "label_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "m4VMWJBZScMQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan fitur (X) dan target (y)\n",
        "X = df.drop(['NObeyesdad'], axis=1)  # Menghapus kolom target\n",
        "y = df['NObeyesdad']  # Kolom target"
      ],
      "metadata": {
        "id": "fkjK-FBnSZ1-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data menjadi training dan testing (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4qd03RkcSfqD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7DbmR2VdShp_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi data ke tensor\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "MfOPWGfwSv4_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyusun model MLP untuk regresi\n",
        "class MLPRegression(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons, activation):\n",
        "        super(MLPRegression, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.neurons = neurons\n",
        "        self.activation = activation\n",
        "\n",
        "        # Membuat layer input ke layer tersembunyi\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(self.input_size, self.neurons))\n",
        "\n",
        "        # Menambahkan hidden layers\n",
        "        for _ in range(self.hidden_layers - 1):\n",
        "            layers.append(self.activation())\n",
        "            layers.append(nn.Linear(self.neurons, self.neurons))\n",
        "\n",
        "        layers.append(nn.Linear(self.neurons, 1))  # Layer output\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n"
      ],
      "metadata": {
        "id": "UmNzWmXnSy97"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup perangkat (GPU jika tersedia)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameter yang akan diuji\n",
        "hidden_layers = [1, 2, 3]\n",
        "neurons = [4, 8, 16, 32, 64]\n",
        "activations = [nn.Sigmoid, nn.ReLU, nn.Softmax, nn.Tanh]  # Changed nn.RelU to nn.ReLU\n",
        "epochs_list = [1,10,25,50,100,250]\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16,32,64,128,256,512]\n",
        "\n",
        "# Menyimpan hasil\n",
        "results = []\n",
        "\n",
        "# Melakukan eksperimen dengan kombinasi hyperparameter\n",
        "for layers in hidden_layers:\n",
        "    for neuron in neurons:\n",
        "        for activation in activations:\n",
        "            for epochs in epochs_list:\n",
        "                for lr in learning_rates:\n",
        "                    for batch_size in batch_sizes:\n",
        "                        # Membuat dan memindahkan model ke perangkat (GPU atau CPU)\n",
        "                        model = MLPRegression(input_size=X_train_tensor.shape[1],\n",
        "                                              hidden_layers=layers,\n",
        "                                              neurons=neuron,\n",
        "                                              activation=activation).to(device)\n",
        "\n",
        "                        # Mendefinisikan loss function dan optimizer\n",
        "                        criterion = nn.MSELoss()\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                        # Training loop\n",
        "                        for epoch in range(epochs):\n",
        "                            model.train()\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(X_train_tensor.to(device))\n",
        "                            loss = criterion(outputs, y_train_tensor.to(device))\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                        # Evaluasi model setelah pelatihan\n",
        "                        model.eval()\n",
        "                        with torch.no_grad():\n",
        "                            y_pred = model(X_test_tensor.to(device)).cpu().numpy()\n",
        "                            mae = mean_absolute_error(y_test, y_pred)\n",
        "                            mse = mean_squared_error(y_test, y_pred)\n",
        "                            r2 = r2_score(y_test, y_pred)\n",
        "                            accuracy = (1 - mae / max(y_test)) * 100  # Estimasi akurasi\n",
        "\n",
        "                        # Menyimpan hasil\n",
        "                        results.append({\n",
        "                            'layers': layers,\n",
        "                            'neurons': neuron,\n",
        "                            'activation': activation.__name__,\n",
        "                            'epochs': epochs,\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'mae': mae,\n",
        "                            'mse': mse,\n",
        "                            'r2': r2,\n",
        "                            'accuracy': accuracy\n",
        "                        })\n",
        "                        print(f\"Layers: {layers}, Neurons: {neuron}, Activation: {activation.__name__}, Epochs: {epochs}, LR: {lr}, Batch Size: {batch_size}, Accuracy:{accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV19VwUqS45g",
        "outputId": "9570f461-2664-4f81-8836-5dd374e44d6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-692.6013287641197\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-14096.760905418367\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-25398.07284562206\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-586.6791184066881\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-15040.365094270546\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-14440.062943737368\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:8.78734669176211\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2.8692050934589375\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:43.960627666883724\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:30.004946659689725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-91.94622053651005\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:33.93903600596555\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.19383762604238\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:47.3837600743517\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:53.78689893570541\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:53.13429362349758\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.26849900183712\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:48.2527388783775\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.08674936689337\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:47.9876091141603\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:46.89147384078415\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:44.71175716184461\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.047897970005195\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:48.73042697214629\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:48.54272947807402\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:47.86343784038479\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.48435550211828\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.67149859434324\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.802545662631765\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.222932845448014\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.44399997404092\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:40.71107870415499\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.561507556478844\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:45.401129774731665\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:44.74459817387909\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.74413949488372\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6712.50668205174\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-9362.648546047525\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3866.964259515887\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-9491.868921130355\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-5773.632550483806\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-9714.266690182065\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:53.159853414440825\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:53.105525814519325\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.18001686549732332\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:20.8560378040452\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:35.5128473611776\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:56.676539968937\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:72.10785605077955\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:67.87536555476974\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.09955464755578\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:68.05292005328516\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.06751966795835\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.06675259009228\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:56.59815361642575\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:57.60495811730178\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:48.11091111507634\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.59986991220989\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:57.82152619726597\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.8410838027936\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.92339050570185\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:49.055788242694796\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.211913516570306\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.54343473265451\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:45.83599815648592\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:47.06270375484974\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.98726490132915\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.380306801374864\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:44.485338826034834\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.2297215448873\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.01189655774193\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.2703923054386\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3875.596201260133\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7217.436229722344\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-924.5202388041972\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-311.4156307809648\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-948.194433291941\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3933.4428004104384\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:48.66951518494657\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:66.74244613794006\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:66.50199882151857\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:70.14467973141711\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:72.5493204696992\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:65.25355760650994\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.53341166967478\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.60758411236125\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.71245057865613\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.76341216361268\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.34296026997345\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.15777969886413\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:59.7715786162843\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:54.597999958704555\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:63.36166455965986\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:57.51296127783068\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:61.39920620971351\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.54219444294536\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.21272638346779\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:51.39014627006553\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.16491790806288\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.13236096712714\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.09362730914631\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:46.96331597025043\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:47.321925538322695\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.17776646304779\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.62227336256534\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.87862293262782\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.11367085853178\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.745609037654425\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-367.95737842953605\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-569.0602133460079\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-715.0209127024837\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-587.6504434197789\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1814.699176919094\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-587.046801809066\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.51781365625307\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:75.02823890523707\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.65445003601583\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:74.95836460562181\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.8209909810336\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:35.53975308570831\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.51819100128185\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.7738111240832\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.85060506969855\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.41692796121721\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.56455187209484\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.03465246092719\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:76.94141415510711\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:73.53511693864661\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.75971827661314\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.57579369776074\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.23676062414644\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:69.76385363902371\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:48.57255240434074\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.546252956955904\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.0117835030723\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:60.38147006756307\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:57.231562826532944\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:52.351446406896706\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.49717303193442\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:48.945406007369826\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.936097935570146\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:47.39213071945524\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.87505703512799\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.61110509894465\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:54.004385715117124\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-98.03285433421276\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:57.22601568727066\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-168.33332244386062\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:65.56352714180854\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-51.55527901705839\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.86704413171262\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.82926948846467\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.10668029890368\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.91136044343688\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.01057983581433\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.92519233769747\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.9468595091051\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.947373396022\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.93356177156792\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.93722780949493\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.8950831312378\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.96460801564962\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.69690625229813\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.47721487250828\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.37106303604125\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.04148508837318\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.78563465416384\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.0680210400135\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.12963669815807\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.62223598332832\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.923078381693486\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:60.35532835868045\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:56.39442978258016\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.775717310307996\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.64277143111795\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.391839067998426\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.00661423604515\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:48.49009140738828\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:45.72443592973446\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.872928111618016\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.95451356746533\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:74.95028797898169\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4940.488958659372\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94288912112549\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:66.13009981135856\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:73.55630234341812\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94817916721317\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94804651047697\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94805446245991\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94810141344725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94799070803549\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94808021598767\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808379743304\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94806805551288\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807591590475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94806540289481\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807288870274\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807566226797\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94832569882098\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94808462292684\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94814277033434\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94890001881207\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94824618016575\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94816134218347\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:63.806872964756664\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.69862928284351\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:63.20054815969098\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:69.12142043277163\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.84648478972903\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:61.509603396288526\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.09789235184191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:44.1918306534125\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.22780129769076\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:46.206638279207304\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.13270735626761\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.78106103026088\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-775.8816532303349\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-13470.05503427522\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-15644.164140098579\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-14441.104936862763\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-509.30968597237757\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-13948.647054337065\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:3.6819682875611437\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:39.772918904926755\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-4.715087298242193\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18026361768878063\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:7.289254545601819\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-113.29226754048003\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:63.413519586654424\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.392701837833805\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:52.441769919502775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.1748715990918\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:48.52593399531452\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:53.48116531689233\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:50.57943661185678\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.1909323085989\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.947606384143576\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.449732853224475\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.34221776496763\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:49.41999220221037\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:46.786250759406386\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:46.5877607044998\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.14528683499617\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.45771122286412\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.426469666403385\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.604114842670846\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:47.31107823127974\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.983276389004956\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.507003980912586\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.82105655505538\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:46.57369997554919\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.05487173128729\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2789.294867068412\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1558.7179882870216\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-9608.327126258748\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-8710.446712780975\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-9488.461963110218\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-6952.077312860271\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:13.267079284568773\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-16.126837095846057\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:57.79106441776616\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:60.577726890197226\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:1.9729215014722912\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-13.412848483680072\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:72.30516269133729\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:68.17338157113468\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:75.76438527204937\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.80860469076369\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:75.8651103040569\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.12518466843498\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:52.01671809923869\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.87671068648921\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:61.81443546281451\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:57.87784837074783\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:46.986252075344495\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.49511883599821\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:48.04802116232655\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.762186850357274\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.67719650872116\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:44.626739975784226\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.09912040448028\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:47.135831986923115\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.94600462834838\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.43156370994986\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.47014808224277\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:58.46071308339271\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.52235069936706\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.06771399719836\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1193.6248273150577\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1626.0265223335527\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-7125.58036739193\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-725.815563788087\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3711.8675138745557\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3403.718696305656\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:69.74677349095086\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:33.48860084963559\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:53.954553853065775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:50.33315326211208\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:41.32753281822536\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:50.15518229903903\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.0838837414111\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.76634601319842\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.93057673413327\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.17075931264999\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:77.62688880740798\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.52776455681938\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.34507197733465\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:63.17824778639491\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:62.86093860606306\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:68.68701253799682\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:57.35187948666003\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:70.15853800155499\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:50.874252770891616\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.90187976597989\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.025007673212635\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:45.08272142474626\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:48.40646903694756\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:43.41011351375151\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.34569958521682\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:44.63550260949548\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.823025640490684\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:50.10499659018595\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.31453668804644\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:43.11868231464692\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1427.757702397962\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-81.94110748615671\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1473.4171405939535\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-469.30758549154416\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-446.50256606985766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-933.5372876707638\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:76.1599747213066\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:74.15797716055074\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:77.05787589364019\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:76.67088260605543\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.43846053603693\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:74.98825202784826\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.79889691777826\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.27142185841704\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.3857093660544\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.83901292447315\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.9183401849159\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.76561873338653\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.14308775983709\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.14679053672381\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.07992054880182\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.60953466985244\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.24984799405021\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.34267758472967\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:45.44285843405693\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:45.66893602293528\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:45.29149663892198\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.20765987648046\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.49480584637212\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.11334054398669\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:49.424788438611564\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.917892350713224\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.86603700814929\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:47.60814757505395\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:45.558872192487456\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.50530031771994\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:7.751116318623785\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:71.5587395490672\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:52.796776272162774\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:39.913557903141\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:47.67251732407638\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-400.6332546073306\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.94002731378103\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:75.93611760154496\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.98417877333665\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:77.1339926733639\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.85074075363676\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.03074413880859\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.93335616842229\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.96177168001425\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.92551581853952\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.96619856958787\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.90888573749504\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.95934121960069\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.552791205375\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.00459897706037\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.83354510952864\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.96858931001103\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.92787709247418\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.55222072927289\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:47.524045498776005\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.26755225505766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.71461664670982\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:56.90338086627476\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:50.24277001173125\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.65434366074765\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:58.714515946576505\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:45.690225949547624\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.47986668377669\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.03656459823427\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:49.618336978721466\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:50.03753265790154\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.94457657605855\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.94717757433207\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.94613210228694\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.9477307655569\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.96005588821579\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.9420519506396\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.99971398187492\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94806716308715\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94803054545037\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.9480225136188\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94997186262464\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94811805483862\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808093932221\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94807312355162\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807137627599\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.91724143270623\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94806564126642\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807705961878\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94806175216902\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94815642562224\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94802829559814\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94811381522926\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94810447117962\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94827737396773\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:63.899165017338035\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:61.34154610100977\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:71.53783614143224\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:70.05392404124903\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.1284652345992\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.85009557790791\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.56082576104653\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:49.441813151194324\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.62261683405196\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.91357810028526\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.22707770623918\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:48.376797578224895\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-14107.96158432115\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-773.7137963022184\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-14187.019481613845\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-13869.415341069887\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-15673.962258033813\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-559.2410813174538\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:5.471067545073904\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-203.92976955366095\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-120.77379910799348\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:8.08607082229792\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:24.26502915749501\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:47.249988566899134\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:47.74862545754517\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.49288796537782\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:63.45059831162152\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:52.40854879061805\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:47.9644080860301\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.001563547961446\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.53936800577915\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:58.02683964829636\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.503277844300975\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:49.643061492941435\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.15728319776255\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:43.80772546509103\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:47.41343992862812\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.69964420057428\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.78186454730208\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.477991707217896\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.44829227885126\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.916803994488305\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.242907169181784\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:46.878606008646095\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.20742968526222\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:47.819096352861\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.964996313712945\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.058926578279404\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6103.200751951682\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-11368.852229678227\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-6113.842629578472\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-10889.370188551498\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3982.8700667201674\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4572.342825311671\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:75.73771334896884\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:42.96571412736549\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:26.93367801001919\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:74.9020866468443\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:31.93783450305133\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:66.45643592726253\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:72.84478155104921\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.11946736770507\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:75.55851884321306\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.60041834962378\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.87010616280132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:68.05634476520397\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.772041497272106\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:52.84408441813733\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:45.9949759233646\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:58.26876830380083\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:52.97410145674966\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.532953687112\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.22611294718498\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:47.14291420236078\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:45.774745263623096\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:44.189656871665264\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:59.55907578563202\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.01709805649739\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.76791143142586\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.19464139160064\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.5325820912894\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.19999548764069\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.66398513939459\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.59844895180424\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-134.50842918233667\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-6946.221644132508\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-4772.311316301401\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1923.2772809487801\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-4597.362817169832\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-8134.4581699023765\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:67.17350742213833\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:69.5859268389883\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:59.91951437612704\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:38.916364431944864\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:72.8141268470139\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:32.73061883552888\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.2631709081531\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.41304917467964\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.27369485716822\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.01370340435405\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.47658863586173\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.57850507754243\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:59.183489867112506\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:60.700369399067355\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.7781783099058\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.28865692886055\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:56.954929927603246\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.12480939346989\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.47376397966024\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:48.83213691513214\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.045299869245\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:48.742200529615275\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.61278168966302\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.61937860439703\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.119442749043394\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:43.28657128885565\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:46.76575880817676\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.66648618011516\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:46.94057540267917\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.640169046020716\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-288.8915393745176\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-321.70624341712966\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1072.1005818334688\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-396.78215472786513\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1785.3245032876378\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-396.8048431537018\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:75.41029596065705\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:73.22228161531513\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:76.24449818222611\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:73.90835474005264\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.66718538959162\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:76.40060904084274\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.50554251520533\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.38788547104414\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.23077631212765\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.17003844872153\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.29242171848544\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.90186515109947\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:72.2823437617415\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:71.35646868089083\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.86236198412048\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:75.82156859614231\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.43302809717714\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.79196749501946\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:45.12146490004422\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:50.132108798839134\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.65121044360624\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.76358125677627\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:48.08695506542288\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:47.59916255883198\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:48.532874344123734\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:42.69865441324675\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.568551754509954\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.82937979839091\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:46.38788681550699\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.25348026849699\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:64.82706219310175\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:75.38133490451966\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-49.874191137633986\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:57.2651476818713\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-177.0379505352865\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:62.76658241254687\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.78988432677549\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.86809477982698\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.04660500758646\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.94639033271723\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.00084855323517\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.02906828306152\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.96196080851124\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.94546918966716\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.9735608564013\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.89412200751504\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95950134895841\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.9125936184463\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.36839092552803\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.28338501103946\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.65060452347764\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.39731638327277\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.09824349412399\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.8903289844522\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:59.61734732485269\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.464804507093326\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:46.77846896732952\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:56.639474342225625\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.68851937392361\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.52662268323256\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.65822142468278\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.22935694143458\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:45.64328652676679\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.720856526853346\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.89555454531273\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:46.75924462523866\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.9476453369297\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.95231317440481\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.38643673783311\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.9478861791492\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94869920717063\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.94280532704647\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94827094615398\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94807667211813\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.95045827692\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.75150506509581\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94806492497736\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94806621429768\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94634350385132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94807729916464\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94806933778773\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94807175907965\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807631749634\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807830431782\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94795990995388\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.9488276272331\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94801836383915\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94824466421625\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94801231882909\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94830981599148\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:60.0340778681826\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:55.69956119284563\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:60.938020378139846\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.3141571297637\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:57.1426198799442\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:61.81358973003213\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.51914585338886\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:46.76661203968374\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.81755607477128\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.39611090871177\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.17571646362614\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:52.46455359431916\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-14201.09469445321\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1030.767632094399\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-768.6172217060206\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-14166.8301976131\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-29880.589233560768\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-13781.322582882158\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:50.005696213696304\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-6.816036049261909\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:35.21841370138811\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:14.333294422444254\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:50.018807207626836\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4.9700833522399845\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:47.655930337800676\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.391147910867545\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.68406321775312\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:47.770707900478115\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:57.05195115108581\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:55.513656349269965\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.08867823157293\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:46.01353976003667\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.3388342950361\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:49.00434304108011\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:57.67682689184086\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:45.24942046021081\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:60.11556454818956\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.444743732899035\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:46.79673467098586\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.3967254845656\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:46.838134196950186\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.32248494797001\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:46.21939112419825\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.62701090771067\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.83666069958273\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.93079912196919\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:44.50176118266121\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:59.47675687107541\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4960.78872744543\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3254.1703148278975\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-8857.848047463323\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-9361.728706014166\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-7857.228016233332\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-3086.3904677947926\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:34.18970357911431\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:40.98979628302152\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:44.09562573834983\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:27.1515798167134\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-7.002750424839932\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:59.13256070480466\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.97179352701696\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.35585049576792\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.84539109919369\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.96200924449496\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.13146262435673\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.07448975151219\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:54.581266373742324\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:53.113059771311065\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:53.27856435144718\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.16560678650207\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.123046253766006\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.83563157667129\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.827450520574004\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.90266133813149\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.04326155482314\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.387107147838854\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.31145747975865\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.90706689678091\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:47.893879279036334\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:46.19164951703415\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.64979250090296\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.124443061197724\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:55.27465201744044\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:47.359544044937365\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1603.6202880883422\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-8081.880565625273\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1963.6762228230023\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2047.8083059297387\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-279.7562701576239\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1987.597836163027\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:64.21811483900221\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:66.2855727922456\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:60.206198917776696\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:53.60490661422694\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:62.64467778592901\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:74.87056203438975\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.45492774431305\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.1545416547897\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.55929699913547\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.60092781668484\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.87273212649674\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.80089621895219\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:69.61003220320876\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:59.67875310154507\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:69.40106990372131\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:62.45071583180164\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:58.579577940352515\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.46389201872926\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.38250680301864\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.55089776453961\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.03685452338745\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.243284366232295\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:47.12349352367381\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.53204320810318\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.17243032369959\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:58.640806057539585\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:44.76784716519527\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.54520853998109\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:44.46676975399421\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.29407656748197\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2417.432857630665\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-495.71500796798273\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1514.6480971382207\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1119.7324893294215\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1344.3187944338583\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-477.78715493643347\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:74.85523403301495\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.88053908434509\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:78.48879793575188\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:75.05941133596843\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.29333229587245\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:75.58847106846417\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.44481130976484\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.89061399704833\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.58582996955718\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.42964832260442\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.2544173439062\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.36675061514472\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.39232507230636\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.1052739382718\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.12169839693065\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:73.48726388563125\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.33609808092515\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.67410121881605\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.2113890369651\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.08323423342501\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.59532100626856\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.125604103044125\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.232864180789676\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:52.05989155846438\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:46.831109708246984\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.00565535957367\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:45.19957558635749\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.8361113220101\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.11923169803206\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:48.908898145161494\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:43.30974743063756\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:62.69811963922307\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-36.827748220111545\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:44.469626293678374\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:33.47914570236507\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:62.26619772313615\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.78027874001187\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:77.14012784925947\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.15721581280937\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.74273458919345\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.94039303923893\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.08557562813033\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.93968921829341\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.94038190975068\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.94012126272546\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.96059068137966\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.90206843158971\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.9141967461934\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.12037132747348\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.49286584451595\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.84173216915582\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.4669521709565\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.33743326996517\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.08799418170588\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:57.5842043744522\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.34338134860691\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.166231739024326\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:57.56771222807884\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:51.337760652527734\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.73843441969348\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:58.056732381043055\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.83665544827967\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.818310781233045\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.14456057463977\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:48.093939207969825\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.1143957138402\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.8669852879782\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.73575515536646\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.91825509916806\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94770572127274\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94825010096773\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-0.4438663299296097\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.7821620119379\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94805744034366\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94808305765908\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.28342334523363\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.64509351747631\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94806605460045\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808233432454\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94806002837828\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807786984741\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94806606164592\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807679423955\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94808047666993\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94843554468584\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.9478906295354\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9482334102581\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94879202884046\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94918345204952\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94827034024388\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.60231021692474\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:69.65781214013637\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:62.99625185587634\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:67.13922221985644\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.44334374101638\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:68.58342740129916\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.26097522637241\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:45.93058334644429\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:48.04261455721889\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:52.37826484323747\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:45.93552326808491\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:44.4887255053524\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-27066.479411023727\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-13398.767788904308\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-13522.359257105112\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-12864.711515503292\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-15256.410037860616\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-986.7459832259854\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:3.993616515581211\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-169.66132855349585\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-26.258652953767147\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:67.50478364756202\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-97.44250062321751\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-10.197022752183171\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.505910343406136\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.00846996575805\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.718154822780775\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:51.31529516139024\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:57.63515559435361\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.89924352378875\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.10648065645738\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.61221759630274\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.1408550207473\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:49.49709865241844\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.6039499014475\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:45.58007095194032\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:47.34967547851204\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.28543033013436\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:44.96021929972749\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.64115142606205\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.03368262206831\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.06406163583364\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.120709075619615\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.28091305515445\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.07682193724852\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.052929011331344\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:43.45834140964527\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.16173230295369\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-26472.03362564856\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-29365.41328200963\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-21373.28407514556\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-8884.503206744545\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-32167.44180480921\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-24683.64662902387\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:73.63769180479719\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-150.43232366031694\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-90.81121175377459\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-148.4836594808562\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-61.80881007484229\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-78.26517662304981\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.92968713532666\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:68.51814070773744\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.27754216254274\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:66.55150082188388\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:69.27831363640402\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:68.26712378279443\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:51.297517614607926\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:55.215784375555074\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:60.18959945456732\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:54.650628333948006\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.67860626333619\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.15990862100025\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.49526734162824\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.02593147288495\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:48.213015043472474\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.95743541159999\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.62598497274356\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.36907198502616\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:46.57531661444568\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.576061845671205\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.65377763173211\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.00951094520289\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.28233470043815\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.41295026199286\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-8006.457141969409\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1966.402888391974\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-6285.966469679788\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1530.0392654394898\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-4706.114632905797\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-12226.269863321613\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-9.55764935465664\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:7.110969469808426\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:64.908915744042\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:18.384542777089273\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:40.941602606957495\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:18.938286432231667\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:73.95690492375617\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.09643876505612\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.47231924825056\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:75.00494207520482\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:75.58604550699816\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.81180453375627\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:68.97562899640735\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:62.180881606014204\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.01299818258784\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:73.840096414418\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:60.405360890803394\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.94685808201068\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.554000772330305\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.72633837233902\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.14233434243734\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.835084827539006\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.56586100467553\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:46.89887338226193\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:47.45266959716994\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.85986644444125\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.81766995317923\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.085667328420264\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.23108624212496\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:48.88550605216865\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1004.0459899755797\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1208.9688673087046\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4611.26683921303\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1123.6669961254458\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5167.161587301063\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1652.7048789581227\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.6543621295451\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:74.12672691029579\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:75.91740813567189\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:70.91021367750176\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:75.01015259324329\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:74.61027169997905\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.11848670145581\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.04985142928395\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.85522809096263\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.91047405332351\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.04560592054287\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.65307095569358\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.10163675764116\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.01436295746066\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.56963332912132\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.00864786191471\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.0295875668056\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.31312171528901\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.64226114395287\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:49.1849280717666\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.61412943121107\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.54955534779058\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:49.27807360875786\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.66961421529264\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.3517313692117\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:50.11604769174465\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.153906575178794\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:44.824719013333606\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.85433714613876\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.11360331781507\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-172.8945944044325\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-62.30196599607114\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7.610686018863366\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:8.923131824009422\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:63.67639228995152\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:57.77104869895886\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.77053072210181\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.9558328686031\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.86093756305222\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.70755273625079\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.1461786107814\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.04028293690031\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.96969519223258\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.93116376022357\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.9797353433567\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.95242936353782\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.92843690174034\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.94772979093406\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.14551894494733\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.20228422101414\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.20922686106769\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.25335451692837\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.13023542042696\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.16934769946445\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.517417839197684\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:61.787224999556315\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.18454395423639\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:50.82332295658458\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:57.14083014727975\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:60.11513577138607\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.87518690658002\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.13749741219789\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.78565426415069\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.60735675086647\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.40730813246621\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:48.426111521004124\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.9393261067035\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.94545517388622\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:67.46369841720666\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94320137619127\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.95596813685881\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.94915301035105\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.809409953554\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94809836510883\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94805236760794\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94807511037311\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.948056115796\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.9481775514529\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94807905583423\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.9479818706723\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.9480776843168\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94807405825014\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.9480873389541\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94690435584648\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94801022397712\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.9575446444858\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94801100895948\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.95264616662635\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.9507113136674\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94796873909738\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:71.17807773669185\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:74.69129993325619\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:70.73955143867185\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:71.7902078549396\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.41278697117\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:71.22883702400071\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:49.09651009138406\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.75612959205822\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.11657346921282\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:52.73735454075561\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:48.55241199457758\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:48.74106962365884\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-16495.769340697003\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1405.8792778222555\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-30045.749822012356\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-12866.099844550032\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-27414.361158480693\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-27215.897146334697\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:68.55379669825048\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:35.464328116465026\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-114.45251226284259\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:5.506665850831727\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-33.59838189855158\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:52.22819154191149\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:58.72722347277981\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:51.253749580336105\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:62.81569676489882\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:53.55825299768466\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.10958285566634\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:53.282884660729565\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.04317085973338\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.039479332753665\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.38277903276696\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.157280845293094\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.43032024891194\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:51.695744943686876\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.81460968279071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.739655467987625\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.831758517692705\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.62323171586103\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.04048814298109\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.46791250993175\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.36725033635319\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.07589974801567\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.56652949730461\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:48.90785388732175\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.27883542347274\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:46.9059675098217\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6433.361949048895\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-11141.263676647879\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-5633.034920485778\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-31449.98834863998\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-19884.540140018205\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-25541.62634245705\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:60.74546738061688\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-25.0466682292797\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-14.234037127806687\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-95.89800557534087\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-54.27160013417167\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-62.02163851289322\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:70.68168449063673\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.05192990205342\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.3179946419195\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.69624109292613\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:68.1068011303414\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:68.19766835963472\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:52.852454803549364\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:57.16147939692904\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:56.841194602661574\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.70514650683971\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:55.74277052692511\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:50.9873499352576\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.91282583712076\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.18651256901692\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:47.14455906040468\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.548702188476135\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.71441015247711\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.08695492340976\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.09910372740363\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.030331202690945\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.962320650899095\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.75210047630084\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.11059935153752\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:46.59666889725096\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1758.4776711520292\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-524.4782693560805\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1101.5884980336243\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-11727.437756285131\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6297.493748555886\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6046.915163591774\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:54.7152014582809\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:32.58606750632572\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:20.90527002411249\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:24.08175066383548\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:4.7676935545378\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:71.6869564484761\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:74.7617935763277\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.0881476462404\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.18646933367347\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.47234330833005\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:74.02614820792601\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:74.5274447849926\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.0083698049904\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.69921509086663\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.91173864007466\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.51218290036358\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:68.0413494090615\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:69.48141168312729\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:50.46868570049134\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:51.68191247918388\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.042493691117485\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.39094645716103\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.912415813587145\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.04636911851763\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.97405174127402\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:48.50770952701099\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.04520058199189\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:47.352281698063194\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.71620764619163\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.5697389272628\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-505.4756851812532\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-961.8696189659425\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-813.0511154613691\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1397.6597619113065\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1255.5848577813522\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-329.1038392565211\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:71.62617043635335\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:61.904370315061776\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:71.4381557735897\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:70.35883147008218\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:65.44056113683116\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:68.06427370947678\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.75125320611552\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.95386460721728\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.71574027966665\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.14146461845665\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.97661707399396\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.52553607855752\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.87226583482808\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.5954653758811\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.11498902650025\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.00933120676248\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.21115857273504\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.11157196731996\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.40522435577579\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:50.71713227904904\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:58.25665331144001\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.410293394792156\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.09450649705528\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:52.47924718624193\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:47.59272393558418\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.847160405841194\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.798328946797376\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.8306068331238\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.6993529730373\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.70300456444705\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-28.76774131829012\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:56.55955366490861\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-48.58511029687615\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-24.8225415006597\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-44.37588790535833\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:7.307763997732508\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.9621040240529\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.51436240584762\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.97628922496281\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.94702654771677\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.65445995293236\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.84540122958785\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.93653881690744\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.99436223863898\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.95105864928405\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.94224580194745\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.94675740151071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.95375487407988\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.09651141889083\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.17765264500775\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.11024281074909\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.96864499737654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.13077052828832\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.2009581474219\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:54.28249943382022\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:58.890698068108115\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:52.48818426173536\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:55.12660098584314\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:55.606844358093355\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:55.06742504477453\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:47.72155331733943\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.27127636369051\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:47.8160300282534\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.70537008572931\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.19257350391624\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:49.434183783964244\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:48.05263182232002\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:67.09281107494454\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.93257343120891\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.96054487175788\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94355069510668\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.9514791814242\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94988429217567\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94817521177097\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94816285461023\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94907735084999\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94793687832458\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94610608103145\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94818626199772\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.9480698262734\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94863472001772\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94807485908481\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94803362197065\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807453734185\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94799774645632\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94803989595837\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94826543190237\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.9480101312118\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.95002185020793\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.93937915671614\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:68.56517946161182\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:71.42584396862345\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:69.17567782579584\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:72.9545743130529\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.98246161899198\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:74.3405326179297\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:48.07291614189685\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:50.54160628916946\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:49.65245588069783\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.469236912069306\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.47785571839299\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.08420044942292\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1031.0126846094033\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-16421.40122985539\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-55983.158957667016\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1323.1908373235249\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11887.838549835651\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-41775.75355425324\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:35.125211938053155\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:45.17542399272288\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-10.344482449868986\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:27.869409442511582\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-63.6274017869158\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-134.9032043072067\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:55.88996887524078\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.031851821651685\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.82848877951186\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:53.26393146135378\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.52685392151864\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.888624434564136\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.359015225389506\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.29929965647587\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.81061513451866\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.90395764875615\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.277980407595734\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:46.834493730836634\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.88642020696162\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.45450130572369\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:55.95171613614327\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.221614853674915\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:47.02291294721002\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.319801798555645\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.400817237242514\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.14098732312298\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.37513291246314\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.96526417405683\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.26866672155164\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:46.91764373505464\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-24225.90369798707\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-5486.738258802206\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-21332.187900287696\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-23865.676008912877\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-31778.12744641135\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-28321.168488456664\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:13.689823710514482\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-126.39098963087427\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:7.189885671914709\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-17.25590876277927\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-10.260233299482335\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:29.760075712222765\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.6039571643721\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:68.64329374522275\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:68.24558823948492\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:67.95274109423302\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:70.84653054615755\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.04442818236218\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.43840864924252\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:53.5311620855679\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.933668347021275\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.825682195564006\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.207465721703805\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:54.43106641783031\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:47.07692612734623\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:49.035222976636575\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.7854557450981\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:49.534575829327906\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.32764821206612\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.16048843056034\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.56552274252741\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.20252317058654\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.9140154851103\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.41506244360497\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.19620244415187\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.76035846402272\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-359.4758139340496\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-13701.469695502325\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-487.99503418852527\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-13131.448213221805\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-7807.476942514791\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-13454.186993193869\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-9.544198293682161\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:53.53964096547301\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-6.626879917626494\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:69.95568384421539\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-4.58355074890775\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:13.97557354659148\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:74.5383287575228\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.30654425974245\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.4943934573819\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:75.74947144310713\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:75.3711115102114\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.77362296100297\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:67.9015011611043\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.98552744380595\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.4358199040095\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.27137664326821\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:68.62175266358963\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.44898820184085\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.783316078209054\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.54065443076328\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.244025831374245\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.418913259503405\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.24764760962333\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:48.87373539067986\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.64048510899075\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.21669916772205\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:47.246062148500364\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.40531058425129\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.71037674600726\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:47.00448533051872\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-860.1238923339603\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1689.7926464336326\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-987.0109687742049\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1971.703660272068\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1450.4227622462786\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-813.8465741189848\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:72.3075907609893\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:74.13811763033705\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:75.58844430508624\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:73.78126138115229\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.07529633058348\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:66.1933739087636\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.49737002579033\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.31896311725754\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.23172644041391\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.07257092562692\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.6214250555369\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.21124328760955\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.44386518330346\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.55174002297946\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.8375644938414\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.87368263072908\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.07167884846011\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.53033362992454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.92396746992689\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:51.250778833496646\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:59.27656398421202\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.11519798563633\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:49.80952114782716\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:48.28985883341331\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.249008464792105\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:46.076812517041766\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.536187983996484\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:48.270975476038366\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.85302360786215\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.9769330439932\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:5.9649726741421\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-370.48142018329446\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:5.184870615448888\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-92.77526338425463\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:51.977562373599454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:17.158121006802553\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.09578586620454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.81683230531601\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.6251934523466\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.48797580066677\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.94808375281175\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.94640790880712\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.92837013420484\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9583849079314\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.92609309116811\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.93863323441258\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.93587905830807\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.95427902858965\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.0843800312896\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.13725631447454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.17493850300404\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.21547146920054\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.14242156774064\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.09581100442826\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.67457076278937\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:62.028212433752806\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:59.27493933109762\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:48.32197353419965\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.58422152943457\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:56.98845627856382\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:48.076099309985146\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.705211263998365\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.639534321413244\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:52.73351303916027\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.490756405724426\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.83812878907337\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:74.43412038827148\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.95721896076128\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.94772697039906\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.93497182065995\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94902081861564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:32.78649159544936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94798660052865\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94809939844389\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.87328952424069\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.9481692753785\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94793744196188\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:75.79641165556731\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94805385185283\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94806299451959\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.74779853452559\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94807012218298\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807671204245\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807338658237\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.9482092642709\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94809596495331\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94814868852602\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94823153146709\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94805223609256\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94822414781842\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:69.39891899977734\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:70.89158786560567\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:71.1927953963678\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:70.8834665111898\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.29474540145215\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:70.24733554821394\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.17847277352057\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.454510944109444\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:47.88880119844391\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:59.69667166671102\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:49.94447738390161\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:46.95055188451159\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-16725.968857427768\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1192.7474380009187\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-28803.296104390567\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-12312.99105551038\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-26590.83742730913\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1256.9690586733386\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-17.949477312506602\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-13.700832944389774\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:48.610524388163746\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-236.35360436753277\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-58.88491259774795\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-443.44128721618955\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:62.774792208480875\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.993486695044425\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.57285856986909\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:60.932534330115715\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:59.237845397610855\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.30061939766762\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:50.323991254383046\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.0038942214897\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.60565160529011\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.01772373315854\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.50651930882013\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:45.72329852697744\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:57.24330375439261\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:45.33325377191212\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.270551482061414\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:46.44440246365783\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:50.718214210795075\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.851879367568145\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:46.72474931717107\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.69117870468902\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:46.79868413565477\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.53447237821007\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.116642160970834\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.947991863656355\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-17318.33656102865\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-4827.161082026524\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-18811.761424981112\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-10684.782089822585\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-14177.550214364643\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-9032.037383275674\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-78.02357499387152\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-8.5825022042878\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-57.34118314781369\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-50.27287289136222\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:8.971415658557014\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-8.036629715897693\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.37739295335714\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.7112028574361\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:66.53628985274955\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.87746618543675\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:69.92797458425481\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:68.47307191203203\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.38720252863341\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:53.00425320006526\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.10967806049743\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.3706393406981\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:57.530058744246794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:57.50124324656218\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:49.233576909611784\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.063806958854705\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:51.706893702013424\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:52.8075621949202\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:44.70777030391332\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.750254286213874\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.08021161681182\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:47.40611028903765\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.74873908138574\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.53819034365428\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.924831648550224\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.85783727508159\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-557.4190884147505\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7071.899416317049\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-5440.599703957849\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-9146.459112773739\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-13536.012716646548\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-14736.523559922023\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:49.03855413034076\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:46.923126734740336\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-50.51791716493239\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:37.45935162378166\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:3.8488780916723475\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:22.24543071854669\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:74.24501133679028\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.48197379142304\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.14694257455139\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:74.89908153941258\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:73.61314461586323\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:74.06289192801671\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:68.08014955280615\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.61958550279586\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:59.51426868379068\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:68.93098563325744\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.24570731085948\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.8853227610636\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:47.22274628220532\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.777303293282785\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:49.33731535213307\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.69271123587755\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:49.1557138620445\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.50205297178645\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.979230687069176\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.231043506845246\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.82461727336577\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:56.44228916125\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.80469706109698\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:46.90029520931866\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5230.532833062541\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1083.102764793979\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3478.8524460097383\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5117.424014875323\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1785.9957897165239\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4785.5725012396715\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:70.0231119438454\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:67.63297310018277\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:70.32486303666148\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:68.5997886907594\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:68.6620996964081\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:76.22938853159394\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.68411486068047\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.92447959249465\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.99172251378579\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.961165603171\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.55506352912356\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.87099501079608\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:76.49652302453046\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.1905445317944\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.83323190401774\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.07130030297782\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.55983961530329\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.32706176567679\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:48.80552942783134\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.36959999569577\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.43169484777748\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.29480928910046\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.815268287375\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.123293994084136\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.17976604131989\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:48.70329826506599\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.93472783461248\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.9373619204506\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:46.915114181919115\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.067169196922045\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-270.7108812505002\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:51.153967641675635\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-59.47011308091377\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-15.075609043322746\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:20.54972415650521\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-159.44294072775693\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.34128611373376\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:77.16212573250604\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.03951484486285\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.86170787676006\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.83113808233594\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.11790755003621\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.97637111206896\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.92525764447295\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.96581093742681\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.92776580228873\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.9770671571682\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.98636137894329\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.17997113769688\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.16314740496605\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.21515641238767\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.15153506626005\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.14269608846324\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.11662970911902\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:61.02090997898833\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:55.13681268761297\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.10204657214753\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:61.42044789132122\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.164282836272456\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.145655448555104\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.743935011614965\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.6291138075433\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.04638993516975\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.93035620468587\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.292126982770064\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:58.33960177275588\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.93723674079769\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:28.64199530148337\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.94808082189778\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.95260374822233\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94313482471674\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.94783327239438\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94816750931496\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94810743027544\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94798577386061\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94823277851462\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94940512061964\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.948088405168\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808389137259\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94806968301559\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.9480707656689\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94808146303521\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.90715796370691\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94806688361697\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94834486248926\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94799400061673\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9481635920357\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94814613337024\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94818129846672\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94800976837028\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:71.61138178949473\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:73.33639994134482\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:70.27174168867423\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:68.65408602805472\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.38121135989637\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:68.85559044417266\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.821625756456505\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.784312409911685\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:51.49250823044467\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.566384973091054\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.739576353336304\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.201683057843454\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-44532.65030600125\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-977.760345903882\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1428.6389032623915\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1699.6622256165513\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-23285.897553408584\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-41990.017283892805\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:51.687548130492324\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:64.5391632150345\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-173.50537364787243\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-51.47841722829967\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:62.75599063663995\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:66.97739660739899\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:53.91965851516494\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.27796749194087\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.75530177623713\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.05505036579708\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.2507492118435\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:57.944199604909194\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.85009844996875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.4409904765909\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:49.423322680430495\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.2454999283696\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.95679838744039\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.47231721146497\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.91994234915438\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.926148115590486\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.19506382156631\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.10371678624921\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.74522639840396\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.66298197721806\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.87033288003518\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.48069734937145\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.3676087093034\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.55267494861726\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.21903962064813\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:48.00527240490942\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-56059.557394947566\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-66537.39793445297\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-51666.555998135584\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-13241.415894379103\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-51812.92842826663\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-48336.23299995119\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-434.99192152556884\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-326.02129932742497\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-7.006294014324266\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-282.9146506891559\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:53.444326055435056\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-131.79349346692587\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.40441169543375\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:67.55015621794031\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:73.89831445271618\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.9778422980068\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.0623670145693\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.10579315981026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:61.1597371099031\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:59.539031453131216\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.213965386575\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.755657718789166\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:59.74199980221413\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.538347239025555\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.90190578956036\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.1996190669771\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.85267724095601\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:52.00161075687741\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:48.179128860880105\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.10220175552629\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.393091711897476\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.294979173992445\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.37401862846434\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:47.50119966724146\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.3594310065134\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:49.81424321910004\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-23584.975039385925\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-19684.365479564745\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10291.965591559925\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-15888.135780698207\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-27082.162287857143\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7647.868799956602\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-24.489315024410473\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:25.58502813227257\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:4.024886220717072\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:52.55045361928437\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-54.20966328740402\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-144.85912285422225\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.95331401342102\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.42706421268936\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.22570618594887\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:74.5197458329212\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.22913906102673\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.45171399263062\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:69.76724734355184\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.16672559003833\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:71.97233800746213\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.81511592796883\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:74.57439336100839\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.90821802472863\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.98017878091832\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.439125131771625\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:58.26473795846281\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.29269585957481\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.67609037168859\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:49.40470604782291\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.63372392429317\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.91590207899716\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.811862318557104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.422310998676515\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.10678874879747\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.922630700682724\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3376.6045837913375\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-7358.504799804507\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2403.331463350096\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2999.330117215877\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2671.5168030831264\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9262.9222615109\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:63.09692787316203\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:67.11451207868126\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:62.418828459590124\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:73.74028446075013\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:63.59901623147224\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:43.42689142159536\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.10332971938114\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.02866362435692\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.37743161248822\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.98227799812389\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.29585718648278\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.67663520579266\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.75318623232596\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:75.52678046191744\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.13367540630607\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:74.48137144024585\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:74.25778429746816\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:74.51157615211088\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:50.79326086770817\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.443325123172094\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.59903838421483\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.91463358039175\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.19258196783452\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.588269082299476\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.790061426207345\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.82579810452377\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.53927324733119\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.23271938244878\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.03487563592369\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.9577196814161\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-64.8547701989693\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-628.8648907738093\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2350.9915767832003\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-34463.75502908765\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-382.73653702251175\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-237.84699804487897\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.39248132029324\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.80379539328922\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.52433733474184\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.76200324217103\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.39233942479012\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.06840220542288\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.90328428649451\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9377840232248\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.95004045258742\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.98812407241081\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.94303752447884\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.93166988303663\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.78484589307678\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.82158792108133\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.86257136206255\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.77342540652758\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.79710964267888\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.82032783180358\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.55754844380514\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:58.61025509623394\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:63.0518458123114\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.84369339328333\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.317336523815854\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.96252940949771\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.74122701413853\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.97919305649985\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.26529023117019\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.89088875929833\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.81817781271734\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.665315009424596\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:51.56648484057944\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1360.029498040911\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.95414593503455\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.20665495371236\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.95270189626467\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.93370070581459\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.87931084745601\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.9489382598417\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.9481464762496\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.9489779211199\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:75.4977540391181\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94778529746594\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94807004233436\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94770034558196\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94808233902151\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.9485347307602\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94699491122466\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807871060638\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94810410540248\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.9488304154764\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9484112366529\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94829692278817\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94812571091198\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94756340520226\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.26071862656832\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.95862708860162\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:74.06769739144679\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:74.57392466048304\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:75.90477469153745\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.21871937260654\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.258194515703224\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.991657154110584\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.06260125246265\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.18696064708668\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.37500656691474\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:51.412707445974235\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-12669.938965234538\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-29229.3563858931\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-15721.943691417493\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1929.8131675584943\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-30556.14873910157\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1514.300776843108\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:47.927156929146875\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-34.07557367620926\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-45.56763590650357\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-69.60366022596219\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-70.27081243629245\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-44.10734066021922\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.41163431437961\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:59.870476660247476\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:61.0195474409982\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.068524196356464\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:60.72199663912057\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:54.83951222201424\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.77622339320849\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:47.225423280804335\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.41492295611012\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.07342289176229\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.175238344398565\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.781467166141404\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.21251363177484\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.74222725980317\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.86296701743625\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.52995337778372\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.162563705257625\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:48.07003913894942\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.524433420494006\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:45.77044321883138\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:45.78032531255197\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.236742771416324\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.274412078461474\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.296773333792345\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-10541.027999093347\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-12947.872846496679\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-2120.241394749394\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-11123.018325192426\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-13808.524541163464\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-29101.738891909685\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-10.820828625966094\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-122.51518353925528\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-84.60380183701632\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:2.332681300040773\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-40.87133447986781\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-6.710500001813413\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.80418964837648\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.86117508723287\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.79177078893562\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.10100806698826\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:75.54723629338991\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.0916473815721\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.94780464950654\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.916052134095494\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.401734692337385\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:57.915096499254794\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:58.2185091265867\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.15242271544521\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.64783232555181\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.4552221225121\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.38894850010649\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:48.85923127468361\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.64612969793703\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.06601048693635\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:49.70600222236674\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.01740445216591\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.42865919575412\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:50.4828221873227\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.50813948510434\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.94773389483598\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3715.6943390367537\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-3683.5900763623636\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-12297.581138415446\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-8278.538033415522\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-27061.998515433454\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3993.170510210138\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-207.9946774892491\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:37.55366355063315\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:27.583359516540597\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-44.21628374838284\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:20.004466955731292\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-38.299435983031074\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.86896825207792\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.33964197705166\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.44718453182396\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.43464295698772\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.08165333503997\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.28062209385976\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.5610900127202\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.53862495540727\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:74.36672834557656\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:74.94848122551649\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:76.86889610532891\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.1909651443233\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:49.65631489820302\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.84855803377615\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.60630030590685\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.92185577579941\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.36882694136025\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.96419864264739\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.96560923552025\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:46.113108130211536\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.01863318780647\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.68969950039993\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.64240708556159\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.428184173408226\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-687.4192143914454\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2032.2687651060808\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2104.273648070387\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6519.488008610371\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7096.6539591856135\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2081.549693018175\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:63.46351084416075\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:56.52447364009019\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:27.600823982763334\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:27.7612052863747\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:59.107528924002615\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.41607693774762\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.84179044220745\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.43416021807725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.18401558292109\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.7360999323046\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.96286503539676\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.10059554300692\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.46146270038577\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:75.43880668350616\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.38858084386497\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:74.4913682141954\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:75.15813751634977\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:74.688270001124\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.9992394280584\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:51.75940976122217\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.70256519611188\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:52.39505209425028\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.21354245287025\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.09569825497409\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.68931020280805\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.34593836384862\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:48.42169941458015\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.90853198473853\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.33701711683479\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.77880149334082\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:13.446599390677704\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-141.71947692678705\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-52.58024967590404\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-906.7261262988368\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-81.710785444183\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-208.64865582603653\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.04233794441554\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:77.31090133071791\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.33737877544407\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:71.20238447677816\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.87592592833077\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.62817625618055\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.96151160132331\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9196700542531\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.90763173608728\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.92612787933214\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.9518740375367\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.95415236284828\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.74577427342523\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.8351565838048\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.79887453433187\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.78315681416375\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.75305083452763\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.79717650063118\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:59.46501147174816\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:60.26043112355251\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:60.91387052077233\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.92780726868585\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:56.72091449896377\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.117724047438\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.436518138769195\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.393447721763046\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.71465533770403\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:45.73188263914123\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.967782759855496\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:50.35743628216834\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.94108525630148\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:66.73478999412181\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.95363843600707\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:69.84739632377294\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:59.3218191671409\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-50.405211707942584\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94802994423723\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94789749416805\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94762659129239\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94811109391792\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94962453992467\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94919827042648\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94807778999879\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.95112780758112\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.9891972237445\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.95219250670374\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94808830653146\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94808281576474\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94954383175987\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.9480901089966\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9480280325674\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94731359410417\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94806867081692\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94601932785659\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.02924654667447\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.56565036362227\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:74.88832128468323\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:74.17927819756986\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.59495330923086\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:75.29846565596836\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:51.69058720721775\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.17218469192513\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.30092900583976\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.33634353792507\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.59022438227896\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:51.80524999115812\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1510.1132235440612\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1813.9763685546586\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-28801.193219080415\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-12290.975906606544\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-29272.60579649532\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1115.7704101574523\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:70.17382500301298\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-164.65105025480824\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-241.3734465931418\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-242.9588077855542\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-304.2421039913093\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-204.25883563744733\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:55.240328177527886\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.77060094725568\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:56.06676564163655\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.802707564182604\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.7414223435911\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:61.09802105659994\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.57180913931113\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:50.8747519900284\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.11417770449152\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.691086556783006\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.56120468301506\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.75738929310143\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.915671154257815\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.49208354925878\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:47.755681662295544\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.53668236293021\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:48.67866783658993\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.492814386338345\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.36629729780793\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.962673979189745\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.87406591650677\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.6532079547033\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.57206418434228\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.69662179079838\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2350.21416203444\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-14306.294309407167\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-58991.92551792467\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-12542.47399282042\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3256.871218903033\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-12838.452428433724\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-93.71694358809901\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:24.794649706758598\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-67.62723550259173\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-136.39860230228672\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-159.3670202485213\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-428.916428524082\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:73.17971772476855\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:75.37958503614927\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.81819339114159\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.47143815830057\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.12357310557384\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.38833609925564\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.80717605115205\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.542805456200426\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:60.599535676945\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.77876346550113\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.83201161496652\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.244829258233466\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.08609892133187\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.34314693042008\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.68969012722902\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:50.772748427235115\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.919416372094034\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:47.77079110508645\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.40286679570016\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.822534888383906\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.45406038427418\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.445861342575164\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.7324924567983\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:47.835774859743765\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-20321.926311135197\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-9746.50775208259\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-8109.754892594237\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-21616.180095943153\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-26207.56231959736\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-15753.663561905907\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:39.54790687824066\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-144.58971696871302\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-30.52828402571832\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-55.06371081204185\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-51.5594403418713\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-202.34535756873933\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.49007257840313\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.92862470352904\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.62641739779518\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.58134312306548\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:77.2926849277119\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.82809249653978\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.69023788322889\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:70.59832334260099\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:75.51343909063331\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.4652770911971\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:73.19324064193992\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:70.25032653887973\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:51.607286005366774\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:51.53998833023441\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:51.83441503277273\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.61618766846199\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:50.464369384520545\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.79095054411391\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.33496137593936\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.42268058789748\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:47.36842633150899\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.40162392520735\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.36290408663269\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.151329710962166\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5839.228907027894\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-8910.065685772726\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5189.857542430255\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6247.751187733348\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3458.9913437364607\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-8009.9231629225105\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:53.98807321316244\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:47.5909968217214\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.12803047223764\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:48.34795735124718\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:53.47038781295337\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:65.63847999200753\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.20796707533212\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.18830339499023\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.04085572626386\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.2611067415317\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.49288848199836\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.01898946641842\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.41415614364088\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:74.94430755000118\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.52466059402747\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:74.60367968694914\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:74.7394437755629\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:74.70293952500002\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.445195034357674\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.34584104050746\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:52.65480913192479\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:52.75827757397724\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:59.2664818303664\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.74285517375801\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:47.498328815279656\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.110845092352314\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.9647433165728\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.48810667922124\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.18926688542602\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.32745574228026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-791.48501374761\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:8.136834790144876\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1855.6704998016357\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-377.5257235347426\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-0.747719195717611\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-930.3900061675749\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.189333557425\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:77.13843241651007\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:52.10822373511193\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-38.296093172309334\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.33577353189646\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.71067594448537\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.9440866038027\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9448175568389\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.96634364043568\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.94951474572656\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95956278777291\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.94968041986627\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.76496588345397\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.79890525491338\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.80843633939377\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.76393013943641\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.78278355710238\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.81052536359446\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.97040257951094\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.344961154392806\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:58.05863323434306\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:54.342144120329\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:62.90191830208538\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:57.71038674898416\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.48342359263283\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:51.23748435404729\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.65688340230848\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:50.912084761226126\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.488170162060534\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.287823240763686\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.95930254938472\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.95280049521685\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.95807801916244\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.95136825525451\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.94544630599266\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.64866526357953\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.89339266319365\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94778169958116\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94829328028212\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.9459368254464\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94811109861489\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94846187359335\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94811395672572\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94808215583939\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.948075864238\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94807089718427\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807006581925\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94810604231859\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94969375693394\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94793280839356\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94797717134627\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.95980085407871\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.95155365669982\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94803674017659\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:75.9079132769242\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.77226505169632\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:73.21854030656195\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.2861422435142\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.23041507463178\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:76.87739151037519\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:48.47126136335028\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.497748241227754\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:50.85835210579741\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:49.926788398043385\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.3894800672365\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:49.967214569649045\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-43139.64399513623\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-55177.39301039724\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-13963.658660485858\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-27986.860659932227\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-45917.32735419668\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-25434.639579503906\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:64.91647648989824\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-5.53136444918465\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:56.941563074188586\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-11.898271106565161\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:43.513479159515235\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-52.667118422246716\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:55.61331581996593\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.44483381676524\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:55.88634431573516\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:57.218371932758096\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:59.373887507663255\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:57.75746509676449\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.27586952158909\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.62078954560655\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.18117911280247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.06977746719927\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:50.34879772763161\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.877758027966614\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:48.511450853084284\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.22552372120654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:55.29926513403161\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.73525748650233\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.401815770612245\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.73716660830874\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.57118635164931\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.41528133654614\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.25837327540508\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.03878164824489\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.20893281364742\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.07910980990522\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-36170.04402839264\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-49595.33603907195\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-31732.564411264786\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-56766.12187205946\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-16522.59791902523\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-19253.005647621725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-69.01457923148165\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-58.32807994245825\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-329.78064667248555\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-60.170439493947384\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-189.9145493176718\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-26.113955405305166\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.76069339351264\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.06002697214731\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.96254244031071\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.71952313983225\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:72.08628386752261\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.93225892882727\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.3832180242871\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:59.83228145741144\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.55931861137926\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.6130350621269\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.29806863925793\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:55.628737343153766\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:46.42403901351353\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.46693612178355\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.834575420065\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:49.65153266246437\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.7856827821198\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.23124922477325\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.944886356615676\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.3611784375752\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.306390590554756\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.97150609530273\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:50.448188910402436\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.48500096676409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-27041.656621447502\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-28039.25512395006\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-22206.86080698144\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-27577.238742134723\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-26325.66360206093\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1888.679794104105\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:14.261507104944293\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:50.54958667033671\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:5.122705549588813\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:17.78399426698497\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:2.245399546115967\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-46.34600087730221\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.02356707279469\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.08675843547704\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.44508506154526\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:74.66010658453543\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:75.82758871634425\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.26197193653401\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:68.81491074865498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:69.461836849638\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:75.94123291654601\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:75.90380830556694\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:75.69049694366207\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:70.73099566102498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.033808053808\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.289411754461135\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:47.830592145463726\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.54707304110283\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:48.23194151880753\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.84178196408082\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:48.29782547357281\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:48.960617901295\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.66887296221921\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.051719807787045\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.79447099223581\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.57004359264113\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5983.035785744189\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6791.868791211958\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6924.803501907722\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3307.9429523507097\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6455.444850538358\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1864.3104610337905\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:65.32914398973433\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:51.86090699981949\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:54.35463712382636\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:45.84065272734802\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:68.45233690982921\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:69.33207069446571\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.94561250384537\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.64899881708989\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.11184293712753\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.0332097842808\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.20316771778937\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.83847777433898\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.41946714999077\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:75.50257019657522\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.28491030202503\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:74.47383634634521\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:74.714543358654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:74.77976208049262\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.14712265587703\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.079098236200316\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:52.50995058384325\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:55.43682654780886\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.15374622484002\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.62165584155103\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:48.19585773345286\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.68872025213296\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.27194222841938\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.21104539140555\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.25917731278331\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:47.883777855840414\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-71.33374169081381\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-270.984995336961\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-108.62143781825817\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2848.7908386451413\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:27.30713266383202\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.4941432188588668\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.05590904388397\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.2337685805592\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.45912344668022\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:77.1718437414267\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.53026142817393\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.65857787316385\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.95201467208922\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9234084632098\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.92013149002202\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.96506300716536\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.94598888439678\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.88083683439274\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.7978527491444\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.81950781409246\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.80640379282507\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.79739110436\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.75704247867901\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.79834294333244\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.74787379546463\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:61.53876141148162\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:61.84941988476531\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:59.23653883555679\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:58.02620792654296\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.597810206167146\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:48.82117471091855\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.64466398976702\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.67767848582591\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:50.600368444719024\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.77848218948271\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:48.51674671461724\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:58.63658418046667\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:39.64567890873661\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.70617422971132\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:69.42251185153393\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:20.96077184023305\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:27.130433515454023\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94816682355624\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94798022673015\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94797103474514\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94459991064289\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.9477331046517\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.92938471422879\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94814105358905\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94568675836302\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.9480670667991\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.75559249470983\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94329690332015\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807008460715\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94759503934588\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94813327774276\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94806495903043\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94798098764052\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94806028906054\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94799598802535\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.50517443542856\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.06482868895839\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:75.86242572130698\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.83736311503993\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.93381052379114\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:76.73235310878607\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.565032959266205\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.46346241374293\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:48.76757509818549\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.30514096895524\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.30647978428649\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.139570549189145\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-44763.67528786144\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-50142.895934936845\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-28471.964519882506\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-13300.545942811535\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-49727.95550081089\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-12615.979554767773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-33.10811221599579\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-145.60249741853366\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-559.916934998041\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:15.077973544080958\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1270.6530239001515\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-770.7804369964028\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.9454617091081\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.66676356467888\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.15129153349439\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.73911611563207\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:60.10001945339432\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:59.744562291143154\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.176186703562365\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.55267943771242\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.876249356461\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.602972272416565\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.726451034376566\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:51.092629681265755\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.244687657671186\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.85449060619207\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.56994754896801\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:46.515587807417944\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.794967932880546\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:47.66665629490659\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.27310671898044\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.482811376393734\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.723219531999966\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.295406112099506\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.07042631405936\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.0275541237013\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-15041.874539185173\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-10451.307270825613\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-50634.5807671453\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-41551.701023411435\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-104490.01024819622\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-39461.446404212846\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-948.578333929827\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-79.8446050608036\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-651.2958501247649\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-530.502324032915\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-96.37136482835473\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-769.823829821473\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.54346354229419\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.43207065372415\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.76838649315003\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.43251372332458\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.46856178328031\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.1580730853727\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.83948983962466\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.19123393508559\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.525024130705596\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.69122601982713\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.85648385989\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:69.13780448525276\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:49.638852554573795\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.80848593433909\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.6145798797162\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.236695082310725\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.739426673092744\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.91374022268798\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.61142588545948\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.32789033593228\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.2431557381583\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.95194609218972\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.26023288228505\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.38783270440015\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-39996.303368516565\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-46903.10560599193\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-40869.94590345943\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-21220.785763848005\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-50048.30487336203\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-52757.034002654276\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-194.22215507949213\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-494.0359308411513\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-307.99751833163447\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-299.6418020310037\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-147.4736021389822\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-232.21997011356038\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.19949810546247\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.19547180231393\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.86863754141321\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.90645149347817\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.48190806426807\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.50514700856145\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.04241529640201\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.25549794798108\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.51488207466166\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.64725816165303\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.76784881115711\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.87036838566252\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.902585814924954\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.815452106608184\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.32689363434853\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.533747182737734\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.77244722197923\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.74882203977558\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.42129786104152\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.496683270473056\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.52247414841273\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.09986287488113\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.14982407453776\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.45711309318352\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1508.7311062313045\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5315.685107334098\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-10946.81821271507\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2571.913980629803\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7432.999138347364\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-7156.385805627509\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:16.595858462313384\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:22.781377518806423\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:61.4440822056469\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-40.006253125631886\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-7.795674599842162\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:45.02941490253001\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.94425680113177\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.22084931823755\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.07202295039562\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.0259256269915\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:77.13086939496822\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.9862724369769\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.02322812696627\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.82481919032932\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.49515840500429\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.51244397685694\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.08891353344617\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.19785187355264\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.48108831964802\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.68732220623745\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.428363929074806\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.385283113524046\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:59.55289987930874\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.651569198097796\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.62250686614789\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.1216774287012\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:52.314845667572186\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.27882678663524\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.92203555227945\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.60676540881748\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-480.6966628306864\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1344.2207885784273\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-283.2229823930889\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-263.6652276871052\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-50.39880183665559\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-249.92023671678524\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.97187697840451\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:73.56960075966855\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.09185539821267\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.62508663838074\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:3.0799832937753124\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:74.6319296465228\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.95764297336176\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.95380122855106\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.94368735836471\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.9601520564821\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.79496017659716\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.93827937117142\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.00359592341925\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.96694250859267\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.9427854365209\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.01594670684061\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.94095109300974\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.95362732295825\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.81283771411653\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.88401468805058\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:68.30104151116853\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:66.34899443463136\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:70.28106275543723\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:69.45090812724158\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.69887307001508\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.894398080212945\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:51.2925616246072\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.654604590300494\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.99588042511138\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.97411450310379\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:59.71157804448555\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:21.53560598597365\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-26.27311395415177\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94523768503898\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-46.98772881329765\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1646.588465338903\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94819508057303\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.9484721646711\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:49.00393141734497\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.93203894334857\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.9482987992307\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:67.84035074513572\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.88059698323549\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94807513620648\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.93988061543052\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.9480706200626\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807837712098\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94806707384456\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94811143327455\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94862292121019\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94806505179574\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94588505066314\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94811201628688\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.9474521678578\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:77.96306852354039\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.08011689108126\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.23579661589235\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.8168252079951\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.01908028375877\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.55103875817606\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:51.565155775746405\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.081028320488265\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.00487116510539\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.38970421415505\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.28138344447804\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.17819963236485\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-50446.98016446251\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-37048.426055382144\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-18003.20149820747\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-40691.90143039604\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-2614.8447638332045\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-2879.2517743963626\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:18.458476270438183\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-420.1766460405925\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-535.8677389139824\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-295.9885976744788\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:6.034316370297466\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1.4246357342124094\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:62.76837833008493\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.456443909540994\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.95799439671685\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.99858033035312\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.204904254446646\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.41246275956045\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.40630935009208\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.208825373093\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.87064600620239\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.5529773771481\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.83429911965174\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:49.06023149184114\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.31641505586118\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.0980953816075\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.145346740664365\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.25815195336621\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.2671576635259\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.81579014229154\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.25782187922414\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.550123364684424\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.874221827456154\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.46443391671747\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.60425586748936\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.654392586752394\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-40275.223930620414\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-22558.506419660538\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-30472.576939167237\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-66072.68830202433\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-27695.779211075875\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-19358.584370023156\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-490.56978263283827\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-364.7168243654701\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-858.6475095920811\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-102.06933325439853\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-860.0236599608797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-402.10229612129524\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.67599997814477\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.49678380170894\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.03580172443316\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.765197762079\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.97297455265918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.87234595547143\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:61.86178283541337\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.7463258596811\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.55065658116688\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.89984945710998\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.54688506244064\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:67.31295900329819\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.803095379455335\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.343505943286495\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:51.87237468482802\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.487810330763395\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.39154325641393\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.59287865125406\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.42473888365513\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.66312159818632\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.91792577034534\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.477792591373216\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.15177865885345\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.78673155429656\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-54006.429254097486\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-20100.17256560149\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19059.545216248487\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-36392.71405357559\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-48751.010252567045\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-45356.4643549487\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-173.5636575096136\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-270.6262894649971\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-502.3469039264676\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-161.41738226509545\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-253.4991597171089\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-442.1081421880669\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.63224567053729\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.71181734172822\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.41629466754982\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.83846535553042\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.99966591887815\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.03217324335054\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.19314875454297\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:78.33220187583431\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.08811167641076\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:78.33336294049631\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.63832871654637\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.17327329882775\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.222086579494125\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.95175705044593\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.24627612358277\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.022672776893145\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:51.5660181283434\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.649752542940156\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.950174541103266\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:48.73689309590393\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.997462779113256\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.89023277340817\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.25863468273593\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.763927601747525\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-6326.695039837824\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5496.042619679648\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-14389.181938473874\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-10034.307704524228\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7367.419710752999\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-8402.202197526552\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:14.349643163929038\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-10.644358288499657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-46.77407083030383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:54.329508857712014\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-16.74618908887402\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:41.514660787920576\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.13477905572542\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.0145624735113\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.00895578068386\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.86400167626411\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.64282369604254\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.88418686202044\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.16560597737724\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.9660834607597\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.79779122578431\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.42904011920459\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.37369623073356\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.2794430560254\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.61465270396899\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.63462219648563\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.515644980907155\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:58.387742512415386\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.0875631553907\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.95371762053105\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.30519381456129\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.64193836509759\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.17630781950775\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.93586680616882\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.6587278678708\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.60951808868806\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2520.321861038629\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-976.805735573795\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-70.03351418966378\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-333.89580811544886\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-988.3015307222792\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-792.2649400078283\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.61850402635135\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.53261550399053\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.98079063913032\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.4763688047727\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.02783674025179\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.16324524808061\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.93178294163413\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.95445668941599\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.9660521342681\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.94944964796657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.9367420152006\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.9512726506255\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.06785868762327\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.95548405696127\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.02139879219452\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.03033339282112\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.0046880129663\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.05747799917035\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.79201488919011\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:68.6587018990512\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.61919610211706\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.47256389748777\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:68.28184818733011\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.305249408627226\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.47007493962445\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:51.27932943471241\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.37481733152043\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:49.39770875799553\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.33732786698309\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.71166582449014\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:77.09387962605842\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:54.26602070495028\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:76.99203325877329\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-13.500455423449797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.9554534984255\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-172.11824626411575\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94713315031865\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94823155730047\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:35.98964988621696\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-60.08191815598731\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94830438863394\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:74.94322026781062\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94807605681409\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.39892377704969\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94806662293473\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94806077050073\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807876227313\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.97301459086984\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94802334028684\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94805409198582\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94809356949477\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94666081756189\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94761366521026\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94600821069791\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:77.5899583871577\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.12874832545049\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.43453285230765\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.84863072788744\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.1556731690282\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.13314740539442\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.278645935451486\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.58754893634805\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.64630249929978\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.70585199671527\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.09806159344173\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.571484817798165\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-2933.23376560136\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-47521.07494728503\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-10360.283494728395\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-41719.263954252776\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-10372.966102167224\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-57773.93610407932\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-122.12707759171045\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:3.5491204360416417\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-199.1010857624177\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-230.2106797272432\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-96.97468927331192\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-119.1521782941758\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:56.92977248665336\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.31674328756389\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:58.96107552160632\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:57.011629263242924\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.997608413774486\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:61.82549377364657\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.752724982721766\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.7908442194087\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.19423907303593\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.47037629724441\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.0339959547499\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:50.047698056353205\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.36461333027498\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.39228826721909\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.900128611439065\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.93936108847106\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.724209609066435\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.62302233972143\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.30470756170691\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.961573641621\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.234541060055115\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:48.80389253351283\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.48381818990664\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:54.61468420646809\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6930.261880680741\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-105651.95630661986\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-36241.299739534035\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-106652.18818219652\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-21555.553842248457\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-26575.070303232296\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-224.74478635851844\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-788.6112893257111\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:11.615950212035242\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-71.26702380706422\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-580.9537250616121\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-71.53959608247094\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:73.15737980148565\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.81415038497735\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.38706399099952\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.74976310742193\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.5931232366344\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.52505765675653\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.05084374090224\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.02842128085424\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.381162131978726\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.14909452488213\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:61.69427376133343\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.47011129101305\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.48240699768772\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.93231361492048\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.949501526735034\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:49.154667365030804\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.645729757827795\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.10010997380936\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:49.78481243746876\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.32567376939916\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.19091868455177\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.62063831494868\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.44455475980156\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.442143887169856\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-56434.15118165614\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-16393.98053269202\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-45071.2281055766\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-40664.59818029141\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-42482.990262262276\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-48967.27992810068\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-196.15027096630365\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-437.58085687109764\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-159.73771482682585\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:46.954864756717186\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-60.57088722667891\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-317.58314005684156\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.10999277654457\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.84410455477718\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.36495457196254\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.28931369341856\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.98204700781474\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.55009917380586\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.30601972303963\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.94361730158282\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.1865329348825\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:76.29925048637803\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.99137843239956\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.94152596470781\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.12973240934389\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.10623443147815\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:51.82982248050829\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.53332275876715\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.50066545598613\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.677921735921586\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.68374419175941\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.634520218891836\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.2290597325756\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.75130843676457\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.92350212352349\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.40845480292356\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-16610.22001898505\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10258.225131354244\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-12623.375385140132\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-11350.544471680603\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3592.2221485134933\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9865.170534583318\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:18.66519495938781\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:51.949718037959244\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-68.7316376078871\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:23.069346646233\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:40.83560591518081\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-94.83537437222526\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.77566600278008\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.03435554384151\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.9473392090711\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.99837078486398\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.78383718192624\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.18737113419436\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:76.94256755430177\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.38768075327876\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:75.6688925485333\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.22034889050973\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.90485005624375\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.15575380692621\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.55171887866031\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.185681823602906\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:58.82827028077333\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:60.83803938729637\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.419219254370745\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.79518641365311\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:47.59560816307017\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.82312482029459\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:52.044572737258754\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.140669063485156\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.69585824895788\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.07397889267797\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-914.2292180523523\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-22857.124510179645\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-395.6918331654266\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-47.31629373897617\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-872.0841208624032\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-78.09921457036637\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.1212364017165\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.95602750233348\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.67483591582477\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.82589008377893\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.38374666119299\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:73.66118929910321\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.95789249324724\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.94317763296988\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.93896774610634\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.9499509281958\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95823652806293\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.94321522288101\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.02141863398893\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.00254383802978\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.02195082502726\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.94378971137617\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.03058081080916\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.99876699194465\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:67.8595742488161\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.153377885308615\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:60.642011619816614\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.65451600891667\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:62.126558097380304\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.99035669467503\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.99850402391972\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.254755530714796\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.33649091366781\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.4328585674882\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.12746722126707\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.53017771447193\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.95060155821936\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:27.089413176191613\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-152.97851216802454\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94974295072804\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:48.95402605464084\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-191.96926959393247\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.95538636452575\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94786802063409\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94839643999946\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.82223040067464\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.9486205140092\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.92316595826026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94806732513287\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.9480773085586\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807980735064\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94808529107189\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.9521080667903\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807682242141\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94807063650202\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94808334769743\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9491398717307\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94923181271722\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94803758856817\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94941188955139\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.22017492249408\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.11000624493974\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.25145460283596\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.14397385873787\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.28138675085667\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.87259848358313\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.09010329167376\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.65075558371156\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.32779121771749\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:59.78087247639215\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.81883217488879\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:52.29458089204544\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-17727.99487666317\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-24943.8393057379\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-73629.9816065834\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-23526.823793348125\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11124.08099197045\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-11807.45749300723\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-441.2587926648939\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-339.9843155633191\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:20.921971217396695\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-452.54687232892286\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-79.31082710400634\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-234.1600409190048\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:62.86384759014334\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.455561761679014\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:62.42457808702127\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.44180124119758\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:63.79908024090495\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.88839499308332\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.02560333870028\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.6282613154257\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.53757666121255\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.91818463641467\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.7987703267071\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.51365027656827\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.25546488390136\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.95676693737718\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.59856418009709\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.67362642081541\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:50.19767056105524\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.801701876874276\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.253020681892906\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.40496621997197\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.70922455068905\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.084480406286396\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.70786887116678\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.376285117386686\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-26414.773963284923\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-36324.3135931738\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-57647.300254875896\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-42153.35865020752\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-27077.625761903862\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-10195.814471774633\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-70.40161260288471\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-49.33348641421871\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-495.6301279571509\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-532.9063696688419\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-226.16852472578103\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-181.6337246233502\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.17983025361742\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:78.67174249309738\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:75.51277091270173\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.57967419066327\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.42991006519966\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:77.66163914432856\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.67496991737609\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:68.28307494157126\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.57926445139075\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:60.27140488174367\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:60.87764554823638\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.27057462738397\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.74944967263979\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.6588113066998\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:51.63249546182001\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.39650972162859\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.36529406333317\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:49.74730806828861\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.90554956198796\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.528601690334206\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.38683457365532\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.68478664052449\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.74919889960071\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.101734053998186\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-37566.45383707082\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-46520.60005903432\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-36121.69866644556\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-57724.67842342536\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-68313.63887696683\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-31308.610893291596\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-381.6340124165571\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-193.1205845517939\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-208.18260986566358\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-121.00288659404637\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-357.7851015484361\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-416.453293893542\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.82265620752054\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.18815173193448\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.0492935117255\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.18810027988057\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.77862037815758\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.41548387998667\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.33869848033403\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.8476624477323\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.55008822653686\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:78.03775858136966\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:78.22605557534243\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:78.02544549823841\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.88568976675319\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.92459553891722\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.423345941565834\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.897804505436135\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.12666948243001\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.89278685303303\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.10645789638973\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.99942459965416\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.339299621135346\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.16124055618559\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.40068514420819\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.18989389532131\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-17851.149836217824\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-11938.922556673475\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1593.1549710303052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-19428.74856697846\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13424.904891944854\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-16723.660177607722\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-16.24574383193813\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-0.16523690745997577\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-32.124961991306364\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-16.660217040161896\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:73.68876312171689\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-85.26025479285148\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.14336323188552\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.9457533427164\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.25841588087209\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.88807904767276\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.7334316850554\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.09048657411661\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.06273569071547\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.81604707929166\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.92768655488396\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.07350932537241\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.36052857598891\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.33187129745998\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.90107132388766\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.12094824280298\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.47373201642141\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.311723962972216\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:52.918939771522574\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.02520418049691\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.70831014608144\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.76494912178475\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.35306255674391\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.327259073927834\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.876225522335496\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.09272184807416\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-678.3417049029194\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-24991.810309708446\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-688.7301119600721\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-246.59541716624474\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-4573.168655377472\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-843.067664889673\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.40160146052673\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:75.11232213958968\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.06590601550583\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.3226999977238\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.00917432888743\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:73.54442114619593\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.92517182599661\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.9415137780004\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.96670689058642\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.92489995084661\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.94223305669894\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.93695740919586\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.97786549539242\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.95430551954288\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.00540911409213\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.04346619129556\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.93000959307308\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.03512228549795\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.59361971729825\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:69.86216346551998\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:67.92514456760424\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.41223484285945\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.45507527382897\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.30274388910959\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.390507838372486\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.36248158377584\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:48.90561358352949\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.13360041486785\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.60475994508575\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:49.31813031200164\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-30587.50131259855\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-155.14577109575086\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-506.68718767880074\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.95099520251166\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:29.680420067293422\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-211.9717626143291\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-28.74873503161941\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94825830189049\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-388.77667746645335\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94758807137973\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.74395602645603\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:38.73505887551229\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94806392921811\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94807625878411\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807592529871\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94806723589029\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807681772444\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94807360499182\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94810812601524\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94765950360103\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9480908264599\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94812304068024\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94589545329413\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94673277349618\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.17156762002114\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.3623377394028\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.34791547381755\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.14197841594311\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.9734882139333\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.40497618830278\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:52.82218123927795\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.540474917396175\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.72818000900865\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.69728343616187\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.3343527817745\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.84388265714719\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-22840.392841552544\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-35520.12497794449\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-32536.465424116057\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-21751.819934236242\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11736.349363417208\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-71262.7023172341\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-23.829392066050747\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1290.6257422022973\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-358.62847777498905\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-278.74040721531827\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-250.93718726302433\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-26.8008146068071\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:66.94197839931817\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.76385621438823\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:61.89004581765081\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.70754335666848\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:65.702548697356\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.76576617648979\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.51743881093518\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.151265064640434\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.824692427360525\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.68690255311903\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.806741914422005\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.20664203176355\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.566822907178825\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.60058187369853\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.04493554277012\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.244962060991725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.88538970893954\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.07757603206837\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.255980382298425\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.795361624935225\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.35129787156416\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.46170933221718\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.74903248406366\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.94947816034041\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-62090.53025471121\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-61915.55827060396\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-75591.2048082825\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-66197.73517605638\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-43867.119888586734\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-49032.42492983903\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-87.23417498447279\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1605.0306158332585\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1142.9706828438268\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-262.45350988480493\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1914.2362934289906\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-251.14177692772554\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.50499766050501\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.610963521697\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.69503799426076\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.5762194274353\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:78.58804352904419\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.30594538843849\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.5468761458394\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:74.5681189752123\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:72.75244492576572\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.21190367243344\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:73.50041097143065\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:72.41751211537584\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.25242289700864\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.059728159537656\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.813315390618754\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.61796906518832\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.04704153289397\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.8758268411043\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.43267199961017\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.33013856993405\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.93657489766208\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.72129678874738\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.49764100910173\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:47.7829202786499\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-83951.07654191265\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-137130.88156222546\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-29934.326907835013\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-43467.66952382382\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-45369.888729312646\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-56832.04917907715\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-600.3799831049944\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-381.0895238268366\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-56.291922562887024\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:48.71943293827739\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1207.7747080483898\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-97.46242748460404\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:75.47310714039679\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.01269763877207\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.58545211415483\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.07723082774638\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.81963298619499\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.20615111616674\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.265906278499\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.5014635083993\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:71.78348193401611\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.38113687013058\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:72.04994667318508\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.21507200276973\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.42480920380828\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.54189246703876\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.98415765394673\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.34121636234788\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.78012884912573\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.91802138887445\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.72551967590531\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.90769681279307\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.347963487789606\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.10324353091214\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.59338326766276\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.67032367130777\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-20323.2141724715\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-19143.73442377041\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-9174.122576642168\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9968.693450194252\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4545.592951492779\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-15147.01968614655\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-91.01419980550396\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-180.51097344187323\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-70.58534860798842\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-115.85393121995918\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-62.24559429971321\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-247.28075457521084\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.33625883516878\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.11227150344774\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.00271121012685\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.61413715475652\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.7852147749036\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.60723584810518\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.78094112579517\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.50333497921625\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.64450205039377\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.58784734117788\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.33747572047302\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.51820064182823\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.962332303941814\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:62.815760524167\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.69337290034602\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:61.717103399377436\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:61.51978076869362\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:60.228391818796155\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.67170034063182\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.714393325390745\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.813025206650345\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.871104742465654\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.23835641808567\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.812541282886215\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-140043.87512688\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2835.719323966144\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-388.1874688691845\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-498.69082480363716\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-7600.063474127587\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3401.257153023313\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.1874622956705\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.21966203128945\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:57.42634640048112\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.55055389994237\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:71.10397579916075\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-349.0399446893245\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.95136060152963\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.96500311365646\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.88897663538056\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.9472481605103\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95353405272706\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.94837936413768\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.92931902758525\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.93640754871522\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.01857732601576\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.98049131895351\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.02509215420113\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.98483604958342\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:72.27767887396827\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.59737587723092\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.97348019438432\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:72.47622643015438\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:69.27294110096962\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:73.14731437254953\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.797034039377124\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.89053544703022\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.74392395450713\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.53703671916614\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.28051754176453\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.16234059430735\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-270.59648014411295\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:76.86029724289433\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-390.8360839359774\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.94831920290106\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:5.8100545566038715\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-586.9050437019414\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94851731201905\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94827140645778\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.94683920407127\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.62412183692457\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.46259556049621\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94887730716438\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808575372419\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94806085974331\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.94807113673012\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.9460820207641\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807702673994\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94789507287614\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.94810356231446\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94811157829372\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94810249962329\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.93621103011125\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94806163004762\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94794674843574\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.99571630152029\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.95004427475287\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.05275501741772\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.05961008408673\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.01101196361772\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.06218807245448\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.45809947375218\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.33737799443945\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.65697528869853\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.19579429633275\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.15722915496446\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.34613414081746\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-63027.69622757643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-71454.12367714776\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-134846.56372235648\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-15649.31065527072\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-65975.25642870729\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-41049.29534398823\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-401.29086636388456\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-429.67029961664156\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-247.98914352395198\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-847.9726961600301\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-933.0499612223548\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-696.6214423812779\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:62.41582183532821\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:56.44566882563162\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.348924999353535\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.243841908185196\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:54.642845753659586\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.18550225633208\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.16150581260146\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.333177277928414\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.34842959080417\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.180772003661204\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.070100461226026\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.45392990920186\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.89280007999182\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.86673492743943\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.008499124946795\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.58855550319919\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.46475918436022\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.823720802029726\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.998139794513556\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.029192845992476\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.758722525556735\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.1456929777343\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.707096500036\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.91555454675916\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-79870.9539614107\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-69618.27705321676\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-45561.59960233479\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-39551.642661136\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-80927.1365629396\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-65831.13202379856\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1319.1344942700873\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-383.5224743618375\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-492.03933871947845\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:23.14870989726603\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:22.44469477399491\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1216.4861017273017\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.47516217571811\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.42041701994326\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.44688311402398\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.39018666396656\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.0705465171354\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.68400695602945\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:70.55076382837021\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.58647967804549\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:70.30735358513651\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:73.6845561343563\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:71.09842544657869\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:73.68505850399076\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.27549231036546\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.128602993439\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.124023940223374\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.65357965492799\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.00569783747078\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.33466037541887\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.9265416527917\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.22776400360114\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.30800850830908\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:50.16029713348058\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.29123380346923\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.95260589176436\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-90106.2668226947\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-83921.95332664688\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-87711.43277441074\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-81421.53727581786\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-36944.0308601674\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7075.5295219902355\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-523.8859704200257\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-983.3602229096554\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-711.0447912680248\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-405.30196457420215\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-736.1575450175761\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-512.7177836671414\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:73.07615681508098\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.42345712436665\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:74.11450714084273\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.47805708501167\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:73.45014331353002\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.8218088528131\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:71.87126017020762\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:72.13065686002315\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.11303228616622\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.2173803243419\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.65843884807764\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.01708028983937\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.75470883289016\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.53688732958548\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.70862365228699\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.22006150206494\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:58.230575326745026\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.37782204986923\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.97865010598944\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.7268271838998\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.13388730797086\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.954637098919456\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.29654987200425\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.52038241160184\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-38494.9644084236\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-12643.13420084539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-40268.445483599244\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1358.0912849300014\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-33237.13731296049\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-27907.690212649562\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-3.5893729392518336\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:17.43757743549873\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-60.465967429726966\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-263.46877152944194\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-206.34059796096585\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-197.3839397783633\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.74793745702979\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.91824343892137\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.9932578982003\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.20224704208854\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.51325750764286\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.65021039539664\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.61460615247135\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.59708560903398\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.2711030158403\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.68201217043578\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.47913909660633\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.80790256176341\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.61940648659794\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.99362309715344\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.86736266283279\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.01765449537689\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.0343913990649\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.49931711522118\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.708479521568584\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.71788550991421\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.86595365654022\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.51265634170097\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.25251393991841\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.645113114555286\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1023.6383366340535\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-58611.752629298884\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-136.16562798983284\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2694.290752726526\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-7838.763267886836\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-623.0281003165941\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.50050605987357\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:39.94260860109442\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.37692944002113\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-348.8109536486596\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.69523380495977\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.60461761896961\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.96418994942267\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.95421447567907\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.94225930106086\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.9614055482678\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95495488842798\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.98410128025299\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.98288847251236\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.99175337292812\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.93001395773945\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.98869147668962\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.9582228827561\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.00450057244564\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.84042996685977\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:73.80433965348136\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:73.57331983131556\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:73.00734121596089\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.88692824108051\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.58324337355539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:51.9742312749196\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.43135807270418\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.10068966154746\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.939538422261556\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.883525058685834\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.98266294462366\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.90036584299507\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-5919.542802911372\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-302.3527699253331\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:37.39794782994769\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-691.4500038862417\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:75.07910161059705\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.9499533753211\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94857919939491\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.83459342324518\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:73.33707348674747\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-39.272900056049906\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94767765213506\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94272656577887\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.95185703447807\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.91770886416694\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:77.02189138125397\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.87892864969793\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94806939649995\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.95015112394607\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.95550824463415\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94783732764733\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94810187786089\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.92910480607298\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94808232610482\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.97752276985922\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.14522319285886\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.01416184540054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.06813971424685\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.0350502855295\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.098942143436\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.74466419160671\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:60.548134604021264\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.071165056281245\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.44545222715518\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.697359561673565\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.13614872926398\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-8954.929005282427\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-17256.213858448868\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-53665.72963550769\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-75159.34818439168\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11813.309881948317\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-116839.64818006805\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-136.76805121866713\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-580.5708659056887\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-446.28946175248353\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-556.2810629347914\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-203.59736495923585\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-108.80876602480222\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:63.76334012341462\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:62.73568722032674\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:61.32393299188785\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:63.80964789108041\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:60.57878204550187\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:59.424625328904156\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.68382898967059\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:50.60667123284463\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.81976860793933\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.72541864473488\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.49492095498012\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.03994603220217\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:46.791047201593905\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.52882961426049\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.52746724283912\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.521743878240756\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.4966935992323\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.18300867016692\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.437560870870655\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.76257857619553\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.325804213395124\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.998363070192894\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.14574893110727\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.32398998831862\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-35995.29273075978\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-94780.73718023638\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-39946.25989374351\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-66645.12205018688\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-59905.629161627294\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-97311.8136394672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-280.7306682434112\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:47.42414380641694\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-915.7252680724582\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1705.9928645666798\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-343.38412708401023\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1930.458008405775\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.14515210099817\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.86302108413314\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.88140839056484\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.25253099329929\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.8436876856689\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:72.3337726120032\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:68.45746497004208\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.99170893739537\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:73.62005686471085\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.07305344501238\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:72.30576297592657\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:69.6766258552054\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.65041133370969\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.0743476664332\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.23329530374225\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.724495952016866\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.0157827011231\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.51546870951722\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.81448860086613\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.16467148950359\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.43664335957938\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.31602761595031\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.481617624020835\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.41483934810773\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-112754.51558265656\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-70981.99165064674\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-127967.44602299563\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-110184.76752904196\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-104377.50287548213\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-61697.19657837828\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-878.052063961495\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1144.98852565591\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-856.0896096922827\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-498.43809594311426\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-273.551407773444\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-883.1390829890425\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:75.92065079274188\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.28127127956273\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:74.212279158422\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.71467865434005\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.33802459595051\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:74.36710822244062\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.05948296514573\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.94459317435515\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:73.34454801253581\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.48478829879474\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.75993889429326\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.45193773879133\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.35928717397676\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.04308333400259\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:58.40574380471257\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.7634611979855\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.17837087703769\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.9062899139756\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.832952081851836\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.095301101534645\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.67753079930766\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.04215790762899\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.07506868495351\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.38956941425261\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-23538.227383107816\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-18713.428510240537\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-7340.90590924142\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-12377.171116311125\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6449.195522882508\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-37102.36125653705\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-81.69621410475088\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-249.96421644310018\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:6.120978113795195\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-151.51727076023934\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-39.86903424334394\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-80.14300782629785\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.65390350200512\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.06845938173028\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:76.90881209828142\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:77.08592474977269\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.69998778425115\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.19696331343565\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.27558269944127\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.66673302114995\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.40529731732123\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.70327609692906\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.58699274960233\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.31724370174092\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:64.44939289145155\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.62101018129369\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.70694858486301\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:63.3292404300672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:61.06171254721786\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.93194323675992\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.05673399298114\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.167599798009164\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.14573145570883\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.58718455638046\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.74516373235729\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.123527533149414\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1355.8102700163568\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-36065.8282334829\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2217.2664813679726\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-74813.39059864281\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3501.6665502455035\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4350.079391545625\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:74.37371775989368\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:68.20879998969882\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:68.65793748386643\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:74.71008921721678\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:58.618422264748425\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:73.60383290019534\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.96256430201684\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.97251461874885\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.93706408694938\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.9581544108049\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.95644700780828\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.94986227979051\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.97887580938655\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.984592262359\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.00476716525729\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.01987543967505\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.92833053751006\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.00950336665315\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:71.43112753537741\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.03386171827925\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:70.94531754593947\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:76.02418182877173\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.91894088021478\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:75.87609949563553\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.21301079147487\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.40376786668062\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.31310201646764\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.900172551361436\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.533132744026844\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.15875129596608\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:76.91881301555227\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:77.09571358911441\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-74.13518934197272\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-152.3171008525635\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-165.08440125918557\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:39.73265314214901\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.94634602143128\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94851254928385\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.98479403352249\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.84801130242194\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94963608509542\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.94727803328735\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.94808015492697\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.9479815113535\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.73970920960672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.94535820948222\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94805668882726\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94806659005589\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.89605321738078\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94809634540849\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.94810716548334\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94809386540436\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94808261203335\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.93646577420998\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.98093782420511\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.94817994280159\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.02582663525457\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:76.9613551215171\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.9510912709672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.00305783532566\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.342823802039234\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.0108555387544\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.78497912924387\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.82872154135654\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.37528194911585\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.48659810272374\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-51690.26104857172\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-174183.56893117077\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-10694.206629783925\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-55055.07206928081\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-10954.521457673622\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-53708.56754251876\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-127.67192946821804\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-551.3225577072988\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-123.70861708131523\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1142.4727218840608\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-230.13990978446884\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1313.2735025774691\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:58.60443404744326\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.71775595721671\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.88267130791625\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:66.16118565888694\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:63.80568099031305\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.16164899877528\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.49203296870557\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.69030105840294\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.1480705731668\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.33248457120594\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.36384467902711\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.25171786020646\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.63138608762464\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.56174465490783\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.74505936826446\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.07798002552244\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.376674655786736\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.154423518465954\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.93995657069439\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.160444692152986\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.42409436861486\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.600632110456495\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.151578942529554\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.30332376432463\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-63100.13655714391\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-44814.19984416946\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-76508.72634439792\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-133938.84163428892\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-59286.289807282825\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-67637.74536229006\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-28.170169682085657\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2094.691493400351\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:34.38574468835871\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1751.57069387729\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1306.2837345591674\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-325.52288035128976\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.14149257660476\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.32034642326259\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.82931261977595\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.37115589782326\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.01592398225274\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.67153133850007\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:74.10211315557619\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:74.08367589679735\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:70.29045431275094\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:70.92516147175627\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:74.1260144122714\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:71.29603103272927\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.48702154906248\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.372611549118545\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.728724702006716\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:50.373480849443595\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.565651451583165\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.39683305369976\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.21627592714613\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.125410795012165\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.493497089044695\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.62136248233353\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.20793064924396\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.31689240990707\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-52102.48361757367\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-108502.6326950936\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-5901.228764416009\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-134858.9156697922\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-55174.73493294982\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-34525.77795384905\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-701.7711396241771\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1136.9864413830312\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-906.3314303156895\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-668.1197411859947\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-703.6174209405343\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1020.0636055076848\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:73.39702499391902\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.74872913827475\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.06327370971653\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:73.8870265917857\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.4912861388344\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.97778663313981\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:73.32981925008568\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.75562598979594\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:71.72948376072308\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:72.66169846868121\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:72.07054105022932\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:74.0308314168472\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.53730519470546\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.1168060845294\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.5239312554364\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.66551336872121\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.98298508895545\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.548502465406216\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.764298117241815\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.9624988257744\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.48128316926912\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.68880234235991\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:49.262786171068065\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.24369594914335\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-19203.24502528606\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-30746.874769096583\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-21454.55575233562\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9660.247886753908\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-37671.01252516299\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-7500.201060623517\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-133.62869352125765\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:32.15770533086748\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-38.19983959010118\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-102.20426494817833\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-104.58026318403566\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:19.50869967939348\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:76.94954409009364\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.59262913221258\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.08135646473619\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.66542953727186\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:76.77428423418972\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.05925810139793\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.23553296915418\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.73061738392798\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.56783616434785\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.88662774249077\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.53108468896014\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.40049124750404\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.56202872644103\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.00810262970656\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.74040361075208\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:63.17633472154045\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.88143114911185\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:62.88417704532567\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.21750268256153\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.05589039858587\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.75585111255858\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.07990155216098\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.52275023396275\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.773769231488195\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3737.5949642430905\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-980.2278331549173\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-576.3364247772241\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1187.0165411556115\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2006.255642986373\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1315.920173811856\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:71.71699688883632\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:59.2423936999436\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.7129019831371\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.47452042551845\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.70316168677628\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.40752255024171\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:76.94991297192044\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:76.95304057887448\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:76.81232888084213\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:76.91954634056212\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:76.93982560442977\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:76.95332383480103\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.97042770055545\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:76.95766490002708\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.00568062463927\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:76.95795238734325\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.00051798993815\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.92197040427942\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.23852275502173\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:73.73087310222681\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.9586717726632\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:72.4339056833463\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:73.3690113466236\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.41212723349565\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.59004503170615\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.16641352486548\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.26418610817809\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.85440869746634\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:52.864780248024616\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.73577772172489\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:32.17333184160333\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:75.76422158707963\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:15.753681853213964\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:46.59622431365029\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-78.2125287397909\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-350.0703712445342\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.9476304756928\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.94763167811905\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:75.99213080109341\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.94894865425296\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.94775398976226\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:56.15003744009633\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:76.80067013247545\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:76.94817140076083\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:76.98483528162758\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:76.9480697840006\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:76.94807176612511\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:76.94806912642375\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:76.96539353699643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:76.94806876475647\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:76.9480368352904\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:76.94805385948543\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:76.94810989325303\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:76.94524554954072\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:77.08322157227589\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.98461504622273\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.10070027210189\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.09439089206187\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.95217002462083\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:76.95990425862601\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.003445549478336\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.22782251750207\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.91713288418474\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.633040405451744\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.48574065295517\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.265960681605186\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-789.8370606021865\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-659.8939213252987\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-10709.345492459921\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-7568.8166781426235\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-20241.57979858495\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-970.0517144890824\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:57.64932966871088\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:22.88252155643641\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-27.299047136419485\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:66.41191153004003\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-58.34117901428559\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:9.558512687307353\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.599830817668995\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.45006696989068\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.86257237988583\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.46284798649562\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:68.28214835707271\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.61136518246175\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:45.20484547301763\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:50.596364196668794\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.84695997867672\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.79544787260375\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:46.51944676988043\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.66454794319527\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.46438769851734\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.69511185289369\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.281266136689396\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.98953521040315\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.31182401573875\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:42.03231431209168\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.11994444594152\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.711894752614796\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.21774378632636\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:55.25840430500659\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.61727386583861\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.7469710629225\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2952.807791839912\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-447.37739292442376\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-450.3266759891976\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3149.1238482079234\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1368.4522822675412\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-674.6866344935881\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:71.7857582302334\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:72.68333043330668\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:60.68779891921932\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:53.909134319957744\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:16.95277105644052\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:51.366981725414696\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:69.91368354635036\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.34069777775036\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:73.82500329479822\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.4248819029923\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.96348081619557\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:74.91156507233543\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:61.7199970522295\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:49.95756487078066\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:67.43477267294628\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.92936031940747\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:60.009045738042865\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.877600799920145\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.60446375404127\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.56399282512465\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:47.575539604146435\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:60.18484151438523\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.044974164525\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:46.78444700496135\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:47.84965870404356\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.51103526407852\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.39515536031895\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.80256420728538\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:41.44155921853368\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:46.96234119652386\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1271.023747148807\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1677.411755019985\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-431.89939238876696\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1598.1234184487587\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-770.2767963574757\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2664.7678258007586\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:73.26978372719645\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:65.66667625338567\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:73.96036258732079\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:72.03725959674124\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:68.72058081946287\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:73.22983752093603\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.05858553198026\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.11450094477786\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.30866144547038\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:75.5845174580883\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:77.41077718911347\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.92049306786089\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.29222346742479\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:74.95696728299038\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.79380597591025\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:73.4703757262211\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:75.2157181618813\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.24006755226141\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:50.145488156048316\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.1033696088385\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:50.18614680958373\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:59.787378589922845\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.490553477319615\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:49.87400004051631\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:43.99743599624875\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:46.661130878472534\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.554413201491414\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.91017609783886\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:58.84403604940695\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.620385379186295\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-33.48058508173324\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-809.9383850939354\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-478.1725112428056\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-894.1708329533666\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-476.5601585754923\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-994.8470029237235\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:76.97500586979402\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:76.52767504924296\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:77.2529975742313\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:77.87309966752434\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:73.88702701921063\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:77.11754555397845\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:77.82232597458541\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:78.29005451442877\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:78.5767005690446\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:78.9733851186115\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.66008720856375\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.76470746281957\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:73.74027203254761\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:73.4025848484866\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.35996588803916\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:75.38382185078494\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:74.08129681838226\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:75.03324829752376\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:51.00714178848351\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.161071634320784\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:51.53743520326226\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.32092599614198\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.671992800492795\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:47.18539793076621\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:44.98051323460442\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.772677756934016\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.179023743028054\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:46.28574263577484\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:59.864301835109714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:41.87968673905207\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:33.56789272539816\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:66.60709279648802\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:71.28672994338592\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-7.5681322667427775\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:65.02301337871145\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-7.273152909756075\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:80.29448495689013\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:79.20177760699116\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:78.47443041226543\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:77.82089264022731\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:79.77188300485213\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.6289368540025\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:80.0535928014698\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:80.60390931224616\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.00231498038328\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:81.04059734865928\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:80.38749622490765\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:80.64657850961595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.71050078930865\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.21979528829937\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.43723509929798\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.41130448120424\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.03667507122782\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.31395998369341\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:59.14543235954852\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:54.39243327805712\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.05350553092288\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:56.00804277439584\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.159012749403644\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:50.818705987963185\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.14854395114783\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.624060950192806\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.08563749948949\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.272451178965554\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.04420685333657\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.31685928898218\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-8315.677037400652\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:70.99883430486969\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-556.399658479683\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1.7353808250457403\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1694.0519211140086\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:73.69567635869116\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:87.43945915366459\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:79.71522345892362\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:81.46448619634359\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:81.10130800798805\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:81.19670741665166\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:82.66358542761716\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.28505295740516\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:83.46805255463782\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.15103410786772\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.36560780599044\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:86.10504726204842\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.22496172139924\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:79.15027173510492\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:78.70970738507144\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:79.02466915459779\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:78.72700392730223\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:79.20832344403503\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:78.78155238497811\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.67053273947245\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:75.3434662230847\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:75.64186712622737\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.52832418111856\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:73.70306669820286\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:74.90531885783629\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:44.71759327853919\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.166459540273614\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.30312912698052\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.75814127748271\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:51.88559766556449\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.26947470682168\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-9424.78561717004\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-8739.64632694133\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-20409.74992973021\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-10647.712066476039\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-209598.05204483162\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-246254.99833800647\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-997.1683142784544\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-84.90078731537618\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-62.50327017431283\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:5.933177339645512\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-297.7971419656812\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-499.80131854590127\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:64.07051728972306\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.98334991975362\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:64.98863388695429\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.33265918671755\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:51.12913649094748\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.69053544135803\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.445433928229804\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:42.677103728643075\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:42.797317095776066\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.91494887869972\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.137944986540276\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.50469022712152\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.76258210688711\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:46.07306856212886\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.61898660049182\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:46.225009459365154\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:40.61015122771921\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:45.89281194822069\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.10821590294741\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.8342802363108\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.47994721548776\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.54181585427143\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.47878881328401\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.52307309944202\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-24191.053304228844\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-15035.354662354863\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-23472.842929079558\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-25437.185548702688\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-76466.00947774612\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-114776.6534719625\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:47.416279605282305\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:44.553154035287164\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:33.09196898841407\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:21.08923574899294\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-109.91489852949611\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:68.98929631268537\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.88920763724427\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.40323226051692\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.11329635360093\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.3951053581809\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.32447563352503\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.10445167719612\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:58.17354651934183\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:62.60066011508118\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.54164539156312\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:51.11957554440502\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:48.808119323917786\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.5994337490922\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.02812639073746\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:44.338341856960994\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:44.47401879374393\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.46867270282725\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:59.4732919718169\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.44094354900626\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.18901450774089\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.458208126919395\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.31297243592587\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.48113387010527\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.75602836074371\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.16770387691621\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-5943.082713404446\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-345.9583066033979\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-29512.192321218216\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-11464.203265635773\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-11544.817305099692\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-319.38019881011746\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:47.25658747978901\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:66.31247366010156\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:66.8431594486402\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:67.24873665658578\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:66.66027460631842\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:48.420376534345486\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:75.9054303920767\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.43119620628673\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.73982571033721\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.75064767647015\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.95209902942979\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.52626783576324\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.60527859756193\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.2255904073317\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.2947327122151\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.87195774905788\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:70.68249610721642\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:69.56802371498915\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.516674970011714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.40800782321851\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:60.41088836037145\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:46.43266397176811\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.12436436084992\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.446077922956505\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.0941875945216\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.787218957493586\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.48594406672216\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.881789440651694\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.84048969358488\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.66496075615521\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-793.8068170449787\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1687.256771114701\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2749.1277395598618\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2811.49951042013\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2610.5704114416435\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6488.510626634338\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:72.65954066487727\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:66.99113329157667\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.47772517403436\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:70.75526699294623\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:69.44516943231918\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:71.96841628838938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:84.67421019236998\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.40556456255482\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:79.1069208354439\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:78.510816079411\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.83971015480769\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.58717498608327\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.12319404990585\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:74.75803563264152\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:75.70343969185771\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:73.22161027631768\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:73.44535755021447\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.39583245405915\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.26729998949524\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.568665573689024\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.432034440450174\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:50.24465650035299\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:45.87576028702295\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.43509101228888\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:41.782237624586614\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.17694077413555\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.52688774372281\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:43.36848597095838\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.4001369833641\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.62402291438586\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-7258.278133326201\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-37.13244816935655\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-55.74946865686006\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-71.75615158862631\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-65.92893653070016\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-830.5702447703355\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:73.63944499862767\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.80412370826055\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.24190133683224\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.29030716597705\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:73.08229530205213\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.31642444646668\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:83.60573450841709\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:82.28063131877059\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:80.70826779748626\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:89.72794337945251\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:88.38433649616978\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:79.89943871660623\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.35768265128605\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:79.80554678409094\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:78.61138164668311\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:79.0224860605055\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:79.35460974631862\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.68548831994183\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:52.949734139597446\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.854142876680996\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:56.01956306878182\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:59.81636355954705\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:67.6464254222957\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:61.047587357021115\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.353222161841884\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.787160963512854\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:60.60191990236676\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:40.27652301780815\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:45.34913361295646\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.70136500696576\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-347.5711422703038\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-150.4192941108024\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-1471.3276970564991\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-711.5783698921414\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:73.07771978836722\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.57927781113308\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:69.98123626618802\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:75.8276584300589\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:75.74253294578774\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.32422433564568\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:75.35108804139121\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.09070456807683\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:81.17020783859317\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:81.17377678353643\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.91451623216213\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:86.67201528030648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.92078888106289\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:85.88791924541253\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:79.49220387836063\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:88.42369821054716\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:79.94959674734503\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:81.27898536769305\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:86.68158942197984\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:80.5313543859103\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.22059446512198\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.43542847969665\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:73.22813468809856\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.11207440690416\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:75.58567503054748\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:76.22851792567353\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:41.46461246331157\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:50.423796924375665\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:60.0929863099229\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.34994929408914\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.55157872073946\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.77513336635087\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-13871.698180815665\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-480.4683235895925\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6948.8913064871\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-7227.204670165823\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-13934.30251053133\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-347.5829431820893\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-22.682522111656734\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:49.01078353020222\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:72.48826927796792\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:66.86011057749238\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:63.06758913775896\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:1.2775652233872226\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.780000637515116\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.11472680448453\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:61.63575545693121\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.82079591349037\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:58.28836302737537\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:50.62945934850649\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.04299929573064\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.41458105829591\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.70655397705622\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.57138263318508\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:50.63314944464592\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:48.84569366573348\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:44.86581573660586\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.794275379420455\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.85371055060058\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:44.642555537516905\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.23542242247679\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:42.56845937646966\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.82649466897956\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:46.56923488076039\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:42.86557700429214\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.00913046360298\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.676739918847446\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.93676372660343\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2149.453717315169\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-4698.058945555871\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3738.2220392249715\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-4803.086883088\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3535.5211899729575\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4251.014103675283\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:61.08455611928605\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:58.55534658176491\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:70.72169648746133\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:58.42388573361721\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:69.63395552901981\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:76.05602367596893\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.32871481224343\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.75559996656774\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.46120170085237\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.15813350865369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.13732845826446\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.90582979636646\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.92485830068024\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:62.471800911041385\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.32150493734835\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.43269698200872\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:57.20575998931348\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.68730077671198\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.87543153490393\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.277997908851034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.1139344914726\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.79918928116771\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.34400256277541\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:49.895690606101184\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:55.56106781447563\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:59.92697004589911\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:63.44691361377708\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:47.36105947277506\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.43767613785486\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.209869341670846\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-841.7540795226282\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-970.2376273225104\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1269.065518149999\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2015.364219599394\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-653.5390673236079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-987.256873734266\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:70.64092638362948\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:63.68905462741476\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:74.6506657724403\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:73.43318414462657\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:71.29499154169791\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:75.85765499125512\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.55815427401012\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.02157382546118\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.24661810394345\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.62031246349508\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.72962020249513\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:79.18668452025024\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:69.07739518100206\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:69.11042576187516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.68884326323831\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:59.72289001500164\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:70.01793474264272\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:67.17648799725646\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.18266954311149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:48.45628926810831\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:45.30828036044976\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.739947823721\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:48.76296912254641\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.160637365071395\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:35.966090051276744\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:45.49292691163514\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.40449957729232\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.72219476026282\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:59.491290186126\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:47.51617124787083\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-297.8923603504826\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-253.2797131790149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-473.39900004008894\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-354.6188760311046\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-180.56005510971994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-291.19337320891395\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:76.45758584881506\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:77.7835877417015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:77.49927877158608\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:79.18029376331326\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:78.6391591161513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:78.79729270935059\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.49656891090086\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:80.2768240689386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:79.9899471214759\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.42473845166236\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.99964778427066\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.2051688365057\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:75.20115102154708\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:74.4965379495523\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.17509358543595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:73.76641202292356\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:74.60548518866982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:73.05530024100891\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.14353142371087\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:58.96232765288312\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.578498337802394\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:47.72208664269782\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.574562564386554\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.018056522529356\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:40.359889502784604\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.02065111009786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:45.065326592976696\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.90648645404477\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.932245968715506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.55878147121204\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:72.07008644386575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:74.49906892528489\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:71.16452586096604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-79.5451976634838\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1453.9610944647222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2130.6947664541935\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.30802201322912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:78.80835660899879\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:80.15422476286773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:78.2721073914927\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:78.70893121423262\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:80.77417465530107\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:86.88300082047593\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:88.20266365605701\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.9877805686354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:82.23040126222998\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:86.82807041398178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.51278119391584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:79.12838461128533\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:78.49750112510272\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.33983300726088\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.86424351386708\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:78.71064481723957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.58462887471637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:51.55339681956597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:61.211354303679386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:47.757415082437774\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:49.89103913964767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:59.00579310125775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.29248216863314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.544624959252964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:51.25679706676127\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:43.64110497248465\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:43.91036135672207\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.68565449921796\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:57.24327350996723\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.96857833862305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:74.87319345263819\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:74.93307464605621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:69.5151410204299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:73.52920995160667\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:74.96686920206596\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:87.23979968551203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:80.56038467432215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:79.60481128418323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:87.28490447885319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.03015687805728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:83.622476667565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:90.76642379035529\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.23501973221676\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.0956132302987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:94.04747064560769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.36037300025693\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.1953805791195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:84.69652447928773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:84.1404606428928\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:82.25016010216224\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:84.69801644484201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:83.29969221202053\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.35422662936205\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:68.29220132155152\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:72.61618294990184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.26424673648215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:73.31162143448753\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.01748882625121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:72.40722416140508\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.837205490891485\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.302266688493404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:49.078971370056536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:52.6373279609015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.2720904485906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:51.951347023595076\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-5464.91761158732\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-470.71784900998955\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-10872.977041089694\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-5827.082448422768\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-13687.902603570265\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-574.7663715488804\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:20.002480082572028\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:16.691519666413235\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:70.93263593971307\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:52.382445896677\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:26.87990718159363\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:67.64366569201528\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:50.28461162044928\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:53.410165988266975\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.9175493760171\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.629453148590095\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.11194958207267\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:58.0319408283307\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.770151120222295\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:41.60310432984192\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.456884974072175\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.366991444283165\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.53657042146481\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.04048973343638\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.23204831002828\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.35969635712714\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.17982845664775\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.76729360297967\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.057441200007126\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:47.27939330246901\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:41.35877791002475\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.04105430030044\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.769048635318725\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.37755274017604\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:46.22248288411339\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.838563391268025\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2135.3045126131146\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3068.6925613382277\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-4890.389638251447\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-749.2263300199035\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1480.3869148236358\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2018.6299972594302\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:70.98120432655298\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:46.94002022228436\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:41.417403449579616\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:59.099648527689475\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:53.532330702382616\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:45.504601927983465\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.23693681890519\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.47390052781883\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.73913289751003\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.80914041749881\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.5209288039106\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.02042747971765\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:57.307057705589685\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.2477239095573\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:61.80923042057114\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.92666650804786\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:47.38150987953206\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:52.840513809987\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.10102343688432\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.1673854762311\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:44.06854646343523\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.80974611097476\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.43868580974866\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.93625306512446\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.275451703714836\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.933808171004635\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.10823052305174\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.77303316531933\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.03553919373205\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.81684744489579\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-728.4600864347274\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-418.0946062454753\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1752.514000029147\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-426.303345204527\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-821.2508348896338\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2834.319286406557\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:72.1539811321466\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:67.3879461038573\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:72.97131578409362\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:74.8138640695336\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:72.39867205973025\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:67.05672997391252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.41279567744057\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.50946660235324\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.39857997417074\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.51622543577325\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:77.47384699148114\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.12889634247743\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.63006094008848\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.52598176365814\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:77.08653379980272\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.10787777991347\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.8708301804038\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.51619747985622\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.87520410867306\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.43329405329587\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:51.24549333936732\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.15487545219062\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.92303255200386\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.95738170302411\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.16554224293846\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.29703311745439\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.36938185170235\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:60.86389974194122\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.54348933625117\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:40.73760225441251\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-253.0037341294465\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-94.72225879101043\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-324.24691773663363\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-189.61458739753408\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-92.29317438517901\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-117.71812453995172\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:76.02420677999703\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:73.5495414670008\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:74.2038840191678\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:76.02713938958068\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:75.07950693157548\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:71.82311440566282\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.17728275628988\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.91481935780662\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:78.88842537423774\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:79.48281019221525\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:81.8811423013866\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.6668084401423\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:75.92861206454964\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.29369680598742\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.1415280006456\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.02436775208646\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.65227822566051\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.95266609384706\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.873604624923324\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.55102315681295\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:46.648353039983505\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.181684517074835\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:46.228797061528816\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.82395159874121\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.05371554707852\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:45.89152882202955\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.53390267325469\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.56849744655279\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.839655663322006\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.997618974523334\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:50.77012101903122\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:72.70766341658067\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:71.23227064021467\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:61.60857859702445\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:68.69112079400918\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:70.10717613665112\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.78029811523203\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:80.71278165512145\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.84534053524429\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.61387979110646\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.1832754378999\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.95974723573178\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:82.67485805390105\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:88.34861470335012\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.51642540555193\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:89.87496348231491\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.20383910929903\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.26492226302295\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.5036885181781\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:79.3320020932302\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:80.24637377266812\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:80.22083793689737\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:79.25751685767402\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.75213286596504\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:50.30868661188477\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.84576601511009\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:50.90429955275864\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.76527930247775\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.56230040494619\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.06961394918069\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.520355381817204\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:45.6258223576279\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:42.70256593929115\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:49.994202040670146\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.817022092188324\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.110701292471404\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:74.69727175737387\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.65340490919854\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:74.07320680535618\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:75.63790245446941\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:73.36461085611859\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:73.78974851423403\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:83.3549423796441\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:75.64442574367267\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:73.36502000043672\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.57641001185439\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.38820759915667\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:78.85221412935249\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.53461696511653\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.93559136641505\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:92.23737454818308\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.27487559483876\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:89.89039909379326\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.25310844004483\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:85.18115746824641\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:85.69337021444989\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:82.96710552076733\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:83.25610698748987\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:84.65140302811578\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.26869050990511\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:77.46878568526326\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:74.29858322942981\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.1085172673501\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.05296055283294\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:63.67383348668203\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:73.47155048844381\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.6825853471121\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:47.6662626209646\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.517746785454534\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:47.373845345444145\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:48.15731408783448\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.47093018353972\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-15513.564700343837\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-30942.367257914084\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-28123.63689593953\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-38463.76720816249\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-19998.101664754326\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-19114.833837198024\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-285.6334842594709\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-126.02797676203662\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:41.74687544176013\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-95.59492711667662\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-176.4828754842892\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:47.87457347667715\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:67.52899767988023\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:68.30163607689413\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:64.53366931307683\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:69.4785686390338\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:58.7760517736229\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:66.62931347381796\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.1785753667472\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.96154527987336\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.538685735869905\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.379760100239835\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.87733190105693\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.519984804029264\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.196930996868154\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.151633688485745\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.97934387843848\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:45.706408925888766\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.119814387684826\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:62.68320181550144\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.95211784842948\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.0317150305067\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:58.8406731379699\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.38818367007001\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.18580517205693\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.626931180251304\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-17255.003549923007\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3050.7257291705146\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-1179.95406820419\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-2424.5136020501077\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-15987.748872172278\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-5495.943963612225\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-69.00031297952758\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:54.389027008820555\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-65.97632958815734\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-139.9063200533531\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:46.764304774825824\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-194.13291728806553\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.23544685759819\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.12224661317559\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.742951939292\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.98682836870023\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.10735400517783\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:78.04329442029115\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.43589095481275\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:65.97703884115738\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.0938399253256\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.78823935553444\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.20535017534725\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:61.81529049942866\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.26901008698346\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:46.54910130187035\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.691984526079125\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.741297053306745\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.02378671998532\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:49.32639804926324\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.971050006735965\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.63398206233978\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.21443581191266\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:43.33872811544403\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:47.90790536396141\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:46.47265524728924\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1081.6826361948529\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5665.199880397066\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-8472.072420954422\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1493.15107892685\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6668.105848235723\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-8515.140934456418\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:65.0498980513889\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-60.64447954567142\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-12.323304233445809\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:58.61971983297121\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:32.53004229660576\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:30.643125609960777\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:75.31696022073521\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.76567857071957\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.55804218317788\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.18764657181393\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.81267993763923\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.93840652323783\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.60848402798504\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.13168351381572\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:71.74573954021584\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.83963135549456\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.45259503401387\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.14144665110854\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.00536609443392\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.92082313623741\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.97970911487056\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.82545208517635\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:59.25409375118213\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.424810609323025\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.32338530454605\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.606027846781636\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.52231766936393\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.595311054547444\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.810182088368094\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.31951121362388\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2021.2150913415883\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1668.849538648288\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1003.0233156220758\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3597.47261125521\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-944.3489474513758\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2058.355019541591\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.93485301117713\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:71.01639367352328\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:67.24155818129074\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:73.26861226342625\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:72.61087949864032\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:73.71398534616962\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:79.77699893750572\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:79.20837754851912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:79.75395301649006\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.14432069022791\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.46053266149511\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:80.33277236917435\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.28793236145924\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.64938795932923\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.404130963569\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.28206747108035\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.55977467273144\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.56517397991027\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:49.35218658301189\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:68.19210446566647\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.06749118661392\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:55.627711169521476\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.7074164157312\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.338698588012235\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:45.133287638097045\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:45.50903113903823\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.04031531834481\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.841212550376326\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.27449696226276\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:46.58159884331356\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-37.49221248641739\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:50.84250008994149\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:23.870850285739753\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-222.96721260786242\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-82.6793842000037\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-17.92074305697442\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.91391769857083\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.702413801324\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.67552885192411\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:74.86033891485468\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.5953983820922\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:74.51051960224426\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:81.800872377517\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:81.80749834617167\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.47281091714864\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:82.45036921884433\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:81.1801050988542\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:81.83115704192055\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.76145121307238\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.60146418549678\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.46206944246194\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.51439061570676\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.75189447487499\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.77007200099804\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:67.48841290543453\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.31489129696801\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:59.785178714116974\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.46807886987713\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.26370895622846\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.55661967610449\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.77921047414542\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.12411973770441\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:39.99790627130662\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.84428262562617\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.51504217634247\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.02155823034505\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-11974.420679451632\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:74.26392695770384\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.34885266110877\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.7834791148902\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:74.56344810407683\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.11554106734135\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:78.38388167092705\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:81.9949857919962\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:78.78754005552372\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.6856273905887\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.90538451514722\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:78.5609123460696\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.87189419500653\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:92.47826113885928\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:87.34559096671917\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.87249431207812\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.86237295942749\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:89.81128368582473\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:79.5204416351867\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:79.2178388511787\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:79.56059179125667\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:79.54992302953961\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:79.28817517896915\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:79.34053780891183\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.118151440782\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:75.67467949257018\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:75.3052692745876\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:76.26785181280756\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:75.52995489656314\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:75.76652667576916\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.77054756959656\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.50429975840874\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:52.655330803935186\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:52.989657910891495\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.52841005229499\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.60597763374342\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-491630.9166477645\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1210714.1620127962\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-35666.7927518804\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-31109.936369526942\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-527027.6295065973\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1339945.3342711297\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-872.9147631131917\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1130.9370110033065\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-847.43278321551\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:23.0129009442972\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-239.25560401874418\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-334.2999862440935\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:63.0642772272781\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.91832561028858\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.94867338854277\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:61.01520921979202\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:64.7648089955039\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:58.662279766020674\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:56.03074596400708\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.18526231426485\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:46.45107225863553\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.294170206695966\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.92546350888796\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.030518014967384\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.31121691410123\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.36772909401157\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.184787384543355\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.77411691258516\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.9979584506288\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:45.194138328774514\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.019781542080324\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:45.454508340950554\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.18962751330119\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:45.55714477860523\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.53233701813822\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.20860499937976\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-230648.44000330113\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-62343.94838530027\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-272175.9299059568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-151871.44892627184\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-14778.729238427464\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-277385.04978477536\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:4.084264264508819\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-35.174885427416335\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-157.7202881011933\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5.11641079652394\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-120.28382000160369\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-90.92446707476773\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:70.5626892423517\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.5852414131916\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.78037928896124\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.4530983666344\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.49284650999509\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.43276382563525\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:67.1952463046503\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.06812235743535\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:67.86579228555996\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.82227910100427\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:58.66097199508202\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.97883637464356\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:49.0107569523549\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.362006572773126\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.23701628927549\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.32322057417005\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.395915545622984\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.48763908848602\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.75787062880748\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.06225990085407\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.48818128945274\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:43.25605224586078\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.014701034853175\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.14346967793713\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4261.737433299012\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-28026.253317208437\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-42615.99660682528\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-18566.96883232411\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-45313.51920023408\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-49037.26093361376\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:50.02722713870267\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:37.4592009447427\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-51.67342793105434\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-25.79385315554643\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:36.33252902703552\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:11.09274694354071\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.60599375785665\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.98668857335669\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.06496959750909\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.81277012040617\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.3271904955519\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.1773453298002\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.55754065908158\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.8488275018426\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:69.48178281832907\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.05644141904381\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:74.7076910015539\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:73.39597257504414\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:50.35505202416128\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.87013879059055\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.45198823406212\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:51.490279160575\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:51.00978441166539\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.39840830631195\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.08113183101113\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.25815114242716\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.60437576310713\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:50.77194346098848\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.0089716037091\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:48.07921794042801\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-18072.80281854484\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-9285.361178903902\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1229.4044610362432\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-7755.635783088029\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-8785.775191695602\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6304.177878088985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:66.56923997674615\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:66.33026052216454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:71.85373947881544\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:69.28341240747599\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:68.81418457361916\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:65.33882177373948\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:84.34614430763668\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:80.79000656603827\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:81.47602171245948\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.34048978506438\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.92494290179395\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:84.85118061233638\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:76.67599147562909\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.35405374080577\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.28031674786004\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.90170679015377\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.14858671358196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.04717119299961\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:52.59894985805425\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.28500249693016\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.451667466555364\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:55.9017808516374\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:61.131020819135685\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:60.69009648335084\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.01606450922101\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:45.890043638910804\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.65239297760059\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:46.96450805052281\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.539510313735605\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.112063892661254\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-139.38373478497925\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2699.1628666390015\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-350.38766973689377\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-11021.461228182035\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-7809.89402533517\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2188.2210046123387\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.94968484517061\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:73.85572709841837\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.84531301640449\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.18749044071134\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.97556384564197\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.79931295566243\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:83.65597354499161\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:88.61516413959205\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:81.72200050607171\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:87.20861169956537\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:90.27768244792196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:88.33853358636229\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:79.28354923794643\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:83.45462055693376\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:81.88861911753861\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.81849879961112\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:79.61503217500247\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:79.1868289076878\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.89027809167913\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:62.83661437090971\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:67.67471413897943\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:69.40941853937528\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:71.22569937373449\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.98037280042497\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:49.41654235060005\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:45.644007134122866\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.92422584241727\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.02972941183968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.8101261744468\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:44.70028065327024\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-207.1264451465051\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:2.274593957490678\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4822.646416558159\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-557.6078705002324\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-14594.013579498605\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-35.653197286258646\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:73.76508968284132\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:74.88353530471959\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.47014788777176\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:73.51642247726825\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.15855664733454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:75.1065772851684\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:90.29663507162444\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:87.85854846597235\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.16114778195525\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.23247510997962\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.31152675666614\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:85.47655921913771\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:81.33054282765768\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:81.00130395498493\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:81.02668756259483\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:81.27220465006839\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:90.93373829074692\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.54197639064868\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.00865545722093\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.55707106175058\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:76.97027104637395\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.96737747318262\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.98949374510981\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.15814037760757\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.673732215208375\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.918706749770664\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.53678035929834\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.761367336338296\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.98799145448927\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:51.43656558375527\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-501.73459034251636\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-886.0814722059654\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-836.4677009853066\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-14150.514328207342\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-7380.533049743508\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-12325.062891702373\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:47.76085392521347\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-31.280021088812827\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-10.866528519314045\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-58.86062837379764\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:65.85109669735716\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2.607372626251281\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:58.042474219045644\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.435341691764165\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.86505069067574\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.917954470154996\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.94510674899351\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.586446830942656\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.35555784748332\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:50.70217141046405\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.37480694736619\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.42795816768428\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.60474471960413\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:51.53733722049483\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.91826501995518\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.17332346003483\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.22147823528476\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.17949629931398\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.05814481629947\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.131292027855025\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.640146515705716\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.15491818876788\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:47.083050865677045\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.5327110312016\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:46.523997839320074\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:54.16910067887595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4637.286628560818\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3133.1098347597\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-6211.4672348948325\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-9240.458539717774\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-9334.814079170437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-12456.025864741669\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:68.11872235990305\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:59.224176035799125\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:13.785808057274007\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-52.87832687744671\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-10.090520947443583\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:39.48869502290766\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.21201243900332\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.39599397860708\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.85549597368173\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.22815903178156\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:75.16412332924075\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.67141144833667\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.41706748756486\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.57828311097255\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.936329486569235\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:55.364952126622114\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.47168076943703\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.378293642761015\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.11578954470919\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.65352929108156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.49848466789844\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.92676342033889\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.898154409313136\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.91807615512745\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.0458776506326\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.00210775729706\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.48916366846661\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.79008211546568\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.3631970269695\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.23211492390216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3077.4784799069284\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-3501.941315070018\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-68.87211510287766\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2252.202820759105\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1598.4189904515813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2991.1157083473777\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:70.56342131796552\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:66.65269097913618\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:73.8141251559141\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:71.1960739653537\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:59.16869626259409\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:68.73464272471278\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:81.13620683398183\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.45844373358246\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.9528808481962\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.83178911925866\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:80.73975503843914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:81.32989893662263\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:71.22073198416929\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.20861296488414\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:69.403405932576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.94949974217127\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:69.14515115314812\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.3088348729109\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.23444007634177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:48.41705077423929\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:50.65448782454452\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.41044928198071\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.71045256055558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:49.27125093479435\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.77069516131218\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.72685391483483\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.946998464015515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.91999439896327\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:45.982888627465634\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:47.32242897270326\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-709.3646432021361\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1437.8830041727558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-646.3918621282676\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3266.5174419622517\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-317.03717898345536\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-553.4012933525164\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:72.70018590351462\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:73.92431444028308\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:75.12003089425318\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:75.90683007259084\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:73.28086545657135\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:76.97541946449836\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:82.4323012966918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:83.71534185253606\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.69839819911148\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.84360516921473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:81.47605859371411\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:82.47481851806971\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:75.0866403534621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:74.6085229682772\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:73.8216096815676\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:73.2754251541727\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:73.41045224826293\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:73.3948204252455\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:50.81700578396531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.19947297451908\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.07775368419945\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.092682293919324\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.11467177590532\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:48.47320986484524\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.21227655826803\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.363910949328826\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.48509611430086\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.7355352474701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.27091016397878\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.72957267673866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:13.060058130815888\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:59.958953797300566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:4.875740430033792\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:63.06686070699969\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:38.489953319889246\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-280.6358594045196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:78.70373711800181\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.47817962464617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.39685297575967\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:78.23769930218786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.8470813903027\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:78.4530535469476\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:84.20224050845191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.67603376359804\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.70441599043454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.37496470695785\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.70544611534046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.90082510613004\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:79.42924364473615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:80.37965283079632\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:80.48108579771457\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:80.1752518560118\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:79.5962237496842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:79.45052217530679\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.32502932488401\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.65267304894115\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:58.75556027212887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:57.64405460245878\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:58.12134159254783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.09684450669586\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.55826786850337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.405769233784866\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.84993968841785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:45.17697006393549\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:48.949058451656754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.11840095052201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:66.82079187803515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:75.31914947726203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:71.8098600611525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:71.7547700008696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:76.8648861617531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:73.6673745891069\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:79.28166693829476\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:77.21821806203482\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:78.92385169076958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:80.56061929656916\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.86748798180979\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.98180423983445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:94.23475743302969\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:92.24635629883143\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.28881592450881\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.6009295633029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.31903302876192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.90306406588513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:87.24129952085215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:85.92729137093416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:87.55481889026666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:86.77168022547654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:85.28073980605818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:87.11063364789278\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:69.47824774152937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:74.0130941871586\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:71.60496971004116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:71.80576797918225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:73.12466027794906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:73.5166563303852\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:48.887572478623355\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:48.75256146052581\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:47.51534737159269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:49.43214816498512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.80388840422374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.62087884188356\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4667.014033029735\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-9967.380896734385\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4936.199345524805\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-5407.344712489604\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-9988.591685794863\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-9698.292819339522\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:55.505742854824014\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:43.56281465437583\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:58.40275950371703\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:51.525316241221496\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:70.31133238775135\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-140.9160782024558\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:66.5082116769091\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:51.146854681584486\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.67770701146577\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.31071483255183\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.58960452949125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.76691436300228\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:48.29103497889589\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.85621879239244\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.72280791845727\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.12277179875413\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.35442727677366\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.07345840321975\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.69562758900184\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.15720696930486\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.4206590238119\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.906145297751195\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.838390544550066\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.56554778630664\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.81780463992563\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.813921973414544\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.11659258653368\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.046317069548344\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.442402684824785\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:43.78835613082674\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-12055.25844595017\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-9947.637693256353\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-11643.981043497723\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-8562.275542190828\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-16365.96972711261\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-9450.127642130268\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:22.284160217400885\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-38.66291559991921\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-17.2264946455839\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:7.215471874549683\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-8.274204962078846\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-5.1738915244268435\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.72709134312669\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.04922044690525\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.28902729972317\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.9617820262815\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.16610218564576\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.94737731348914\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.60970391999487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.071592624435\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:69.16296690044861\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.64436354465238\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.523706743774035\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.38223777992035\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.670411043497324\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.663847976389874\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.929542328542944\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:48.837881642147906\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.895352838626984\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.470411869216576\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.85764322540861\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.7860888917912\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.846636811316806\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.89714698931767\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.58852330456108\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.2652225405377\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4335.138207594177\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4550.659345772625\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-4210.0755422485445\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-3772.871820225877\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3376.278172937127\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3359.675512847419\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:39.36629676743696\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:58.525674666261175\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:64.87313503351054\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:56.53923146831792\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:59.41903640474271\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:29.988343533425\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.71552677564118\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.81235380009275\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.83987687656125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.26432203480913\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:80.04815900673351\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:79.15328052496703\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:77.12340862897553\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.86718047215912\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:69.90355123450922\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:76.57546745605879\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.90909178872057\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:76.68280692798966\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.746018256372686\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.53892946243286\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:50.554306576302956\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.89587439065895\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:49.44995057786\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.7818027222384\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.11972374612299\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:46.16504877840938\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.30771274663877\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.61071997716541\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.28037270260102\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.191234308868125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-772.6147849321178\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-609.3693038062657\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4407.251215695021\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1081.1036758482971\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-753.2344504732894\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1239.3712683302667\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:74.17656260273229\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.10584083253516\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:73.8760815350628\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:72.17550112376352\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:70.53203825127711\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:70.28329720921738\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:81.46899462544702\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:83.73273211238515\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:83.49919667433716\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:82.32590152674345\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:84.61610748130943\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:84.60892319820171\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.67748477181362\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.72164073166084\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.73142856878498\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.34781679795238\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.52878833822231\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.8473109668451\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.070439796780306\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:49.85750941097314\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.268034111006784\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:60.56514218760767\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.16139875066455\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.123781939268326\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:49.72291740202077\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.876746113371716\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.0775690122065\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.93588895227986\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.65108785697848\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.85532575297347\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:17.362573937791083\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2.8337365910234835\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:9.8723609584631\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-0.16714735609795195\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1518.2303996044786\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:39.37455341513463\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:70.11638633654378\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.417125436619\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:73.27626627951366\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.1137679301443\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:76.31578270707007\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.48667591232498\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:90.36819350071269\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:91.9033757044726\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:92.3486749718657\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.02155548620637\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:90.05383508495687\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.02284094914384\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:81.5062326102439\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:80.14800829902421\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:82.3174297243028\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:83.30873910064675\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:81.09171126900905\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:81.98322725458065\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.603343020969014\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:58.95662008717926\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.10396008744214\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.50640906802165\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.23935917605792\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.20020350823554\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.63166520436322\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.72857299900318\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.68761824043224\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.50914406973702\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.894515950946094\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.15895664814046\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:75.99007352493803\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:73.18031620659914\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:21.35240037766284\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:73.8837007841226\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:73.72240648202018\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:76.15863989430962\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.22854237109306\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:77.12262841169058\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:77.65288318208675\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.76003909749812\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:74.83780526851838\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:77.56850008094658\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:94.51497531810833\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.17073657843332\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.55120780131683\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.96910177994376\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:94.24930925534596\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.29632375557841\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:91.44819026227256\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:91.66694711849763\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:86.72468490939707\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:91.6450907358088\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:91.11163632150144\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:87.59258308435422\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.65082599146335\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.43853403983668\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.19346818013206\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.15727954708375\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.96386509746243\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.25794896805164\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.83919233497059\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.821631483727785\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.75101950273822\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.24758885180543\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.7463765273515\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:47.217835479183314\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-32484.15966469815\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-26270.313995818247\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-3311.027583369502\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-34555.31128987823\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-35689.206295749915\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-32511.4512582573\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-842.7294838606983\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1268.4876853035041\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-172.7245801635574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-413.9541540303692\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-208.18457757515455\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-488.7544550794236\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:71.86454322696953\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:74.06482065259424\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:70.42042256059189\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:68.19621188796535\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:70.44177045495235\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:73.27465183439924\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:44.22366783974019\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.59083138170253\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.77661376711571\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.57087345490594\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.42533793925675\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:58.01817578673833\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.00896511397746\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.01741331880303\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.435198848892426\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.209123630519926\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.559568162564226\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.79926463517737\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.4233791396973\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.016474577270216\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.63812226951828\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.86157268175666\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.3332791600444\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:48.05652884527207\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-63248.877212849075\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-46387.77607466125\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-35623.72287903554\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-52124.24013875807\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-79757.78284335906\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-83576.1396812397\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-295.5789989895291\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-763.7789281359612\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-623.357905845552\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-582.5989552611343\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-266.8772152599338\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-515.24519822652\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:73.97070991607798\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:78.14341078507233\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.65140248575578\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.26243525006059\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:72.52968279417338\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:77.50441638901067\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:74.76771524142242\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:74.7156689775751\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:74.1862269158059\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:73.54426623048325\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:73.90628233493265\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:73.46280085185647\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.899055491677885\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.27853825111808\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.52617947278153\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:50.571449828855954\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.765769516745365\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.97087380119765\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:45.05538225373572\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.28942053258958\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.69158774653084\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:45.22135982934277\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:55.861995919916566\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:58.499614432912075\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-18115.68860353871\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-9716.263315788492\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19179.863289306253\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5096.183672094083\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-34484.18073842054\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-18579.321156495007\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-323.977622786688\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-175.83123326207635\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-62.1312525960007\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-112.62013938504003\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-12.863353146071322\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:52.230033928996654\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.11991753702186\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.46773729444584\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.54574019980299\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.92833214350063\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.71920075634505\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.8794306622799\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:75.87566139474453\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:75.98439219244077\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:76.07227294251523\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:75.78862623683668\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:76.38978102575426\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:75.6238417187669\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.092509293481065\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.81002774353192\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.72538735487971\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:59.938244967830755\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.15210096891514\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:61.485572747586744\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.26036993129115\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.55954501697451\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:43.18009457243438\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.71085789210219\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.270517771078715\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.181977322267855\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5906.771069008877\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-7695.721096462674\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2265.7039549145948\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-12377.727420166593\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3724.9106254607696\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2910.759389409876\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:52.55050493846078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:47.262920856100074\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:68.94704777016425\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:52.90991379765659\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:69.29518614724643\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:60.40709640587099\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:79.68354882970394\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:80.97244471522933\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:79.95576274333929\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.80510395403637\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.28266779943372\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.35513636087038\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.14067009182969\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.24139484455493\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.14117188872645\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.98651701564204\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.26475397041222\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.1562071274922\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:63.444704761460045\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:67.88700724606255\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.41249622173248\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.1639920578311\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:67.33634593779878\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.08599610869766\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.80695361477581\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:50.79524000010169\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.71505957665736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.602896071072166\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.10860276381926\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.544923394049505\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-645.8207249923238\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-537.1733230338311\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:16.603404617008966\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-479.20473292646113\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-722.605187316125\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-148.37615912687693\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:73.30368267822867\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.6721622603817\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.48026681603926\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:74.44012324766815\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.01982799000962\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:78.69339252288555\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:84.48424434995351\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:81.22808042975323\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:83.75265327457653\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:83.59016785302718\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:83.24914499442112\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:84.05603641090758\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.76619952621189\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.6590508631217\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.74492211234767\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.86634751809123\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.6159365807489\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.7415545438574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.00137039035019\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.52875070913841\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:74.43428371627093\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:74.65385822351756\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:74.73135916053826\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:75.5242237009525\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.77575852566929\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.343471595528705\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:58.465761424191264\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.803755754908764\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.2949136315696\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:58.21275035869051\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:75.688467033272\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:10.713930332914313\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:73.19321613597344\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:23.899970343960277\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:75.40566614991197\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:71.36726499637156\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:78.52956469928871\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:77.06165389811738\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.21455446202704\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.08456959660548\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.96420319724778\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:77.8268657583623\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:85.31948760492394\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.28877738463399\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:86.24556031565412\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.31368500649506\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:89.03527294965923\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:85.09011753343802\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:79.85687876330105\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:79.71867206906408\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:80.09966074527955\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:79.61315540831691\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:81.10616055410429\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:80.37695674925831\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:75.98600177148649\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.23101061399383\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:76.36703489754875\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.87106969997205\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.2103548803322\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:75.94463546695063\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.13448544789526\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.64674496481605\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.61707575655621\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:60.67958852853052\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.741607186454225\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.029822529043344\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1118657.9733750122\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-73913.84636628712\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-909273.5729412923\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3294156.6557082348\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-2264326.379154046\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-909500.8787619588\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1033.4586659785423\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2581.831845042271\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2696.479097776661\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1122.1182254283235\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1122.8915801472886\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2103.8377441694834\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:65.28377657428888\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:66.2686191575559\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:65.80226148461807\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:63.46423897196496\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:70.29200241592008\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:66.94015344359727\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.44263954499371\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.59971019970305\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.779293089447485\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.4027114745385\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.251707215328864\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:50.20584295033363\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.19679277106661\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.4915075267836\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.138247437499196\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.87045331771352\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.20609162563503\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.01439493219973\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.832190717418555\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.17239569013659\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:48.64196862476467\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:47.44581500988622\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.9545154426514\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.6780000431177\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-94536.68542197598\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-157134.71204849373\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-1814333.5616404095\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-161816.24500704528\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-185946.1257501697\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-495487.22093866224\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2336.2079962395233\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-767.6188390587521\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-336.70207685706555\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-186.0183106011721\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-175.7434087254289\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-816.829164456532\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.72162373484919\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.51848515908112\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:78.17023310185043\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.77511872016511\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.95381298978278\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:77.20096776859322\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:73.59041290972719\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:71.86571408013268\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:69.54570186946034\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.03157899462398\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:73.04584464752553\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:72.04650898116888\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:47.53291312050313\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.878022802314064\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.63674101157743\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.56680933140965\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.874055964694634\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.3204051866552\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.85379922892562\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.29894110671971\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.651464293893625\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.88276497237648\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.64950378335443\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.927074132823314\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-80958.81089375092\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-134099.0985165439\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-252248.09758950633\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-132205.09766923622\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-150964.4889332536\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-160026.12785146968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-204.27753740262574\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-91.94386293443759\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-396.2415768932977\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-385.18946690292603\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:41.948941037634214\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-202.87994555923484\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.33447592609788\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.47775558780928\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.97698971147702\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:80.36426917552197\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.71452933958518\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:81.34529034954248\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.5117985375572\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:76.4970980285189\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:77.73509223786182\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:78.2086142341014\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.4474342194385\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.35025067795347\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.90127886130736\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:58.84363088460303\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.37216970316297\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.242724341304395\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.2853650606103\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.667980531569626\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.54212449284357\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.43511984562479\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.019330665833174\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.82198176413797\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.5526162251607\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:55.16013124674395\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-20323.76347452379\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-64018.420347329484\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-12231.666592597208\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-19436.90954859187\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-27172.195018530834\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-27553.5367077218\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:22.955428003983013\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:32.86638549221511\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:45.86299417336406\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-17.273630761344005\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:53.83168230665491\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:19.57251326693993\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:86.20821433193201\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:86.27335333020974\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.73403060492612\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.98684710301781\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:86.89428415469432\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:85.76698237934669\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:79.50290528172297\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.18361697589627\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:79.94585753755366\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:80.73834609607245\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.23102831399\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.95857670628432\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.22621100198057\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:66.39223019258537\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.9044434937837\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.50058629044968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:69.38395250303901\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:63.55408187852871\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.388854550671816\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.66437903367177\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.13144842762474\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.37345054016909\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.09236324964264\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.21677243432443\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-11700.869104672454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2687.1794351918948\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2846.2204445432358\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-718.4671809299429\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2502.911942844977\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-7031.079079881252\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:66.25542106169992\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:66.03498314195397\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:69.88062543884048\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:73.23458656915254\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:73.00804222635249\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.69233086768618\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:86.42440812267405\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:87.74407371303245\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.31468467377978\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:87.26355196971231\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:89.28599651870623\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:87.95480450323193\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:80.16368495704059\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:81.05035647926037\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:80.46536839928939\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:81.14598417159982\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:80.59266108382491\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:80.07509209585528\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:75.97068873937906\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:77.48924296516617\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:76.64821454748758\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:75.19902680876501\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:74.8700575155945\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:76.63336427628383\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.815798017091396\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.264570096975895\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.965326176972454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.11341328498553\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.01725163007225\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.04824298175186\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1461.1633344932839\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-193.33530182534076\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-580.4666000994479\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-641.6659322660489\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-4967.315079707439\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2840.8492621143\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.91245545760397\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:66.75371847535982\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.49360365337796\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:74.27152688339811\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:74.13028244712956\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:73.6105173520914\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:89.81748783771592\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:89.218267958121\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:90.20290268369318\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:88.45275641661915\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.10110600690751\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.93527266277489\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:87.85908795303135\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:83.14727394481265\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:82.68940768023356\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:82.62253511048284\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:91.08560206243801\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.68697727658882\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:79.08329730244299\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.01441445394799\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.17033448493603\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.42885859844908\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.25840348047568\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.14558508172573\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.99416854363477\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.53285760251061\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:52.28825124777661\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.82353393253234\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.391894890449\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.65670365879534\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-12121.839732838202\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-14401.467277460722\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-12261.486979936219\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-7690.168424325256\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-883.2166963341294\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-12082.85591480204\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-57.21346807818042\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-259.5209432080376\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:71.14254494555077\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:66.72133205442377\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:19.023077087763074\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:41.29310465873556\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:61.56315268542092\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.796870693435245\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.628475339230434\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.98561423331194\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.69404566898602\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:59.427480586313465\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.24170625536249\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.80835789754413\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.210785823158616\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.674677992097216\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.73244587629389\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.83889513153368\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.202108282992185\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:47.08403653697858\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.293586108534114\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.20413411391049\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.02301667736356\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:47.45428902812602\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.803136868233565\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.893298821137755\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.95641323467284\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.941051148212836\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.65953596370769\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.375471983266394\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-12795.257850929542\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-5494.090338331964\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-15437.030302773695\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-10225.045537084365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-2142.53710122255\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-13938.8670362949\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:2.053496760585538\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:18.770226458097838\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:19.940559059921636\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:56.03271717157205\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-0.8372437023947521\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-76.75455706245415\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.49703632432518\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:78.82090595127373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.38152303237253\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.08868549225178\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.12996722066187\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.62759237725308\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:58.11824251386102\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:58.14021813343415\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.15230728153922\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.35933963251077\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.75788774313752\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.61976106210052\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.003959430248095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.57373767922111\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.22410387765994\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.01242458256706\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.51968420148953\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.58142718193661\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:54.84914153908256\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.96186735132273\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.08921326586493\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.90715875963274\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.080088264255295\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.58803188785546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-5632.173294416087\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2641.1241821457406\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-7036.076622745763\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-6436.796510905333\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5932.27373127678\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3202.810435374014\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-30.033741653012513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:5.813182386664362\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:67.34809892867098\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:61.60455473395574\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:43.19823962482906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:55.57526822537302\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.09026832398324\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.3273079078718\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.99683178340102\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:82.02552499617997\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:82.19380327526089\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:79.30124995509314\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:73.2194522124186\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:72.77616723679105\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.85366006682857\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:72.4685852972892\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:72.7347658035603\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:73.25432735507746\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:51.51185435312671\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.921940083575116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:51.527288530485734\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.07043810167047\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.18272703430425\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.79329534822604\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.06244049515425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:44.99303054584115\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.28676987377746\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:56.20719642973584\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.370331187056586\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.1545727103567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1160.9692853111467\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1154.8156332462393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-628.0084766300764\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3950.050822348929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1034.1167334217646\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2078.8922020541672\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.72166618199871\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:74.19566236395269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:73.96180123396047\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:76.40039417290895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:73.33859875034968\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:65.21704022202368\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:84.65282324264142\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:86.13833897432255\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:86.37849843530226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:85.98837662250438\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:84.89960933924661\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:86.53640842653805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:76.83100288923187\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.17904683104456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.36473486008279\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.35468833083895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.70515875237678\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.57011659996448\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.71997333052028\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:50.14649723385665\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.856370354844785\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.123459228575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.78293323853853\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.513884442612536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.23079128191315\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.636279065534765\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.9893957296514\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.2400901263816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.6003351497359\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.77071992365438\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:7.494483208261771\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:11.781223032585364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1127.9951836576229\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-12476.768093244404\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:8.707405132416957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-0.5343546164702895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.82035326318913\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.18228721750168\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.7353709615808\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:78.84474598205962\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:78.95369832209474\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:78.54163836455889\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:88.3564809371018\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.9251711941592\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:89.3383787996286\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.34222355383977\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:90.60071162039883\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.16687648269584\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:81.67174159893376\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:81.68917912505479\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:81.65142788684584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:83.0730149890843\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:81.4762809568498\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:82.27673289200939\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.76499762612124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:59.86647499744304\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.4065097054691\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.56717272261356\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.78612755958821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.1184436987478\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.10770189917116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.82621075102577\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:48.602944926026304\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.9361128488965\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:57.09481313178819\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.384415409032336\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:66.81936067140788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-629.9418671099194\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:75.86148083914537\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:74.10018167879\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-546.7759854592517\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:75.90898013284021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:80.34277093795644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:79.54395343883476\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:78.89308151623882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:74.88218097822042\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:81.8038764762728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:78.90494143145585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.69369033582572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:92.32398225178015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:92.61903897738063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.90656165474508\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:92.04991304259116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.58750330824097\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:87.33076079241444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:89.05073084095692\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:88.17725955318568\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.94871905786583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:88.6837112864845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.62667504002299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:74.59645289149783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:74.95394353325486\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:74.63046251271446\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:74.66972869996296\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.59900628120717\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:74.59333415478586\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.67931970479547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:50.22728884808421\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:50.18859622079712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:52.305245397420165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.48422956227128\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.5539983110084\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-905.1418176685571\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-22640.388519018066\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-23645.14364989561\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-15979.556613272809\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11455.236733814598\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-17942.08900438133\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:65.93956967523664\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-574.6697054593182\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:62.93709684395245\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-25.843163263243518\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-300.61179627998314\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:53.5938808375968\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:67.96701879330843\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.251723480545174\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:64.3406418653409\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.66379242656361\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:59.83979933586199\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:59.46573541625171\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:56.46398404130228\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.70857676691057\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.25279998144619\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.654214363037326\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.47894969469831\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.13899259977306\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.27557019665074\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.39030471293827\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.78509486476921\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.117769181555154\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:48.03788373650436\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.50433724074735\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.54780228777699\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.205652806611404\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.938233045551414\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.159915444780935\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.85827485746151\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.18760812023642\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-35835.593801187286\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-50532.99432608722\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-14389.430022634233\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-15183.657837665578\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-34729.02320669428\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-40215.943620409715\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-320.260328293974\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-373.46982911311335\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-541.4866682062758\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-288.00989656677575\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-335.3441076169717\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-470.4752330426817\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.73538699668632\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:75.88237757002678\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.27790444849795\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:78.1312556612952\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.45015551904885\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:78.1856827103218\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:70.8924090083163\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.99395725755733\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:67.76612939781283\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:69.59704804968842\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:69.03176785771822\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:67.74690671757133\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.29877413932007\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:47.24598324162647\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.16623597856906\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:49.91792044062916\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.45676708005962\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.069058731268775\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:55.575333512479915\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.00644512963023\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.67387203407203\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.39506414729934\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.792198336176085\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:48.897398413225744\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-10018.469656725583\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-14451.048493441678\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-21108.379677433586\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-9729.379879986798\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-13266.742848636037\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6545.1306595776\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-0.44438438776255307\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-67.1141553714202\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-35.2681421125095\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-82.26049913018592\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:1.5211147642962275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-53.544552219111296\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:80.1570765456879\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.73190125637491\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.55170343629575\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:80.16010651304742\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:80.69286694951279\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.54198897396888\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:75.73816889590218\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:75.09443760153061\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:74.41017222366904\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:76.09751344055901\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:75.44172965606617\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:75.69595778946618\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.20798576093617\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.74052676556145\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.74250097409583\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:59.20332534175581\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.97410907510043\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:50.27694247833288\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.925973945099884\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.040984508621825\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.67818702682208\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.59857699243312\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.39684445373978\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.52319859510759\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3438.264148793322\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-3569.627693603131\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2579.340316856631\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1900.4868839555502\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2166.814053763171\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3762.5999946684424\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:58.87563691259463\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:58.3027043147196\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:42.07776423229581\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:63.443574668667836\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:64.1764797217457\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:62.55519905834333\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:85.62879895863334\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:82.82094956313277\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:85.70646589505945\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:85.24640261939044\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:82.72189428667275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:87.81372419814598\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.14085612072073\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.55737220123117\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:79.05210525302364\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.9397621437778\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.76849086617888\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:79.81310121075106\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.82105799267103\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:61.12526017054034\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.25971459063655\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:60.09275699826948\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:61.81093525931156\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.11247530836727\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.17795683888584\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.219059099037416\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.31539006101465\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.180999154434886\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.42780121111138\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.840885657285774\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-253.0665841038721\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-305.57681212188504\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-272.1854028784449\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-247.05684630301548\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-68.04149956849731\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-265.71113475201355\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.35632972702254\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:75.79570946682148\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:73.61382842533601\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.69086053316944\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.0711584626642\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.51598778101663\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:90.87375921701427\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:92.22008457819808\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:91.3933318169968\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:92.25560317742158\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:91.52489490425427\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.27886701001249\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:83.08516376078646\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:84.72514743758902\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:82.97753701407765\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:83.73443760429902\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:84.22690686785195\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:83.30903175816093\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:76.48849973764779\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:77.59487185424665\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:76.123242970876\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:75.1147748539892\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:70.13896009492136\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:69.88704173118934\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.22256045546046\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.82270714766848\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.306995537311096\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:48.70708420068331\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.833408392384555\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.57575460525717\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:75.979642364526\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:40.86714117803191\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:50.072084194661315\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:50.308817864591624\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:73.31676480805808\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:39.026702417925264\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.10444376748599\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.38697738812795\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.25233388855948\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:75.84454519153111\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.08302698255619\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.11348656240273\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:92.81079880570313\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.01472512077777\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.30978236558214\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.97550036439377\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:92.9004319299855\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.39634575065992\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:88.886520507253\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:88.52594185729163\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:90.0427803990172\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:90.31338813774128\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:91.1550499915701\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.36891591581798\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:79.70195367427395\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:80.14317624875652\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:79.67186352345209\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:79.31920089491058\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.99161671164282\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:79.44844018072007\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.780342313062505\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.68860208440405\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.01320417706654\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.47323309421728\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.69384542883757\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.572400571653645\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-102880.19773274355\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-157732.31306023445\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-128003.26074911347\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-424433.75643346144\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-47106.31846134074\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-95342.77050357996\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1874.1891700137405\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-605.3409644052492\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3971.1889280495066\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-5748.745337952959\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1320.2971161586079\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1469.533270977913\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.15660994028464\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.87324723979448\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:39.929130530150694\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.59653005983247\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:48.008935859205216\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:69.98720624674202\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:61.67595775884565\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:58.489780014100454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:60.57739645782843\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:62.94205738062742\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:60.88690287584016\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:62.06876965279275\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:44.729393753505676\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.316766664961165\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.58852028716987\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.73006041398474\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.1710593735049\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.32247089033901\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.0975963654271\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.37006279215558\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:57.56838028829243\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.03490315702979\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.3994347723399\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.88422792886917\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-87954.93154623454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-396664.4135315086\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-392552.2873994964\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-111284.52932058685\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-358631.0448949407\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-100174.84609545264\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1031.422707938697\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3672.5053225097176\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3347.3102708610613\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2429.762798900018\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1543.0423854936098\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2993.9177139618905\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:69.9847954619673\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.2567063929811\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.61471419018775\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.5293204133392\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.15297369115272\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:74.99091864994325\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.00893237479941\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.34981495005769\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:70.67839385394133\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.39714676907347\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:68.74517117831725\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:68.56736738537126\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:62.2431731017393\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.84694847997669\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.65426431583362\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:60.22671844613561\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:58.284799746399884\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.21461861240667\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.4465673334509\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.76790177566129\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.49789970184964\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.87554453359147\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.06283001701507\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.82582934854818\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-132441.12615202056\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-112000.68468555303\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-11058.889901722576\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-20766.50976356885\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-9725.557076564637\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-70496.14542306549\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-432.3320639236787\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-201.63261961805438\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-752.9690622625809\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1374.9405822291722\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-901.4552784492126\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-437.31826259171146\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:72.80626820944913\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.90052306492372\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.01660680986934\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:73.5746652240167\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:74.88124626090529\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.5180183100456\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.55716551148674\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:73.85514728472494\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:74.42383509484495\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:73.92871167548911\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:74.96270794301074\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:74.47574630884601\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:67.21019461175604\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:66.892313821002\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:66.76468179627983\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:66.96816289208836\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:67.7765404783524\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:67.55177420927279\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.11816072341868\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.58023142542212\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.54330541317955\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.162152810851545\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.40140933869297\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.16676368940712\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-38726.266990222735\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5716.13017593997\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-22905.572783918808\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-7090.334989218566\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-43643.385503722326\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-31146.19435700401\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-115.9517189289661\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:51.19339765950015\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:7.286442303112672\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-122.05094567803157\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:18.432961118982195\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-5.923896121452699\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.05898910786713\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:78.83601469773774\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:79.32525059315424\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.07928864095416\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.12514668975504\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:81.30462660481368\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.13516811811614\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.63826576295662\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.01144991097627\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.25832538871525\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.52269276556206\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.10091271580815\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:73.87380688278765\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:73.62591604062945\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:73.45916853353111\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:73.41616764793817\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:73.44009497205136\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:73.61410726140672\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.17035934312593\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:58.19517090576103\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.72064362617812\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.025278956942714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.62029008220932\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.87464056757607\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2392.4582866160677\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-901.4585521298193\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-832.780626385676\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1249.7732298500055\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2803.1728479973067\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2790.0923168311638\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:71.69092946206612\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.38193337535934\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:69.35965081102928\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:71.47877075429786\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.39006939452872\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:66.18026152100501\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:83.93678448102058\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:84.74987811336281\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.56318515191593\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:85.52672610661475\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.68181390598875\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:89.16689337262777\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:77.75851354836666\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.84706623747745\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.69117492263574\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.02214782899341\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.7432743104731\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.68540405400444\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.14492553289337\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.59966573685149\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:74.39619148219073\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:74.35230500497059\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:74.53861901664283\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:74.30240418894071\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:58.78086169466812\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:63.40861942375429\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:63.05765928106104\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:52.74247242309522\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.90250282493325\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:58.46255894858974\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-200470.73648511377\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:68.82988961312225\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:15.837187951150334\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:77.96954374035293\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:78.52712305067466\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:27.855505240630496\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:77.15543432438628\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:75.58932752943677\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.8475264897959\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-575.3538040780381\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.35725841341853\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:77.18218019198395\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:88.81800660498035\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:91.86806421612454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:90.95556770735386\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:89.26304135503874\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:89.82227361277391\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.73774088767685\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:85.01489544749683\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:84.72419073511652\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:82.83445399498216\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:83.73825063061489\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:84.90523383127037\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.30974430179296\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.09276721757449\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.06024898770666\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:76.17967321094892\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:76.46416829645023\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.20275806403704\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:76.24224026528186\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:67.68353376640309\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:67.76660025777359\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:69.33679490976206\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:65.21459912060752\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:68.61032076103655\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:65.01677216414488\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-333867.8416583555\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-5994190.835241824\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4496212.701930653\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3685250.4460328016\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-8642990.934975868\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-4526171.938718972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-7725.97092973425\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1618.965488310589\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-7300.613358830542\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1128.002326971344\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-3548.2302585298194\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-5222.846018713793\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:61.533003735485934\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:67.939585949888\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.13184279621446\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.07470882530752\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:68.97617503824527\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:70.72893759225465\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.135083033900685\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.8077444799121\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.40179542578328\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.07789495269128\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.0806500733521\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.799387224529376\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.512069881890035\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.509649510455\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.8150940325032\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.854260157021706\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.14770980784045\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.05721340660179\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.10614223140046\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.535138409109194\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.51220558436369\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.20059686691931\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.04767694202721\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.77231270496398\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-615220.425778773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3260000.837483117\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-760311.3127249259\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-718266.0014147266\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1194265.6205089379\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-734591.8770621009\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-931.7000433861317\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-867.7805877558541\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-4741.486251307248\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1068.0871314002923\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3745.7694216541076\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-709.0847404666357\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.51835462086966\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.15523249075298\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.87758353002623\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.48565078580162\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:67.27727730974989\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:69.15625725983634\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.01237053416487\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:65.91039823677897\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:68.89620877514682\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:67.67962934277583\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:71.02380063798692\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:69.33292197467212\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.56484856917996\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.26472437800949\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.49988036030291\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.46737026266455\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:60.28830699792898\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.04935503649467\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.13698852081012\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.75134575850762\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.08491759284026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.41388049936018\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.57831438553906\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.162443961686876\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-254740.4285019077\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-488550.7928601769\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-516469.65308012784\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-391277.5868204656\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-533903.1179706161\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-610733.6711453678\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-615.8118386546677\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-695.5107902522346\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-97.1621441925671\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-358.1014831109344\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-444.8043573104649\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-748.7824046888909\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:80.36437266755047\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.13398971399799\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:82.29298011184773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.84350967689045\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:81.31558429053489\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.8909132706546\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:76.61868335225621\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:78.62161603191878\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:76.4223824907608\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:75.6647043452665\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.18691841131876\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:76.86368239686844\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.03328184751755\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.82919710165313\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:62.03964995506526\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:61.00188223535006\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:61.36469831374613\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:61.70366958100746\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.52171957805179\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.798306222068604\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.77800961492849\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:50.08816108712302\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.876936960586704\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:54.095044796236905\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-89456.57998784682\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-171425.48559262493\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-108013.58912041846\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-122324.40872012019\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-43149.199931935305\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-117427.19526719258\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-91.60258976656026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-44.566962153447534\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-56.94456014978877\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-1.4527706483671077\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-38.974418053719084\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-45.330436028675166\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:85.22204160572883\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:85.02923556323874\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:85.94078014717034\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:82.74533093633192\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:86.59506112783325\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:82.0959312284998\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:80.13831994212266\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:80.17907793640245\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:81.04933265734601\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:81.12832389131975\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:81.55921457013903\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:80.03539531788928\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:73.27051042946799\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:73.56204299404455\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:71.37149598205814\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:70.58865527899083\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:71.87956531419822\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:72.43740794882237\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.18771726065634\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.425046202115325\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.58269931949012\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.5741086422258\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.170097790629114\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.78585624335798\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-22890.37333955156\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-4334.696557730365\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-11463.385204784134\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-11311.40108867552\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-11360.510509121219\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-40401.08187369609\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:57.77845145962763\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:61.9727484911234\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:62.316158854228675\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:63.7823969290142\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:67.39993725732333\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:60.41657906803586\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:86.29986698158714\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.0033689561653\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:87.03738571951199\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:87.19084763897978\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:87.39638182358821\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:85.524449750511\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:83.12008021321586\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:82.78118907976705\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:84.69191476984508\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:81.35861196299065\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:83.56732246124716\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:81.41998834408955\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:77.57102969690418\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:76.29294691238937\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:77.95333223515745\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:76.64451848295751\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:77.55076149676708\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:75.60725448355137\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.71849987570745\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.475501715573294\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.95705900804513\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.42025975578877\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.50487760385723\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.74288895847445\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-10804.774222437842\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-10209.938865162614\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-10736.11811933976\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-750.0463778715231\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-15552.878719300526\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-877.064004105973\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.37633715585238\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:68.10826742339077\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:61.06782023882285\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:74.95657978939015\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:61.697993941246956\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:74.12604335915675\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:89.50868511617982\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:84.17802831852313\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:88.79681329167293\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:88.47747249359969\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:87.38541750456048\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:89.46674168697017\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:89.24326081433641\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:92.33844361882261\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:90.79537215584652\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:90.22999586400975\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.21695162312453\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.6250400199629\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:79.36474390157665\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:80.00316764187681\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:79.61999968668906\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:80.45732385535425\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:79.74482293764\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:80.2154552922463\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:65.33587624746764\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:61.532452035551465\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.91295013533886\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:62.66666920261179\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.73111893721601\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:68.34063761059556\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-5074.146187183329\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-21609.581038142114\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-5013.057415949444\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-11609.763032569013\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-34727.51500435567\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-28054.90331146264\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-132.98103018385672\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-568.4456343534332\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:16.413729687766633\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-269.31569127232376\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-73.21404027976419\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:65.55894043052919\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:61.686505803543334\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:57.934056470204375\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.12291508335312\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:64.76633881752278\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:64.6293349628659\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.60824107165597\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.703584526306635\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.986183890519506\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.49612063574594\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.9418506029556\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.200346719946225\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.200582175343115\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.56219751578062\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.071775865053404\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.36172235859859\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.23631601057905\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.282663741620915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.22799037847818\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.78717283258718\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.27114724532838\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.35854893302805\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.30851268346757\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.38220473858575\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.89389368584064\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-27317.870413176744\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-20402.450597596224\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-24346.753238711044\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-26665.24992387439\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-25069.672143393564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-20475.20103965621\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-75.42322833675206\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-149.62731600747134\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-304.29327809218813\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:25.83527705911767\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-205.18944983974606\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-436.1497221639346\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:71.9333031076066\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.38581988415068\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.65997295082789\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:74.49153841622145\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.68012044803658\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:74.87621520615826\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.63216316333617\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.21037383432741\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.79186833233604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.87215886987788\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:59.11986160174987\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.94582731766998\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.15651857067367\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.856141265149994\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.0299286157292\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.5396737973459\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.30075244236241\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.4213305797701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.10313041895993\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.64872677559642\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.90240245263722\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.146341502654735\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.847695417473226\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.49274347405483\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-8742.958333682038\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-19310.14446862764\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-16905.601834311456\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5534.444771985354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-8089.347891059798\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7953.135495978701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-51.23652674204913\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-31.422469393299558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:17.242105228868976\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:36.01855240627195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:58.54935656390479\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:46.59065317224573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:84.30122967495328\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:84.07734069207035\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:84.15675381326224\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:84.44692604684096\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:84.43509323846834\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:84.62871553462918\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.83616363804954\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:70.73724120503057\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:70.63365144181006\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.88657032325571\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:70.43782415307346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.18411267057378\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.1584154269515\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.87102238853867\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.77093276754903\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.82442741782954\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.63831925528364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.93743661738833\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.01393536851984\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.82942070035812\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.66482314015346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.16350876751896\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.28193718118048\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.264936763755074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-26711.443858526185\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1581.7401717646653\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3862.7177822392605\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-13519.91923206711\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2194.9802739118572\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5465.344220846069\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-15.920831290072957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.86413169639894\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.37347303364952\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:31.129519284429097\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:36.891284977196705\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:68.90630719227713\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:88.46616945556057\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:88.69162057684198\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:89.37883368620636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:89.11727294032268\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:88.35394390461668\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:88.78410767743303\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.40268148569915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.88590066915802\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.93756827676832\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.53520580687045\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.19984208137807\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.00496464361818\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.01882612770988\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.818322557882595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.12146378498175\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.73898920137361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.039567135186346\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.60884126647426\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:49.331242576464604\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.29748088938102\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.98240413266646\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.186942227906925\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.33286509533113\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.95586302005183\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1803.2066089699267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-9675.053944448679\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-8826.513533595982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-18325.789816084576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-320.2058799629422\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-304.4275427353109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:73.61428951822555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.43305581831575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.92160782990632\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:61.82960020077333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:74.28204048515963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.3768215596535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:90.5745267128268\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:90.7024248823864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:90.39209603770124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:89.64908487384389\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:91.0007653424738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.05818664755195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:84.81000057172832\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:85.56401168705912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:83.76053060317622\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:85.13411578698079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:85.55840595124086\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:83.79033462454876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:66.13118073149306\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.77943767779826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:66.56408479497411\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:68.04202652710268\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:66.05612491415278\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:67.16476344423468\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.15399827150564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.93454799809918\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.1377974875195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.78217719376697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.4425753794546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.22006251615707\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-3070.4726123734663\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:49.37535489610653\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:73.84560297942706\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.38729445365021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:63.62780487565567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:75.04030653019417\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:75.94398768329546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:67.18030810074322\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:77.80866124105792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:75.10303492805355\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:78.90870914720381\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:61.567888878009946\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.83127300665545\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:90.76146297773289\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:92.17399152552076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.49291310543335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.55944415299886\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.27387154914902\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:88.24880717893207\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:88.35302887233436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:90.53296653525955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:89.54309673996023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.31646050549192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.50366262597207\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:75.86408837091463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:75.74110402189153\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:76.31778597737787\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.97106489447555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:75.50619393939387\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:75.5857133743235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.87060956294092\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.03727971551642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.12154867247017\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.46674304333985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.22901603722779\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.01463932743027\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-51792.73192756658\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1791.3829958654933\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-17288.327982145747\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-20476.884440383732\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-18523.103736346868\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-11799.830887015172\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-20.848017628029435\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-244.32773463269496\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:38.48646078831197\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1009.0552109634905\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-186.05935145918076\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-9.86847677411198\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:69.53050690674472\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:70.81027184418565\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:68.79888176213483\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:70.95751641384254\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:70.23305278344827\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.241837452559885\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:50.137470277735254\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.224439039967294\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.960217798379716\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.10226785613208\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.266100289574574\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.6554932122077\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.42459985748273\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.91685153767056\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.26603778657761\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.733169762425014\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.14594438377331\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.406698544021665\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.08790563474358\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.63223388795781\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.28857349798705\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.65559588127877\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.88729437578608\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.03335792321779\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-204031.91403328103\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-175635.17186230238\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-153134.34816545347\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-227038.30116217863\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-135379.25784664892\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-210561.27712018287\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1434.796295539895\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1761.3219307387692\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1934.7609764811934\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2025.5285995320316\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1938.4721617937278\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1330.8377742673395\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:71.17295247466664\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:66.33596018696508\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.15720180167844\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:73.41422047715567\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:72.07578194244721\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:74.45342008925687\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:75.70579437945564\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:75.43365125778485\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:76.52940862233054\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:74.93891605096037\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:75.27975729770131\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:76.33662863573612\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.26318308766829\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.60805742799284\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.10743809329057\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.75831048345594\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.49009499937543\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.19633253822889\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.545344665458686\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.2549302167985\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.357302823023964\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.53539541099511\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.091610966874114\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.42155757475384\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-37555.01501490696\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-13681.67874461746\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-59539.944549993415\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-29117.515053046416\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-18288.453622612076\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-43626.39874562774\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-616.9088036925705\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-378.91730986024754\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-396.0938047855458\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-357.2940652240347\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-823.2850497496044\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-480.89935542843875\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.93191587023138\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.5438243236196\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.22933167684162\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.03156872806444\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:80.03749567119975\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.8093341063852\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.84943615542423\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:79.19970899908397\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.53226175970619\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:79.2575363626071\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:78.77053722762705\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:78.4723263483427\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.183914771974315\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:61.014687320712135\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.6710060662388\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:61.34535595980144\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:58.514904313543894\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.178639239908264\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.76345098386184\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.53406957064302\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.866623728046555\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.132802097225195\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.25972321729921\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.06760996626507\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-16232.557268495913\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10475.846214234314\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6191.2501528283765\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-4223.873312178327\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-9448.948182601267\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4437.605787657489\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-56.24216361906322\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-54.85453925046328\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-427.69335677907446\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-86.18828386091828\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-44.23254131331416\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-47.86141439156799\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.55804656940337\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:79.98033104636146\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.99829641766581\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:86.83140287726202\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:86.6968707577087\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:84.2460095013475\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:79.19003719080847\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.79367062437713\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:81.53994331346242\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:80.12830392817891\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.29249815701546\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:80.83625018091725\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.6583564471926\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:70.33951846344017\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:70.41329885968737\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:67.18513985154189\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:71.19004100420231\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:69.9730753004727\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.08717777028715\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.10322124767577\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.39734273499583\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.05050282560764\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.80162561995434\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.76846330359848\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1207.6773188826228\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1322.6764510615403\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-755.1332687185541\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-788.7422156578166\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-549.2679736480834\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-472.09868288303187\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:74.1447633227746\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:69.89620505025577\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.11881448510503\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:73.70296479962397\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:73.35262881009197\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.42555779627311\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:85.6855637943585\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:85.74811845571625\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:89.83885749787022\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:87.438869604311\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:91.57229396562299\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.39100521967296\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:83.96176750866375\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:85.07741811157588\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:84.78550484346724\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:85.24854973580915\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:86.15491538623405\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:84.24187075373129\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:77.4375397638602\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:77.54431471545645\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:77.25364930217336\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:77.63364152047839\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:78.0651327665863\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:78.14006689287153\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.2492249180615\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.45721513974071\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.61906510185219\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.733131933872215\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.22588565182367\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.32464385649132\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-200.45653129770025\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:75.68626523111823\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-30.582954951211928\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-36.55232238994985\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-259.9803575856936\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-167.9915107264117\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:75.13017920267873\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.23640801419978\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:75.42977606432939\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-929.6455671695201\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:75.06691662695954\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:76.54701809511117\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.09734368545037\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:90.50677320894245\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:92.32917594407091\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:90.86708929756666\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.81317549197104\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:90.0291020260541\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:87.8383597119809\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:90.40036427753944\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.31074082217319\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.91698382530652\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:90.21944613955544\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.7468640805465\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:81.45702548818244\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:81.12413126834389\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:81.83582425616547\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:81.39143024224104\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:81.24258043736195\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:80.72203899446765\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.54749916527946\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:59.21092418802591\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.75679648608274\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:60.538581641019576\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.23666849624516\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.53293792229406\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-359051.45837950654\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-85793.63645248473\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-513032.7366990495\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-295179.7970073631\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-243392.12916789798\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-515866.9659457496\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-5625.92031901234\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-5271.145008228444\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2952.708172929672\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2873.8022872648244\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-6095.436004807012\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-7412.404160616057\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-105.38864522773133\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-71.01915113751207\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-141.3629712975805\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-143.8929507824452\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-122.78224476873638\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-99.65201194498651\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:66.43786353798153\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:70.1626058917425\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:67.05273061967253\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:64.75549262982827\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:64.35504539027939\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:69.46870724078329\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.82674728417321\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.748125816819424\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.55815548721592\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.757110505967376\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.553272269079066\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.22809783958187\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.79698566763631\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.67479690709178\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.027085899837004\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.140550047922446\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.90013843295704\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.02198351054233\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1118043.9352890747\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-542718.1045279717\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-530571.6080613734\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1018265.1136706438\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-917628.8526506476\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1421856.5336956389\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-7092.499694042643\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-14802.355531973571\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-7486.006100070674\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-9915.218133828694\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-5427.166763002052\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-7963.354272744711\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:45.11419534448379\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-34.2911836009405\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:54.844138710821966\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:2.2535820661143457\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:42.07180213679283\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.747866265411176\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:73.55553848335741\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:73.99068409011906\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:73.75661922872678\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:73.68420849079406\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:73.53690378866955\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:73.5322447956031\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:70.62754005405074\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:66.07265876821874\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:68.7798613164254\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:65.80183868618627\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:69.94734781759757\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:68.32955383333848\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.3992889116748\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.814976891962154\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.35194136912753\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.28233160035079\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.69883496427601\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.80090763935947\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-465509.0113478255\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-526498.3666049485\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-57045.134530694966\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-537432.9452863352\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-316506.22220105125\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-371772.7605532623\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-5500.095578758053\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1163.2785672696207\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2962.1830576042944\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-6189.994858756039\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2268.2011808721545\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1482.095630597279\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.03200129846402\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:69.00580006382238\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:74.81035360959312\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.7067651446172\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:74.74651172980256\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:53.121044420416275\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:76.7841236529339\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:76.57659047696418\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:76.94766722014798\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:76.88535266358426\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:76.40459803355031\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:76.77393736005112\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:71.04933785114633\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:71.90597774101299\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:72.14203099738528\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:71.75294064085158\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:72.31983040335425\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:71.82696471541203\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.777824389032716\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.670517554848665\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:58.32217640417405\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.753283679978495\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.30120947792645\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:61.086798158097764\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-149601.1394341411\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-53141.28352075792\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-61146.11593431333\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-145832.37179514926\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-40788.52015045142\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-62746.41076216461\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1238.7916360528945\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1165.0473439101631\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-407.335584862576\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-1387.8315453645841\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-368.69426658531165\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-274.2099567977719\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:75.8530907409223\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.13461646045448\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:78.50732976898045\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:75.31834736971332\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.84574036724085\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.17356175451977\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.37126854388521\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.44472222571488\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.37751494156647\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.4643767363824\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.56639138228128\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.60315174493759\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:74.18789738177125\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:73.85809240235974\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:73.71546168135694\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:74.08902034504005\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:74.12076382490478\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:73.9508037589684\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:63.78791124638465\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:61.28637108678796\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:62.137351947755114\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.81448163818994\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.99416725287012\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:59.500465721150285\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-9578.46895102162\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-4272.044372558594\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-6257.801412126978\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4615.540573219318\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-6990.546284293076\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4691.1883667569355\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:14.637885815144713\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:37.25985031225627\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:32.18676352519704\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:41.79869735212755\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:42.18820136207779\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:22.794225631124686\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:79.52127536161385\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:80.26015282006036\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:84.15591238848894\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:78.96175613733988\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.5008008761421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:80.44533847799632\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.0275402435045\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:78.10869105747359\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:78.1325914546953\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.95509865685088\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:77.99884199485523\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:77.91841121535774\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.93792621050414\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:75.21841830395638\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:74.61481398724494\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:74.42615828803433\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:74.71633294701483\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:74.75395932547026\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:64.11018020482962\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:67.44968551082626\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:67.33822296509318\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:66.09884932155774\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:67.286027046148\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:66.96252546224\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:66.57471412556487\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:38.34299338530893\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:74.67735544539889\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-628.3805000960499\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-407.36876247998197\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-257.79203094771003\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-16.63119913180857\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:62.25596939700151\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:76.36591805727863\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.73931773747864\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-6010.95877633121\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:73.0092933555585\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:90.65450164772001\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:89.80228142347553\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:90.29961022173353\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:89.82437894135784\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:88.06444025936796\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:89.22824439826775\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:86.0287335436348\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:85.32131379213364\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:87.24936098564882\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:83.46190339327151\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:83.57596936950517\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:86.80892449615037\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:76.82512698326644\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:76.7944194229688\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:76.96009291801235\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:76.83498035085961\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:77.03084525269867\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.02424409788269\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:73.30347432969968\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:73.74193823365736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:73.48941869863475\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:73.48141260650611\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:73.32952649129292\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:73.17671756090564\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-918559.1889221335\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-11113806.315258076\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-7612491.0288613085\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-21549963.758372735\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-7017655.261278566\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-20544131.614460204\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2006.1533874559818\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-11618.604689193016\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-4847.592044045739\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2198.614006703815\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-5129.626084576449\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4764.796483225481\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:10.038249881555005\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:5.3959714793332285\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-5.525259533860338\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-70.80252482442052\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-62.22327781343573\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:3.3805267936700467\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.948794034308946\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:59.9498851149922\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:59.90688244102507\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:62.19570974814226\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:61.249357507724845\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:58.1801541196586\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.062725739205696\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.6852328824929\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.38833563670904\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.96710652681882\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.68738253523835\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.17842542022537\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.73883282584912\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.73727212942274\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.496574947626655\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.74464439169464\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.98829215642584\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.50835715661117\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2779035.2651345064\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-11283724.571128227\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-4863143.1028693\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3803701.5978958216\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-4662523.021585571\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-12613168.168304661\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1680.7607877832215\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3549.425215003432\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3943.2692689300056\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3817.3258789746756\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-18870.505407948112\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-4874.18876310988\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.73872573287397\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.21003079959218\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.52847550242222\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:73.77683552843646\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.055795923145475\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.49138801092234\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:77.79038052938415\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:78.33784937952521\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:78.32539814536828\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:77.41602490603971\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:77.59387360796202\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:77.71437216030509\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:62.75429353763777\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:61.83961159230407\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:61.03555507740701\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:60.183456181963194\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:60.412491719444695\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:59.43467221079708\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.4540523766849\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.05079591048221\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.34269482615992\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:49.21879374251134\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.664539856370894\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.30084307796054\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2129249.227676963\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1514253.705234392\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-666773.7275522276\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2156333.923745663\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2238775.510473229\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-861345.0478838596\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2077.972882107734\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2166.7917788310538\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1446.1182011733192\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1708.5022231224862\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-4867.425997037414\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-572.5920411324388\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:72.57091534405453\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.35955776338788\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:74.63975612153398\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.15933021440385\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.31238481489291\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:74.56118970804087\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:79.71482862159903\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:78.85911359244017\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:79.38727011494603\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:78.93025001923432\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:79.23777446949266\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:79.66215047571394\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:70.31694989302105\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:73.48268004361806\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:70.53681600272327\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:70.65796472596033\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:71.05417585542016\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:70.34663700324705\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.77910522716758\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.90498566507142\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.907172921989215\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.86261773886785\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.95007479307077\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.264548158356774\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-403686.2889583699\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-489796.41859822616\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-498937.4129133773\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-393355.28242586163\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-347983.2474811515\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-666600.3841842038\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-139.984369503409\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-433.33462616700274\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-644.354203294073\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-895.2084058095753\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-71.13113798336121\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-416.8527263687106\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:83.25999116831825\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:82.67130280827988\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:81.53813968407441\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:82.64497605550937\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:83.3471071987851\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:83.64326798183134\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:81.56589817834052\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:81.4302134480976\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:81.94189180830645\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:81.32249893278612\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:83.41191218295513\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:81.24560476159655\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:73.98894795571096\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:74.74853450430952\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:74.81313740483787\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:74.86434878562736\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:74.65663005556057\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:74.8714298690934\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.32632616521618\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.70762047964794\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.85494431940188\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.24790107067219\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.24975592944803\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.0313580580778\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-154897.31448649234\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-184892.486069426\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-126771.09696987201\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-231766.71639863102\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-79731.04442982716\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-26852.7662063791\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-259.7916533620081\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:18.97176496619969\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:34.81908000013413\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-155.90722653882722\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:30.3613647783338\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:32.31366388998791\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:87.27970887958956\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:87.78197902502085\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.69702792402512\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:86.97269437254837\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.66426966864825\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:82.3771214795169\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:86.71368320609778\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:86.89938347707404\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:85.93824893688245\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:86.93416903897756\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:86.00956360076336\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:85.40926392331801\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:77.82153492607029\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:78.19935108518112\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:78.17471829618029\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:78.16458607138001\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:78.52927808619748\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:77.54906552386528\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:63.80939327233226\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:63.56893240278212\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:59.441193960565954\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:61.71451176570286\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:59.25322524011369\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:58.658550527619035\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-119712.72931944393\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-688.4287943137359\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-225413.53460474216\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-9188.439335148574\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-3952.904505275008\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1398.03886586423\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:63.72615896500031\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:33.24279646125715\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-17.768078824025245\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-206.19424018360104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:56.14332037708532\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:47.43077600913502\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:87.26855872699461\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:88.7794649957953\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.66754484214212\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:88.43249108633533\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:87.71800355849255\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:88.35444951076222\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:88.99763547899782\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:90.58949990099673\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.2526812308341\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:90.39254302916339\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:87.66461841944073\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.24692736570617\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:82.69036103999925\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:82.69215205712193\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:82.718608802525\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:82.59537055651042\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:82.66871214919145\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:82.237240362111\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:69.86113181256985\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:70.97033436745524\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:72.81300838158955\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:72.75950698001446\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:72.40297107643927\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:70.46270841120545\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-11080.31608034439\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1960.3867908835505\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4566.627104438318\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-31088.953993055555\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-44241.569981977074\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-15458.237259476275\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:52.76704848611138\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-524.0999821511848\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:11.829455702956782\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-67.02159042899491\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-329.7862342251296\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-74.6693882066683\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:64.32611605517971\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:68.19398407864703\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:64.12765114818436\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.89292444705588\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:64.69630119460506\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.8489752184039\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.39612363095683\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.60756473420547\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.258083951740964\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.5815834218212\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.85958848259551\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.02880109354584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.19170954944441\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.13633174399299\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.22793819086584\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.809009318292084\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.921774810498576\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.644683236237164\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.38443094344591\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.58860511601065\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.91181561222682\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.7616797958635\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.514195821374955\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.906240314116054\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-63322.273344576504\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-58611.86336580462\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-60988.012696364625\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-41991.27991347918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-44045.99720479185\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-57668.19012448767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-172.27168735131397\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-187.47131939099657\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-645.4276108196912\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-149.84760838667177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-159.09594222257417\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-294.9785844654056\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.31123794508412\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:79.80115348847482\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.5942824420448\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:79.60232793110576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:70.98605835221714\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:79.1215501097453\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:70.6404980662491\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.87845371124592\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:69.39992676859677\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:70.22292345316039\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:68.88296898656985\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:71.58480879826467\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.43180423256353\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.96445935348106\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.336396457490906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.91368865673236\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.1705208185435\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.390638111049114\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.8213775468751\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.77837777916281\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.64918216540999\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.3716175256046\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.226160838172554\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.26763518996553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-31702.154541015625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-17415.700441988738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-17828.77786694971\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-17916.87716460773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-26573.77706321794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-15904.402364155172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-355.4069179263615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-117.21038859692779\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-298.93994352261416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-78.83512945603535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-120.84460386241678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-91.44822653115877\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:84.01554747417839\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:85.6370188607016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:84.32992025446573\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:83.86094301786359\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:84.87060945319604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:83.14346130364893\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.8602915509091\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.8089291671771\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:73.42455555267273\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:73.68562289163576\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:73.1683392239143\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.37006618433622\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.07761151937165\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.762602346585986\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.397836827405136\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.080640409761195\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.412491690840085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.53371904110514\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.98291101840371\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.40507390606677\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.751113339330935\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.51934448428821\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:49.580136780209486\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.09322463646473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-13410.850081282211\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-23747.017954051542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-8294.357320847148\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8391.600118386079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-10698.315792219013\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2183.7257584029994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-23.246321685676797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-45.14911954002743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-110.24149010931063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:17.544623525993764\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:15.967799238185421\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:63.05837259224967\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:89.79123695874608\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:89.50298593164524\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:89.73876946995445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:89.1274872060551\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:89.51401678218534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:89.54166846542118\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.84872876789929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.28168053839318\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.53839022670326\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.00117267502678\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.99778280763574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:79.05824776589165\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.83251367017357\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.18744813494086\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.10923639003267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:60.876513807392186\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.52457656655563\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:62.43179532793961\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.28213259182031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.820540272427465\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.98208530248385\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.918059190102596\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.692942475713636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.21968598151836\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-250.68731751378076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-382.865315370432\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-37407.951743364145\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-24359.79435096302\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-856.6941991013932\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-765.8866751560365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.93830896231769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:70.15100444180464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.6459017453746\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:49.61692636834063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-62.529062867822184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-272.4691225281844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:91.46416546018035\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:90.83354313886475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:90.88709827033998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:91.3226547182029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:90.25440773419548\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.5624081654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:86.09426456985744\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:86.35644230219538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:86.17261990176776\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:86.0859111039492\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:86.30554047159974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:85.93953751773229\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:71.58333494308147\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:72.20346139489993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.9541195718391\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:72.28712996128885\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.09630734907351\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:71.45435828877021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.47490844755214\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.91024664272184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.298050450517785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:52.73705823501091\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:52.57396901318461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.04866123241736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:74.38263025125995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:48.11537752384459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4743.7616019102425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-3.9697016196705626\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-156.20618058152797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:42.76334410863566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:78.55982376516477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.45730869971081\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:66.97683522699384\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:78.14100041128313\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:11.553412727524304\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:68.07100416357072\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.95643552322854\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:91.81786891017212\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:91.07495242446497\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.8914897950077\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.65162203159738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.37149316697162\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:89.14707897449685\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:89.70530663093683\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.02218280443768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:90.56972829556024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.2060744773576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:89.1834102899799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.65165686917362\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.89638732905647\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.74013162504697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.298549015894\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.54623115901124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.18644526227429\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.40125362745321\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.67892053805532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.864062919402514\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.31421697337014\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.28120752988226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.62423379783841\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-71792.84656365337\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-22413.615435216256\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-31583.24691011175\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-186142.11584441393\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-94359.64695278165\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-10588.93377046307\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-215.85757707027676\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-646.8041118155135\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-488.03575448486356\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-94.60563165076235\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-340.1246006607164\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-67.71976026707132\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:69.20214678866127\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:61.657146224128255\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:52.35068601790238\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.6225485395467\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.5904200671929\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:21.236408736712363\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.012053923879535\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.8418365094115\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.30956510719207\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.74655174881797\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.699474487227654\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.766810454827436\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.16459469231971\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.96784261802221\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.011549740669395\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.901854994651764\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.3926825573781\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.577770854488094\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.33963146842753\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.52333210460649\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.36361723747236\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.11381896888767\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.67746884526114\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.114194256845806\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-783787.0149815336\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-721548.9463896335\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-814833.7509960899\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-537471.4529483876\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-522607.75108968676\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-647722.1082135765\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-8528.398373786438\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-5304.88683104609\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-6958.155654169989\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-6412.2663426859535\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-11716.971470635177\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-7031.2824858935255\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:32.73875512082901\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:70.8965378297512\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:61.78199510061431\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:41.80908122102137\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:48.36037893103652\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.47544393983764\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:72.67271622698357\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:73.3949362597567\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:74.22932697338227\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:74.43456848697272\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:72.97333204154427\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:73.81886520472167\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.91621884320832\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.25759769554293\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.347845884596296\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.33373901610232\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.884674544376445\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.666183430686814\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.629627325004755\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.25236677312659\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.48622237796432\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.16146754365565\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.68697188216298\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.759729556950695\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-170095.70578957655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-274078.8869890855\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-241343.62902990752\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-132423.94048451813\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-197151.38179547584\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-166647.94545515586\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2088.1017945900594\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1693.2651249605242\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2489.337154407967\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2059.2329958276173\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2173.4679528725624\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1871.4327170024055\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:68.21541571072277\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:72.03474645778078\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:74.7409900921926\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.17481824588927\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:70.74778514222145\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:73.24004236453156\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.4248949870338\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.24960592668577\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:77.1684037901643\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.57504880545739\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.29865459767828\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.26675150218773\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:67.24156169815267\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:69.53634907109142\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:67.68066098868049\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:70.73813253966688\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:64.77910057906504\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:71.09718147351151\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.30060338832649\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.23445124796484\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.62281319857747\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.0882530903269\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.455841239591685\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.09642149246729\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-53905.42179465388\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-21885.92871387142\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-9266.336796281843\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-17898.206241117678\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-54758.97769582281\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-56428.260403115324\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-556.3988040243198\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-483.8490413576717\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-849.4041392854153\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-506.25694972309566\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-457.8421312889966\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-421.25975170691623\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:78.04618389753021\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:77.71603802323247\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:78.58175599171102\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:78.87877759217652\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.7410945379424\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:79.33590660844852\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:81.34448224747622\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:82.38971789901044\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:81.90450697221372\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:80.95743451898637\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:81.56201387641818\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:83.2428717361932\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:76.83755673609022\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:77.79476251585264\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:78.1423914006275\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:76.67491115347855\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:78.07567594051831\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:76.59210196341746\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.07354586347761\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.017062000140626\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.562170758224006\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.45274526107589\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.206541987022995\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.92107378927751\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-5033.174117518936\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5263.805447120757\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3451.5703785222195\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4373.217278037887\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2760.0810780686784\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2889.9127673125813\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:37.81748318690968\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:6.787946348212859\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:44.60207423278908\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-2925.609757206964\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:45.47731696009354\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:44.588675519629106\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:84.69307225130035\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:82.57848676073918\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.98059576040558\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:83.79026227010526\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:82.53538732316383\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:85.92511767754881\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:85.89171714158957\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:87.41771371901575\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:86.02013174588282\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:85.46790610485138\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:86.59561904363035\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:85.72651379785029\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:78.24016166183073\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:78.59950541607431\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:78.32357377119192\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:78.72374867059003\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:78.32792718506545\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:78.42704431690318\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:58.32936943085223\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.90081623009311\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:59.191935547826404\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:58.87489976277729\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:58.64480192464989\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.00745603226132\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-861.0944973379725\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1128.8390089715908\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-290.1853085691484\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-23540.661000491502\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-859.1826721473976\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1414.6837586958263\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:78.63521681140031\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.17209828566904\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:77.91163518355529\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-28.84691245354847\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:77.46982870372474\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:78.83769314151941\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:90.76853795747667\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:86.97054110191486\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:88.378044333488\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:87.87861722862749\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:89.83770086598078\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:89.73612540391977\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:88.805281871987\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:89.22777114666476\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.69574071924879\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.93822007632754\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:88.4421964200218\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:88.9290065500941\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:83.76113675920757\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:83.95931429315543\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:83.49785552594233\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:83.26093717335105\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:83.30202520838913\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:83.55169720753992\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:72.51965204801284\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:70.9522648901628\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:67.82266368753356\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:74.94567407983507\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:69.3125269417574\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:71.8715063540648\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-713.0804416605391\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-9216.540548987421\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-12418.574731945522\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-6014.016697179435\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-18109.430927249556\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-958.2954190301557\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-136.3022893690706\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-43.21592953188198\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:69.84969804942655\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-280.43891833089674\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:67.88592079288853\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:54.34641015163268\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:54.428834520380164\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.090630366259255\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:52.01731259377571\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:52.8194275214223\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:64.94655893298\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:65.02746631537393\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:42.77210482187023\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.855355275238566\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:61.04617298025141\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:57.205034987347815\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:60.435405070618245\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.081642095090565\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.62363005211683\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:44.03356480682995\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:60.30579450517492\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:44.03903675276618\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.354359197795056\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.28290095349951\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.78803280897737\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.054989584747304\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.90579909173121\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:43.56161860897374\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.5834175756684\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.14112288187205\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1711.3605282830854\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1600.5883318312624\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-519.2399762200971\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-791.9573885329227\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1385.7019005092325\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4817.842080407108\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:62.949613645567126\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:71.43587226281494\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:44.30988033142872\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:57.56272426545854\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:67.43884915155722\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:54.146815398436445\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:73.21739746323715\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.91540779665382\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:73.29215792053981\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:65.83910653495337\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.79565287838778\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:72.996967312292\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.10681396107489\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.94435558392364\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.1003815229715\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:57.87919029135513\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:51.60461317753702\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.26453752063032\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.37219567699072\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.322122668396815\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.87936749954548\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.576822641752564\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.51778882161851\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.019303240956425\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:45.0066445707993\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.67327693421791\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:61.411291020324235\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:45.91820679540424\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:50.93285070513534\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.23571566801733\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3208.259052249557\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-299.06058886372455\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1893.2041384649615\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1640.829954756067\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-119.71399564269585\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-728.1619809198041\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:72.33116906679362\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:72.13875011161521\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:72.1206135595756\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:71.87989728482715\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:71.79664370579641\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:65.45927399627047\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:74.06178613268925\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.81504037569977\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.1028243576663\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:74.1707683267135\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.49580312583088\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.18434937870155\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.13825840495345\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.62206057510195\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:62.39315871181592\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:72.98006276806291\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.47699829816254\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:70.78179198047887\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.109579892492924\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:44.639315744428956\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:47.38034519203259\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.366518711837095\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.92388555480328\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.95837214412982\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.192501894642376\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.79855143789045\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:45.69027952268614\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.55255143286864\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.19748992182262\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:40.937523662433364\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-188.36731335795514\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-266.75012331482367\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-855.735312116907\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-545.6715685255983\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-232.55473197774683\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1047.6496595017454\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:71.85531556841141\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.10914599228506\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:71.66882686675112\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:72.42035657237889\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:72.48260072124953\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:71.64065533495965\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:78.43251124999014\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:79.15139357061062\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:77.87548533286326\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:78.77942170093527\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:78.96381727910776\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:78.91429999477756\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:72.93368250108122\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:72.63960074589326\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:72.17529072735232\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:72.89262497115078\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:73.60577270494285\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:72.50783548663225\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.71808667594846\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:48.61426542742784\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:50.84143343628909\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.35866486678638\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:66.8955356422797\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.45438487509557\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.78171216422314\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.63959444358275\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.55696758303801\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.783450709167106\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.960456317691374\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.36336267818796\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:64.41135583100494\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:70.11469284129763\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:68.36139182578493\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:58.068364356050715\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-32.789812696740995\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:69.74474919697165\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.46135587857594\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.4514277644567\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.49537605859804\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.47749633728941\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.40900328255151\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.50225965764412\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:86.67989166540082\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:81.42216737940615\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:81.74685020208172\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:82.45701585185161\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:82.21012962977655\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:81.59249611052121\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:74.08898168891504\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:75.18890576629398\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:73.9482662920129\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:75.01775845474292\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:75.43024451268575\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:74.86433077271855\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:61.941836068628334\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:55.040794303325136\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:58.96465994411797\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:50.95639020920832\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:59.121560348216896\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:60.9540735904958\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.315294533780104\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:59.625134825518614\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.61369170576123\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:64.21442233360688\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.24871343383646\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.82472902306241\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.46312832062031\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:71.43378701146143\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.52250851562776\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.45569281732125\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.46527465146954\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.40283993682681\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46160597384117\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.4630753293199\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.49231966956569\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46150862428502\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.4632150080375\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.46235598721216\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:83.99541575529145\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:89.53018292279766\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:89.96010954639308\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:87.60336735663779\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:94.9018091315637\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:89.56648122146433\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:78.40830540450376\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:79.47966487648169\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:79.30016405616246\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:78.87575008720746\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:79.39944573046186\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:80.16506119493991\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.61436905853387\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:73.67437801744356\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.14090639066283\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:73.30551392643164\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:68.7404337598171\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:70.74822023029492\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.40730589064582\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:47.894993956935416\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.73400393332712\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.527820947369406\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.9282017423822\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.492470220095335\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-8924527.231818547\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-8017672.504474949\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-8026242.168203464\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2875.009255074816\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-55713.49636503239\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-38398.16973891382\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-525.8449751340657\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:53.05383124625804\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-289.2953971880829\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-57.90671430487065\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-197.65078168482742\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:71.93973580150738\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:49.18035367713659\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:52.76671684926142\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:55.213431967018714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.33772276554453\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:54.49596738502957\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:54.83379676303966\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:47.27790975037573\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.9177081754961\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.092483218398215\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:58.161411698029866\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:48.106222322623125\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:47.65931531446388\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.687921773586524\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.20061565524626\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:42.10150211086604\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.05006649215993\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.93218971515283\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:47.055444249940535\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.640311447599686\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:44.964611655948104\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.29655008794192\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.994931597071805\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:44.63963064976429\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:44.33204574177263\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4766.796344730025\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-208.2290865850787\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-832.7833595005333\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-41433.41367464539\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3673.291545894974\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-470.6346931186974\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:51.17115957517151\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:48.81106437520778\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-99.44939038432237\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:63.347559796251396\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:51.46065712726613\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:33.85590492410863\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.3246451758136\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.44437931934804\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.49366264816717\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:73.50033168439512\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:75.07938732773981\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.71299985452747\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:58.532636708354644\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:58.456824885474305\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.39706524415125\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:70.13015724055123\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.23295761592\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:51.47306917336534\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:60.829675366692506\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.771397964986306\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:58.61050150261045\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.13725062253627\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.083539496992785\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:44.51856917053626\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.11103389369305\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:47.96301771786102\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.260081786870764\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:42.265586168677714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.163403924170034\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:42.22142289387513\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-7554.81514355815\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-17976.274639156694\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-22725.129169437056\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-3762.7467054001827\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-660.8598492669721\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-18372.073342614138\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:44.89609180612767\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:52.26508328255186\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:66.3484037720941\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:71.83531053992498\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:71.02806660206511\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:57.49753522910501\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.07510751152338\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.65467894462454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.20115010507281\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.24003692721644\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.94230538545584\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.70281335929889\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.29500697615393\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:68.33578427303861\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.52676623782557\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:69.60257448672873\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:55.13675609519859\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.44775067472946\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:43.342408967638136\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:61.99582710662539\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.823813427142774\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:47.44107737268305\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:59.512912524883156\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.193483252357176\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:47.92780902756303\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.95905751436128\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.0295380385867\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.03825517284109\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.58271091603406\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.548889691631004\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1696.496178917851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-260.3452263148964\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6093.629477210079\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-964.010089847213\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6299.493386559452\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2505.0209261846876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:71.66495834212307\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:70.95752034814834\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:69.94693228538999\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:70.48608851864921\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:70.15814944643783\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.54233223138785\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:86.85319372008784\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:84.59060163456591\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:86.08093560916218\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:83.3665671078026\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:78.9539882806082\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:78.8987835952858\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.76550751638\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.55532054754578\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.28493130535851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:75.45409890213193\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:78.13036441802979\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.4724219884926\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.46602454591305\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.29923113919882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.32885277806726\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:61.16305541531884\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:43.63147791348826\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.41216198970851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:58.63811222467956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.93481132517282\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.039728718634386\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:42.05898888191902\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.7523593055488\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.71979187723686\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-206.44688031352155\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:66.51452352344943\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-147.41556424621146\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-257.78372067931696\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2077.338896406458\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2057.6624335972133\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.56972398036478\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.11728239735812\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.28630275778924\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.53514044485851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.55631509589999\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.1052084878451\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:85.98787255227049\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:80.40042989501998\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:93.2134399365214\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:80.40311209229243\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:80.02217255115885\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.90683269284672\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:80.0551858166243\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:81.50971407508162\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.80589896266717\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:79.05955850091668\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:78.539940844003\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.47341292950935\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:52.25061998710658\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:55.101837816085286\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:61.280369091635144\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.72185005070283\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:59.59063325814134\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:51.68288529911456\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:51.46186522569969\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:59.42860199556848\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.984427927069255\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.344164482327415\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:48.24904691196033\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.47404173032988\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.46706326051056\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.45771139038182\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.45773694193956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.4477846102042\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.41312392214512\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.46178686383956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46138522529151\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46139959804275\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.4614203586834\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46142195565575\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.46149781184275\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.46148024514682\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.31301601384924\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:81.52852705184449\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:92.07456871174375\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:89.04083725901641\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:80.6471320507656\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.19997453839879\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:91.78626160977674\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:80.53912472969157\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:80.2523381861295\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:93.56583306247367\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:80.48942738907651\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.01262750303398\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:75.90980752539316\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:75.55619822044463\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.8030295095827\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:71.1577085644547\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.84599660474358\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:69.41916608641334\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:47.62755234566517\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:51.54103698125263\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.20168669306922\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.95096011397594\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:45.42512437835089\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:52.34575470582155\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-7224.596242100541\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-465.07121146993427\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-7401.663189971418\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-459.21630363374175\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-505.3924915262617\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-12608.300394068749\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:72.03940245182707\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:63.3822449931392\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-20.537851437327426\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:19.933990120793823\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:62.985764083381326\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:65.33466751318076\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.594231956487945\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:51.944063260998654\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:53.84372315179466\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.09513580024101\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:47.268105072238676\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:63.184998987038554\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.06997888576947\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.200339037663724\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.22339631423319\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.980320624895604\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.0610669798462\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.90180974693821\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.51918942999708\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:44.66059904360602\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.39407721192372\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.320356144690905\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:46.54286979125934\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.04970846092072\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:43.974266643360714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:42.96861693462676\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:44.70360678091493\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:42.855938869822765\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:46.340871752012994\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.451259314872985\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4696.97822949565\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1742.0837185907026\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-744.2788225539188\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1947.7947018670698\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1949.499406205847\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4154.960102054245\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:60.481644428274215\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:49.086043870383314\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:72.46428735618802\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:67.94599832936099\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:71.10755944270801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:38.799425896177894\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.81589526994853\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.60751657095173\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:66.9529697104079\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.76732995850162\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:69.91241617029911\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:72.5613465264052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.64043738552676\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:52.128176473321844\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:56.09969993549788\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.5221098987393\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:52.30156446978085\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.86921479609934\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.08623662240175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:49.3064116977208\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:48.05597582548692\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.8572512946794\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.2778775976623\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.10140843035387\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.32913333154669\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.329001758344496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:46.480797067977385\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.662884914893816\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.062361348106265\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.98112594482465\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-755.8201052618365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:40.842968014115144\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1621.7240435011843\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-347.19571052713604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1005.0864118210812\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3338.628620120651\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:71.25900486870202\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:72.52229325314785\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:69.8662834622148\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:69.31740218396259\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:71.94763494345784\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:68.37888335129519\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:75.34977014464971\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.26534503158196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:72.23013615965186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.14764385170783\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:74.49832447313528\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.3268442204658\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.93599380988412\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.84428935862603\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.32445252176531\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:59.521878061565104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.77405059215495\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.633438980795425\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.59826066580413\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.53682013554682\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:50.9496330632186\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.45253292707781\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.286618169693604\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:48.01507996552286\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:48.19599236497455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.5963498605951\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.36904400911174\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.73248572063971\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:46.50557183134359\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:45.33348913804295\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1010.4701576503456\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-258.5678317022662\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-205.9451840448041\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-85.50560254577204\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-771.5839602423052\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-897.2825584682167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:71.80187261602464\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:71.64145127537684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:71.03548294169588\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:78.18893783669287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:72.56177970046036\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.306188605168\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.13544473195283\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.00084797827816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:80.14727975788597\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.02811240511113\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.63474329951431\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:81.2415326881634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:72.07356392632703\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:71.82852062679257\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:71.96139802699768\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:72.2465954773815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:72.71984198414687\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:72.07653564764254\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:50.99161268337398\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:61.16233316813049\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:47.559108256330816\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:56.30563471475109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:57.98002975582606\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:46.52288257371168\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.447922492797574\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.73867491052036\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:45.17377457861077\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.99429981559632\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.811302608115355\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.14763871076025\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:65.05759857694777\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:55.98641688237518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-29.292430268957247\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:52.25669632895524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-28.303549475703683\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:63.79514383086076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.52445191826004\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:77.7494046892868\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:48.973425924543136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.34114732584491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.44589539190463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.48254852279891\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:88.9641204483402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:82.50018137942345\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:86.8540851500581\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:79.67241252379871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:87.48774937257888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:85.54530175912089\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:75.11915323582102\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:74.62910962349041\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:74.55526758499084\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:74.81409258688407\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:74.97243797619386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:73.53764631505835\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.491817403253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:59.37215068661574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:50.328687776887016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:61.24322267852496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.94415793583749\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:59.85003240565037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:42.41240272567064\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.04567658013486\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.239329197234866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:50.49004891932809\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:58.734875745995005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:44.86540279771701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.45981939389445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.4608414562036\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.46056038906859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.43389733857862\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.46293668393736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.45905284716258\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46144032083785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46145357570843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.40108535269098\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46144032083785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.45486169654238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.46142910445555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:94.83090080643753\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.32263047418978\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.06603445938198\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.47154588183612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.24670703660982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.4689989066481\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:84.31247842708754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:82.52039163882006\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:84.2512389709564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:85.3954008061929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:84.16484521189668\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.03084397409918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:61.658101712652226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:68.68591832776441\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.68685180564111\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.3827551690681\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.80419144882191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:69.05458422041578\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.91701960643509\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.782358119955575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:49.68046812477124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.53325174604464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:47.032966599208905\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:44.52827596072609\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-204.1784448826567\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-487.5716518284864\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6171.710618412147\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-8340.892794754112\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-6415.297498169427\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3218.730743744882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-4.8479787142282404\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:42.283775942169655\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:46.96617888549447\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:28.61474312084504\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:66.44319957217616\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:58.9733475254125\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.67397970562381\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.494335261736445\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:48.442244031257374\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:65.33849854653423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:50.11883208350556\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.29827031631747\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.30557788818065\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:48.07743557308301\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.10181414214432\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:49.74494131782493\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.24330300803115\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:45.218947961914715\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.45467637675405\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.55300795487101\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.66677241774174\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.6572649666087\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.98956396769501\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:39.93361772421874\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.35664272815624\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.88715800621831\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.72057221001462\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:58.089996108725096\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.537888616708024\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.29145974666467\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-9152.809847688186\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-2976.456964551416\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-5353.447287960068\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3592.5714082469894\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-2116.3262276315054\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-3662.906803645141\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:59.439950763380736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:62.79066676131564\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:55.76874964626124\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:65.16861820709433\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:68.27299648424695\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:48.19129219761601\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:79.00734201977815\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.36904593017555\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.63021223896409\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:78.19303476829243\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.43726045339477\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:77.10326476018197\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:59.999781867402625\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.76456165792225\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.48160944913108\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:54.35420633047832\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:52.22060113053231\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:57.76804033534746\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.24160708927375\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.7524322748105\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:48.8306631500722\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.88848599153031\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:48.713885781401444\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.82331443836925\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:59.9119715457173\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.25855353599087\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.56483660933067\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.94334361783814\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:62.82773239580639\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:46.46992767163625\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-38.59983439329009\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-524.6185125376503\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1630.4061860715055\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1074.683399365773\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-399.8966132119662\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1916.895812435165\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:75.54849529942722\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:67.98477443397468\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:70.62765377022508\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:65.03895080587449\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:72.69572884760287\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:74.32670171942834\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.61930570121446\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.7105583832713\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.62067002288181\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.99981868633424\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.31019673439535\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.92802414507074\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:76.05807238014032\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:57.49464793992358\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.92947882908808\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:72.56598258148834\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:74.09406034459364\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.8832876682986\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:49.18889968242816\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.83184808716941\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.7541184285619\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.22894964096488\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.85254797701107\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:50.99881488163467\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:44.74893349000466\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.13232986064198\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.69647198798937\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.29880532280633\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:42.6583884784422\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:43.658720176458544\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-203.0215926016288\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-239.51087091925393\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-133.01940125870462\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-398.5466235636538\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-403.394843012071\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-334.1884646103831\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.67303192004901\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:74.7411252571148\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:73.67397483828691\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:77.90037770267544\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:76.28647839111828\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:76.1391061182751\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:82.30486580055468\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.2257700237916\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:85.50698263754141\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:82.52321445772833\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:82.134586226245\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:82.76394804083897\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.37808830259915\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.2082413886949\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.79321699114509\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.54810458864985\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.65434686831361\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.70385093358767\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.740869159957754\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:53.66384726725195\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.228091406695384\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.55888557032491\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:45.424068743220644\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.59774723008621\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.46038808041289\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.59146147301763\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.85386613411777\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.075413332129195\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:47.23373552926701\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.66622665082379\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:76.18110219355734\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:57.096910786685086\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:70.64667629199859\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:60.70364042001037\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-121.21190220657722\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-0.022998205595259336\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:78.5869354051901\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.66159335170983\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:78.62028666515816\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:78.45011911963364\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:73.89210526449085\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.37148480719709\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:91.41354410959755\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:92.7401824623135\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.82687061409766\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:82.94942983029112\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:84.38114931115585\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:83.68651152502561\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:81.05960099057384\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:80.53706970338844\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:81.547737962341\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:81.31631416091776\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:81.23992429275603\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:80.2649343420052\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:54.50930892246928\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.286977175538055\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.64208306082128\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:56.758975313346724\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.12734425431918\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:60.04946352202089\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.50402139882293\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:47.43397102711049\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.90622515309458\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.66234198085806\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.32813285837219\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.0404226503227\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.21591053655338\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.57550241817538\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:70.49525375907302\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:71.85255987048619\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:74.71244690266062\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:50.61874562497211\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.9983755029779\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:75.44444534513686\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:77.89181128931007\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:76.61807053290173\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:75.54296717294284\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:80.25967333145833\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:95.6543945087233\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.0640490389509\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:90.68718567150047\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.33355993302531\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.8610093958083\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.97107098758268\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:84.25058350025715\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:82.5270571936013\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:92.59754011159436\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:83.35574032332222\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:83.59889874838063\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:89.79429294148987\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.76902535452065\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.06681281614716\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.97797935444882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.76870694601507\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.20874223336168\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.555940265586\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:46.41448911646392\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.97916653726494\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:45.93416701112797\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.69223016462897\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.197289662369606\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.63187774889013\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-12478.504456865026\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-645.8897056309044\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-9179.977438635859\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-28907.964092281698\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-52021.63596728169\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-25198.371356937056\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:54.35770178423611\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-827.6463767879117\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-563.6472254122591\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-279.1117171399513\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:33.45884311095855\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-147.67035528653435\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:67.72465914417384\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:64.73977490144043\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:62.60268336633137\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:63.87213360051456\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:63.37075456331056\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:66.41141552921353\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.190169039053934\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.91492880125794\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:48.994545539337594\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.56712523167344\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:57.62613832339984\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.080953549220865\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.886971134619046\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.59567347626877\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.121743362963535\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:58.24230604043996\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.69164875297681\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.50033316809986\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.67063114728112\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.46373685698889\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.24448338266055\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:47.552403521711575\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.342245190725066\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.78730330688451\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-8105.621316246952\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-7300.029478681849\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-28219.13556038065\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-7920.62070589539\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-49852.36920295877\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-56938.42877327128\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:61.58814279933536\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-49.944596632528345\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:57.75147513013077\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:57.79584639649207\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:69.01442442849643\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:45.62997743780919\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:73.57872714199732\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:73.27859331248219\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:74.83630832299366\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.76755692547377\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.54630670066516\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.40990756364015\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.91454330554059\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:66.83275921782516\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.14633185718827\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.21933694990531\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:69.0545765267666\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:61.60821009095585\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.989550527270325\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:46.31681673586885\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:48.63334752507713\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:50.736467941855715\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.99856415395665\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.80045041181234\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.49511740674318\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.2879574992015\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.55115599823431\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:45.86961735436257\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.99086723786062\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.35725323990914\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1576.3444481166541\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-10253.312152835495\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-12891.99318310893\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-6880.208311689661\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6404.130067216589\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-13710.428852054243\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:71.4922412537138\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:71.44516390829784\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:63.24513954285847\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:69.67183219061958\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:71.71904411345979\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:55.435080975411545\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.55525934123166\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.62640316379267\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:77.75977352550407\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.34127575887105\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:74.46142767619861\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.24584653435775\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:71.29270812486268\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.60014789624887\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:73.49763895415057\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.55477679856092\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:70.53502799959234\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.79092365592554\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.448160876713004\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.927306208392594\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.411130365421684\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.269854420043046\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.37473363964176\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.934894372855155\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.12343951709821\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.038725778260876\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.59761707501749\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.31157025976665\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.22417630463063\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.88273685760767\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-547.4370537074745\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5556.728595706588\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-125.55749636169868\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5171.006753258671\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4483.91416292664\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2182.916790035599\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:72.20441018435973\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.11205768622781\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.35685786081167\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:71.86053169346683\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:72.06339909393455\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.28374265140205\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:78.96370336800884\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:78.48826417122609\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:80.28069760289316\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:80.2346476919544\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.94900477552527\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:80.06569196663098\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.18236104027318\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:73.84148825802515\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.63430077941328\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:73.90807097685253\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:73.94387328408665\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:73.68709800560893\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.002851676245776\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:52.79870984871806\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.97340817767114\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.2827710220436\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.67399594761941\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:48.18659164451821\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.91256879374584\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:50.04803712492247\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.61074148547096\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.93864171344338\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.56038179291431\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.963383779411146\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-15.124490075077567\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-18.638843509322367\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-76.55400215311252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-64.51286694682237\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-33.332719194128146\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:45.926560746862535\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.33441559887008\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.56290477688054\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.54968450424519\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.62701498795157\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.53250044288365\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.58646770008347\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:84.34616416704476\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:90.16669749614759\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:89.81606693978004\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:88.43302378699572\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:88.36441645949164\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:82.08920006795108\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:76.49318379995107\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:75.86296985147504\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:76.44655867483411\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:75.65473654403566\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:75.76187794559861\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.38040316020344\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:71.78327410685161\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:66.23134032490687\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:69.65923362402017\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:70.6164243608314\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:68.28949348113026\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.63811578705518\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:51.06932193883369\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.01863584339243\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.4656752107461\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.027417762059684\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.189106939309134\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.768391873702186\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.4644953289588\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.45656157028402\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:26.126561773584246\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:71.5388951290302\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:61.78255703056581\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.47636402752381\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.4623538453904\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.4614522699487\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.45706156354142\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.461515942176\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.49271740022844\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.45373304102532\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.13284954844356\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.16161825494376\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.59706599126189\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:95.17675956419079\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.56525323762492\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.22263783836478\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:79.6317549274135\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:80.7190132725887\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:80.37622004183753\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:80.32873669555565\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:80.07131650679877\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:79.93912984763101\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:73.45278216122266\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:73.38897037731557\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:73.92651060606383\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:73.40386202243296\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:73.35710668300813\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:73.41311553785235\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:52.15492704802489\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.29473140551595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.56934360475217\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.64532553041142\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.91787280354845\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:50.48913188818827\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1443980.0890911275\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-71694397.75413711\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-33315436.68704442\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-18225797.63347124\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1960243.2736468185\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-62319312.87923561\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-4661.551176872284\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-14846.851593570696\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2877.3556207276597\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-9162.006495710995\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1410.2075270539294\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-27.42946418464607\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.261699439034494\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:57.33269886697157\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:62.25271060816222\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.23911738489631\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.56750303774579\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:57.682521775118275\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.08862664151886\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:50.78035171479105\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:49.91251401855684\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.150759775352995\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.988369696904954\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.749167973467735\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:58.25472459067878\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:45.03526533208934\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.9298879066739\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:58.628419695687725\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.09210533871249\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.76367795214913\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.312300910622795\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.2633991037841\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:55.12237755436424\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:48.88247320717648\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.603328777331825\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.04144213241771\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-905.0150336948692\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-7303.53700894836\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-2331.5389213832555\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3742.5788662957807\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-5600.551881181434\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-695.0948931646685\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-55.162996265059675\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-43.76497843586806\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:29.641840643916563\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:35.69616256876195\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:34.42663174148992\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-102.42714306986925\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.51542830523587\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.73537383256134\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.44976607300899\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.53423419122717\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:75.82046576989177\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.82432502306193\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.14090417594397\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.8137658082941\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:59.11988508663748\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:67.40961569890533\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.21875107018284\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:61.87643667343943\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.635030715765204\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.11937851913808\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.94782032525803\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:52.80768248899139\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.14406909758975\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.56527662770405\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.01091605760715\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.212012829985596\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.10195619174352\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:47.07464695657868\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:45.65472558692649\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:46.540377066537474\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-30753.7424939744\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-45356.00689827127\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-49168.10198844748\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-8212.580341312056\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-27588.402281416224\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-16228.028382646275\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:19.876740587518572\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-14.88353588902358\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:5.669059144689681\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:1.5642223628700158\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:48.13538612203395\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:71.85107300467526\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:73.70523917008047\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.186423689855\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.75499066825547\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.3659530963552\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:81.07814088968708\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.85962108479794\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:69.3654124242664\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:72.16135401064435\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.57370185532656\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.6990723397621\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:69.66568952098994\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.61712341631745\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.86198309014594\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.310567467230534\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.42120318941426\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:50.06567293747237\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:49.588354615901196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:49.36342957312897\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.72310438922441\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:58.165099273947305\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.15756424225815\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.825563147461516\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.166732708683526\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.78914084403803\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1554.1908047723432\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-31525.98162711935\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-155494.0277316046\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-23877.36716845357\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-12444.510883304245\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-8101.552305830286\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:55.32075394975378\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:62.20236407010174\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:65.05431798239032\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:70.70908834842173\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:63.87908069799977\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:66.02681385803824\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.45270002855852\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:82.96420493165371\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:80.11845166613682\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.19033294178728\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:87.18600700792128\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:81.13415113248817\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.26276012928679\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.12010705029523\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.05788178346211\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.71641186525542\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.1864338636962\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.77986342856225\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.28332848509905\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.37559685785063\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:54.51066605071555\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:55.68598406851714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.01595452164833\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:49.09174700214037\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:48.939062865455384\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.170416656690755\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.61045037340328\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.28397930836799\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:47.89748425919114\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:42.83575374160441\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1990.3440056117713\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:41.58774436788356\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:34.40083442850316\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-38.01201759500705\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-73.00285718119737\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-461.42332334044977\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.53093708209676\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.9668963088869\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.35810662743799\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.10799201066519\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.4427911030955\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.45264136950927\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:84.90241317590736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.96847655427466\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:82.4745374485862\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:86.46049417666886\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:93.95439292475217\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:89.69869053298044\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:79.65640695288577\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:79.3098617577008\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:82.15777787333684\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:80.30853888902071\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:83.47622506141404\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:79.15867462789477\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:59.34572846425434\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:70.11506190160956\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.49679699312334\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:71.45219934183937\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:68.9488613436408\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.53237745013175\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.18367113871683\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.61843821368788\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:47.304960164711915\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.804538007769835\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:52.24624991745719\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.196595596294884\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.38178493659078\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.38308167814552\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.5249119872085\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.50669372654788\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.36108178694103\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.52497586610282\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46120875984595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.4612941978671\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46116164916138\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46121674470774\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.46105145806867\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.4611033596703\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.86862223349377\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:92.91333028234958\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.15802140819265\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.99756070588685\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.08285136111051\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.25930528813596\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:80.95079471127455\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:93.7981943069268\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:82.18072486367632\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:92.51810248942651\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:85.0169560852203\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.34285119746593\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.32432406799614\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.12533852291259\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.65991044739647\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.5076064843658\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.98825731119648\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.30387940568374\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:46.101527640535856\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:51.59646719738171\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:52.53852182093617\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.66108576073903\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.55249975073329\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.021076922521424\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-14027.614810543795\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-14025.742974367737\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-5835.339170295108\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1006.0671244952696\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-733.7780320428317\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-7571.6171120357285\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:46.24591794325856\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:64.94462499945439\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:10.5408489938981\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:53.308643949041226\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-81.3291374579295\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:4.331682571940199\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:62.30725050207384\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.1646719957732\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.68803769237325\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:52.98559825142319\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:57.3702490451864\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.22415348936761\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.65049608478028\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.26592508503263\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.922269675560685\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.26993414776076\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:49.0392294001213\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.37179721592447\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.96154580490151\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.707271044206394\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.32957691072808\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:46.684628038118916\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.82781946010904\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.23161805573178\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.27218828201764\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.953762698234584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.875712417612114\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:47.68886036636606\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:55.20762608241998\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.9332826279274\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3613.31738411112\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-9011.880471520391\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-918.5082537062625\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3971.4459520705204\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-8871.996074703568\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2319.702678707474\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:65.26515879341707\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:29.415839501870156\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:65.71247136151348\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-40.70161194947877\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:69.0502954525117\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:60.86189916887277\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:71.90584554927757\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.73330150202939\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.78450301465695\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:71.87455444471212\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.09965943651373\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.77973137397856\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:59.04643150227007\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:65.72565184605226\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.64224354773641\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:60.219061640043535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.95173368856041\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:60.672765796441944\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.86743845396667\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.91053160228909\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:46.30147848686333\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:60.28223252371598\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.59569442495293\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.24112099190401\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:49.538307924666114\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.07197639353168\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.011290719146984\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.308261929556934\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.880567835260784\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.582023732828006\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4605.699179358517\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1958.8777961460412\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3664.9876695998173\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-4832.695537594193\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5482.895893069869\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6939.53194043315\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:72.25380559151712\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:71.73283416704459\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:67.80124781543199\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:48.057066445467136\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:70.06599889955152\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:55.504066123090645\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.18465695717468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.7153806671371\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.06038832082065\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:80.42441025270638\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.7767482703835\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:79.03889216617678\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.4170662268961\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.94312100789976\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.87889303439616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:69.32601805650127\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:66.37578125165334\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.52466680047266\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.86146913197587\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.9934052627701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.11029402210639\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.0311069991102\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.3260096374274\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:50.96454632925742\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.572573022169806\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.642683480319484\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.02521700120236\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.216239060587164\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.677767267792696\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.37840209053528\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:19.771458916630312\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-563.7971458705605\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-300.42501363912095\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1140.5711911248823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-758.7980053949018\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-585.9783591953575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:64.43092729089015\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:79.85229383687319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:72.13998400761068\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:72.18307418274634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:71.68322359134682\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:71.7720567193719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:82.1070820727247\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:80.99317647182069\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.0630807943284\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.18795729040443\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:84.23562115388559\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:81.67032902051935\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:71.37383175610181\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:71.9721750258648\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:72.76969253782028\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:71.45406042524358\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:71.67346685114951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:71.45396181689745\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.840287690091266\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:49.158960737587435\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:52.673283357311185\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.68673901744863\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.13980323494279\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.23312250585233\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.89897936530899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:50.87887539584821\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.04100623172601\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.432918590293134\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.74121868255761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.011003286374475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-609.9466540289263\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-102.60358431660536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-12.41714734557673\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:60.61794320084712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:66.95867798476824\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:69.69168199339282\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:80.07761147944734\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.46885203864275\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.30104135659099\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.3691372349095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:79.64383534693737\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:79.24519293509289\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:91.13199331799862\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.39203469418841\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:88.9059896082555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:88.42143366381914\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:88.9782903558913\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.98458891980191\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:75.3454232704367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:75.87157964142783\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:75.49812083548689\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:75.66263602416848\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:76.80934344904924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.25051379823798\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:60.9594626864455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:58.31565733872783\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.46781559099448\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:56.03953625763185\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:61.964558075505785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:59.39756311752178\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.22627147776204\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.900807959343894\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.95553681872038\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.33844106288008\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:49.986059086836164\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.357550508305266\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-817.8995551792442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.46416315870835\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.45947444786512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.51358663500342\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.4595511025383\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.4621318098689\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:80.3739052480182\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:71.65553535975462\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46151577308481\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:84.6603349966736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.46158721411294\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:74.2312759466299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:94.61356696531095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.38352659403385\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.1518062054876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.79069667054124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.39020549311611\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:93.48878223446057\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:87.97363149217962\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:87.80535538192807\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.8918085029221\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.77447004201753\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:88.92002184739538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:89.58559451115423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:72.17559336300813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:70.71123202547865\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:71.61412895712165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:70.48216516150556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.01085695607912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.8726771903658\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.54969499616571\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.99352425952142\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.30891891071607\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:48.27497425137588\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.31589788637638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:49.98387641782034\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-9253.978960564797\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-9819.512760291615\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-8250.595482960754\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-6536.156470536998\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-3773.001826701904\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-12505.154097897504\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:30.95017108887176\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:60.04314395834649\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:64.53443764231166\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-43.71376079635605\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:66.47043043088499\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:25.215670806953916\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:56.28875608081137\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.617820031124836\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.82067133582558\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.55390645595306\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.496062019944105\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:58.944614341965426\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:47.73801295857339\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.39761480878102\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:47.965679590724605\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:49.21417305285626\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:49.18528398377065\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.820676629973896\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:46.19448820233251\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.46499961780471\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.83025540939883\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.08839352001489\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.37933502887018\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.446249600925526\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:47.227078449007465\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.39800159007287\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.07251373589789\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:45.34047476131208\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.34751175490771\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:54.4398137752093\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-12468.977254352014\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-27288.647427269563\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-15953.06495804783\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-14898.722041245048\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-11775.316767395718\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-13087.887008402458\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-36.69772050435191\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-84.69261900001479\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-110.9194892471094\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:63.087458108897465\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:35.342520329781266\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:44.47730299851573\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.17628167183311\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:78.10742752266925\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:78.48162813107736\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.69805953289412\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.04048476738663\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.88726144909295\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.131698694083056\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.90693346100403\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.921465522149504\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.40776052042384\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:69.49082032973321\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.50097833948989\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:49.080579228540685\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.0677156831755\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.08561706528879\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:48.12338863293236\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.17506758272177\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.02292321335855\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.36767580809909\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.581250150587444\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.776721471003235\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:50.60576472748468\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:46.161965984143635\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.88716592377241\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-6336.993814360166\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4338.202204903436\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-2994.3016438525524\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5407.429412108317\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3209.30716655121\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-8549.814797349572\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:41.95776916658719\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:68.47657022558865\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:72.9537661569714\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:65.50109017261659\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:33.67672774902566\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:60.47206039594044\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:80.55714175069868\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:82.25722729901426\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.46536877974458\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:81.98488298671465\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.37239876546852\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:80.98259954540818\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.52593369841858\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:73.56817508050312\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.79870573569227\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:73.63922868108918\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:73.74262018488842\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:74.48685921675771\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.391482974432705\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:46.25608811552737\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:49.29028089834161\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:48.15896047239608\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.9262587085918\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:50.551610900759925\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.23633204493306\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.59911898053285\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.735262583415754\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.99389872219123\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.96694139840918\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:47.65138383969442\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-968.0094585914702\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-744.9987073316641\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1021.8222708848634\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1586.0060785773048\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-969.8437126346043\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1119.2494953777773\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:70.27982555100823\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:70.11870570404497\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:75.94314862932156\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:73.07324751424827\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:69.51597411393931\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:67.00105883175225\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:86.79683032211494\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:87.27871167251122\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:88.86877586279824\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:90.69343262342508\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:89.06335569184253\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:87.18225315412825\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.63828249340268\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:78.36682198729169\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:79.476392482847\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.65304535444183\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.12604112480454\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:79.07894879720453\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.476710576150154\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.13483887796353\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:51.63255968931813\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:58.33442503126989\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:59.1915374470565\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.01145597307746\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:48.83721005773337\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.012561769913845\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.361142458727365\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.41937719475715\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.94727931067735\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.75808565021501\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:27.008803384899625\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:3.0790052421455605\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-24.721050938815935\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-22.72629764157077\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-12.159746025752781\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-90.66949897718015\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.15048061984086\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:75.01599466453114\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:74.25364491693422\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:74.35590609778937\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.00917093785753\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:62.14625454963523\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.86134355367875\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:94.1380395751426\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:93.0065480471127\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:92.81590232659363\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.62152614205536\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.88293176203662\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:83.81558637963306\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:83.85017706393913\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:82.15851394754634\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:83.46263684326499\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:85.96958013925146\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:82.46407758230248\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:75.34245931821559\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:71.19774171470468\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:68.67472102984469\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:75.49628741067517\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:75.40161203361102\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.56204807669089\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.3900349842791\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.53988450581253\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:51.89636904875461\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:50.10325725243916\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.01012209283262\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:50.185700439039984\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:63.13723807639264\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-260.2652144676311\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:73.67526100224825\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:69.48089629670031\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:74.80122932211633\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:68.71314390707053\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:76.17402131675829\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:76.33496081739828\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:78.07619055018263\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:75.14012545652517\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:74.63672422254245\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:74.74899904478056\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:95.48427829998887\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:95.6783973931139\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:94.20789579843986\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:95.75320176833064\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:95.65571491599928\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:95.46165913226005\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:92.65813449290533\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:93.16783938718368\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:93.74422263955864\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:93.92262442783108\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:94.10852954155634\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.5471346728809\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.51322740316391\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:78.37553461874161\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:78.71281446447233\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:78.94491695624998\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:78.3197776369686\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:78.98717160271356\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:51.80308763510229\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.55064636332674\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.98049076110525\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.59775065108723\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.1298260468376\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.537151725027776\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-64877.352926917105\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-45771.45482417258\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1865.4962787673267\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-34048.46702196919\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-78011.75834349143\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-94329.88991162456\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:59.93061262946884\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-836.9711128156705\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:72.034036004703\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-805.2529679968002\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-168.99630950134133\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-302.1008816922716\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:69.06547242961972\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:71.47922873778828\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:71.87752071753368\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:72.37002490729775\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:59.22766167691038\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:72.01073570830133\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.4527697504694\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.563153795410656\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:48.405382599625845\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.12307523713513\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.430609447924155\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:59.24599577443068\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.96691303332084\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.54187256560446\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.142255957785146\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:41.671676155241386\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.27204953177507\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:46.72403377609238\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.80383507196091\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.64071140416595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.649210086199496\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:46.61119445935304\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:43.87511672984906\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.76193263104012\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-58240.599575899454\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-25021.265687333776\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-70433.7249972296\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-21598.595210226435\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-24958.727017305704\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-19663.56713405456\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-133.1568584186623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-79.64165603391197\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:27.361786844600744\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-122.0597615102974\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-142.6859955227779\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-164.06542193335372\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.11648251561314\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.43283952682201\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:67.79956705838887\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:75.91904995477134\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:70.21387061140874\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:69.03412924496746\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:72.41447843652338\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.87840462783079\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:72.61655457476353\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:70.95435342044696\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:72.79335973392423\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:72.05307665915824\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.0369470822966\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.76385746920927\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.04774001383988\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.80900252250538\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.25447668765736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.790911182561565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.74481432552034\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.60401450914836\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:45.573576654243695\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:45.959434099935756\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.11166536552029\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.968921487999765\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2341.3739702662115\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-47680.00384391623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-51956.76774550274\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-46220.04290641623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5211.381523547161\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-45103.154406536276\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-54.012135467348955\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-70.14692693925262\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:30.769282255330545\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:10.264315400375345\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:58.49646562849846\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-21.01897058569604\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:77.64217823955184\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.55816619259058\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.8174160875797\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.1721919187887\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.98348023141811\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.29015354587865\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.98637636070463\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:73.34671758872679\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:73.5337711301162\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:72.74110747473365\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:73.12126642517258\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.7525071049413\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:62.41412674516462\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.097789982813744\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.43520064030791\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:61.21479946388983\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:58.20647130292451\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.53886192421729\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.57972441018333\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.85553126639508\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.89433412323137\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.18387450389359\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.66617348277611\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:48.95050394091201\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-4632.145726990756\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-15525.928614551012\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-13980.299835565806\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2641.926596350703\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2566.5251891945554\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-17873.03798666519\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:69.86840857211956\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:70.46490473668344\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:71.57786109486935\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:48.864141667894344\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:70.91379913408235\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:61.768738964207074\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:80.75034345013594\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.10629637660334\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.5708333998801\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:79.30913287133473\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:81.20091369388797\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:82.26497589226686\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:74.70187481413497\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:75.2475444635507\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:74.77451092244323\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:74.42554774671393\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:75.63637881602143\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:74.44771222001083\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.48616664911276\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:70.5615054443185\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.338997859293514\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:63.262315083902784\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:67.21559422893539\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:69.00348390905381\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:47.34241556320442\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.96897154593205\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.827199277631685\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.866057165994526\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.477505564971466\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:59.46325209781445\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-138.79049044128854\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-27.814505286250558\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-345.3030484787962\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-7303.308927928302\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-173.05458961649146\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-82.3958940257981\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.59233323864527\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.42377225200994\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.4604651343644\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.35131695854842\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:71.6018075826508\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.01425716386619\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:92.22263221763268\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:83.17929177396029\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:83.81440995468033\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:82.5376106621338\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:87.19238926743878\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.36866648752357\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:75.91893932685973\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:77.89580991551856\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:77.7920861052565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:77.59615159861397\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:78.11970739640806\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:76.7595143464722\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:72.60889484715143\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:73.14249393599911\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:72.71628950034848\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:73.00772840719321\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.55670433442738\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.9338862559662\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.55873095740287\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.61630431538589\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.25173640331009\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.10065971588507\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.3386483248103\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.16069513013317\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-238.35103145446053\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.42909605057808\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-64.90506111307346\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.49283260769315\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:46.54917739525472\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.43801128967621\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:73.64303513339789\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.27315411406113\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.4861513262569\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.44712662941082\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.45865404558896\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.46088058202638\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.81879542589516\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.25552147312179\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.3043815976433\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:94.73243484330797\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:94.81026624675056\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:93.44066918847409\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:80.89675840057896\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:90.00760136426106\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:81.27348241245798\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:81.08939501457651\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:84.64615195285063\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:83.44395215629686\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:73.72821881322056\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:73.63765018957633\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:73.48721529011468\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:73.84671965765146\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.00600004609501\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:73.65588515268901\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.94923817186115\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.57660853688975\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.107813634019465\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.78788936664214\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:61.40407307632707\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.465298887779625\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-220139250.42356187\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-89801867.05329\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-225657681.0185185\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-10495499.747586682\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-10179308.796604117\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-49586528.74310481\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-6552.571408066625\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-23205.4417290774\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-8213.149274701298\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-27908.704053369256\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1238.5698421439192\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-23161.210766995955\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:70.56348640398306\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:68.6715528239783\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:71.6024661270815\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:62.711172403549\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:69.60414962518675\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.95851620437593\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.13803775406569\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.78560586675556\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:47.84057600243153\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.495023889814995\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.94841658827167\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:49.43143979061345\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.36917217516166\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.03696087568739\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.98368751322828\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.35937373727631\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:48.779756400273286\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.26316578782819\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.317199137065494\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.29705686344699\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.834474473234664\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:55.25732410468389\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.36581652829317\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:48.31444374700293\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-21000.637795739138\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-9429.91737744487\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-57902.72320686503\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-15709.867328616743\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-30486.16640347961\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-28734.563213375448\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-337.3240890232384\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-421.8743425734499\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-347.19464998718695\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-325.3155491876264\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:23.431410603489443\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-71.04519783182346\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.24590663218517\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.30758429343913\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:73.17640508038497\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.41094641313485\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:73.71980152419461\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:72.67785384205968\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:74.98633883147845\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:75.81938805309593\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:70.5734133720398\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:69.12793925280079\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:68.05243703960151\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:71.7937464409686\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.20011019288695\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.83591160976378\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.283794743002304\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.49705547099042\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.302459686794926\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.64089078472016\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.907340248226184\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.14918607199481\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.83183641806891\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.34176899424634\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:47.63933474783638\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.15359207454972\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-114461.04225537456\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-145662.0269558954\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-97252.87376025044\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-141181.21848681296\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-173672.31341422873\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-100334.4818331671\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-95.10818102681044\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:51.8086918244407\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:15.227498399450424\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-230.43291348937558\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-49.52180960499648\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-118.44089251038032\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:76.53963384523084\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:82.80080279278135\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.58276919589633\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:73.88311555011711\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:73.09064398232738\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:80.07937975527265\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:76.92674978029268\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:78.25931199335318\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:77.00320115889781\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.6247412976174\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:78.1005501606222\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.99505647756247\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.43853205658489\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.72087435079101\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.07262603849336\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.07443840537512\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.84625680667148\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.061357970039055\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.0428263938643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.896256226033465\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.375546905204025\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.2554174743393\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.00386083247015\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:54.72963411123195\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-63586.24977490581\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-25079.830954260862\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-69539.13470329122\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-118984.63645556294\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3052.5441271193486\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-81340.74810920878\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:24.341943078007265\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-22.590722428991427\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:65.15055009941119\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:71.68849052830508\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:3.062206718093119\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:42.52176504608587\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:72.55972100581778\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:82.2669538247294\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:83.56470642031601\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:84.41091899424674\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.38616422314264\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:73.23838275093277\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:78.32676842515163\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.39263154100114\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:78.81288954458245\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:78.39422087861008\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.79399478745518\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:81.07286115816204\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.77624491747202\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:66.80102337994288\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.78083579750677\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:58.86081337834832\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:67.95620033833059\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:68.31414736190868\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.516275904186124\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.86153052020978\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.21565797969617\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.7057312618944\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.83591142721867\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:51.02434771016557\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-5041.43878043966\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5379.728720374142\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-335.729577355351\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-3290.674358394974\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-5480.794757815963\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-111.73618059631782\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.22883490899869\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:70.83111519509173\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:71.60872175902058\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:70.91095423116\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:71.89779052403709\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:71.60215181473957\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:88.92068824869521\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.41893107173384\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:91.01623319165739\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.85256229055689\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:89.05643679853308\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:93.67403393542325\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:84.7361108242667\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:83.98607834157885\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:85.38165043854545\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:79.9363690487882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:83.50769154040526\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:87.42603957917251\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:75.4105787938556\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:73.63704024007511\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:75.70807292200243\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:74.52442627708399\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:75.3584120126105\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:75.45260280676015\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.21480128737981\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.32946414432955\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.76944114786842\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:50.21624602729688\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.673886185102425\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.40723788918498\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-205.3704999017377\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:69.79619725845853\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.36587909190462\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.21553868623678\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.31517533226403\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.48066946500113\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46116963402318\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46180283356314\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46162077871432\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46200085813554\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.46122632654189\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.4620248127209\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:87.96731786313632\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:91.29276374858416\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:72.46149940881511\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:72.46149222243949\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.9892457732072\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.851566400605\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:94.09846904253847\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:92.27945489604892\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:92.4148640289706\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:92.76895194459\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:87.0447919236524\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.78293988422159\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:78.95930395105675\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:81.12318481254803\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:81.30512584215126\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:79.8401121898511\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:80.15065206636046\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:79.02512177648838\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.211125286943314\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.26016109674534\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.33760129949819\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.65149346583467\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.63313693362395\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.91074941405356\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-20871.70672285172\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-7791.577243429174\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-7749.39545254899\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-7801.73928912368\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-18903.63913341429\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1085.8310437935183\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-53.69899545343397\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-43.04888697474656\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-239.09202775586954\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-38.51068408776683\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:72.55363484082775\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:69.12398417227094\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:61.819795149813686\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.51437839774094\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:63.48852815357506\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:60.2467882670785\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:62.357467946055564\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.06349930075608\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.107915360231026\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.147286010549415\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.99376260726422\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.58640375547845\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.15354833045609\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.03318536079615\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.88584223689059\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.626373975036465\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.65452883138349\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.444580519828776\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.96988096415198\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.42653373156221\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.225827200474754\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.00914997346201\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:47.74565662252236\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:55.27272304157462\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.98310723413484\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.15533301125041\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4721.95635856466\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-18583.983201431984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-9010.819477054245\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-23263.109312666224\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-14389.975430103059\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-13051.438416825962\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:71.32061817591541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:28.20537259392705\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-54.1762738832815\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5.616396895725018\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-74.44853919805554\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-5.560858931665447\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:72.03539663454602\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.2348530335723\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:72.46632372139945\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:71.35593131172836\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:70.98116003875191\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.62127941024876\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.92396440911801\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.39005134667441\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:59.02952623470643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:59.65261181054669\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.55676688088312\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.00179505160325\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.44628221484693\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.348795814705326\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:47.927162821505185\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.99527283072754\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.73799169011902\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.236256465632856\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:54.65006787503113\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.00604400632887\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.92961954541793\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.87409836152485\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.123592976463115\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:48.17225783828491\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-11263.839700036016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-11039.096090979609\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1507.333904293412\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-7792.023743974401\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-15723.826112138462\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1899.431461307174\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:70.6250925342148\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:68.64354232806123\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:44.776864010485454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:49.77551329502259\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-12.933671972336413\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:7.06402257824621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.64075327032283\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.66052787683441\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:79.39727463479865\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:77.8728839517861\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.92740390956449\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.14683576471886\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:72.52734833763188\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.80163468593119\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.5140385687868\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.67801082932732\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:72.41770952493773\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:72.01201152951818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.125722395753755\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.67789132358804\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.08936927551542\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.167625957206056\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.3132925756904\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:50.41471576249157\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.93991988765807\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.418557033095425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.36360094447343\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.97993390399514\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.579350978934556\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.814471763417046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2725.0402031215367\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-672.2638664516152\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1466.2822939825396\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2237.9358710972133\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-459.1438077020307\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3368.629179609583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:70.51952507103213\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:59.94057334061209\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:73.15129035095984\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:72.48257917151666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:72.39479971645947\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.17529718099944\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:87.58765506030444\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:84.40253817959974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:87.16372523935317\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:85.78830816973093\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:83.46724700068188\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:86.3573863609181\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:72.68064253155504\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:72.93813009728025\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:72.88526804828568\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:72.56167255300909\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:72.72022455296619\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:71.70711828086019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.03078669699466\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.8330392920426\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.89524042794234\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.856091033811175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.11453965942723\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.743229760040535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.08954623433151\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.90627444065796\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.52082875871207\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.925102203391596\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.062755706004495\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.281360087101625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:42.87790677226181\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:33.848631598049494\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-133.64078778747123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-43.426217424108614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-338.57872266295954\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-286.52199684305396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.79037688452959\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:78.34923736827405\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.09452811519964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.26682312381465\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.20839015323408\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.42005310066108\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:89.61532788543461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:88.9541683138779\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:90.90542863024042\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.01211935464936\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:89.77728175121185\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:90.22234024331736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.75114651154684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:78.72104492123621\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:79.2368840663991\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.5237140877215\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:79.86649553826514\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.98096275010195\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.66601081867684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:61.165578645735486\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:63.507761849109535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:58.625637362377205\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.84813871000395\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.125710317335134\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.670220067455986\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.00564680977704\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.110704648320926\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.317058069955834\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.42735309481996\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:50.19486167059346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.2254635030778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.44386883398226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.45381477782819\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-38.63431037740506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:72.45864402223891\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.40608491890069\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:75.64746182062572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46375704863767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46140852230003\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46165671998634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.45990217342633\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.4624227688386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.26369268181193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:92.74356951151803\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.39956555477364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.46008993857859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.4486518033477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.34051477542724\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:91.3788847554801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:89.53782031686876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.15972981963034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.19106380543998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:88.13145196181263\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:89.77610868048818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:72.65494680479814\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:72.53519436616048\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.47534083794007\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:72.79029419517968\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.62109672112011\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:72.51363856478692\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:50.399009626244265\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.98807494624145\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.95523438052552\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.671944927943805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.049832578575256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:52.81559714681996\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-8904.53011563108\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-49048.33149289972\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-736.5168384344584\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-29258.803044612996\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-333.4583091585537\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-8397.79181935075\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-393.8420547637722\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:71.28969693014808\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:59.481572376826875\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-358.3767043137475\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-87.24267423810501\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-21.710915655672693\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:70.7870790516184\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:69.92400268032571\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:65.14447625650135\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:66.35504312669438\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:63.27419289519132\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:63.419761887103476\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.44922739394167\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.57658197879321\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.27456349505506\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.61698479790731\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.1390762730928\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.77228364038411\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.60201178027288\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.060562569797746\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.27285179492876\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.29913388273677\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.978381532350795\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.823112625555325\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:46.62906271651376\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.81719308707591\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.6330419896718\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.22806104117017\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.30873543853079\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.881246029121186\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-83766.70772832054\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-70791.5471775124\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-18619.89581301233\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-57472.35634926269\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-71457.4677658983\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-18360.10796176438\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-339.11985525284535\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-269.7068131984548\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-558.648378431938\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-513.5047720397336\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-485.758872855076\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-268.5269904662719\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.40280611703865\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:77.2746230834483\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:73.43843374504078\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:78.69426763907862\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:77.439861013088\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:78.2287492643575\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:71.42306248605298\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:75.78151482234469\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:73.93408058412297\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:76.4882604633381\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.45733759693738\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:74.75522685387972\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.86168873907193\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.55661844780963\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.27090144247239\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:47.083641809445844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.35841288096421\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.39526646399329\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.05482450718246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.82219971328903\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.192699894849206\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.05400600542085\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.14895479373451\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.72581023156313\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-24179.7850233819\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-33774.29310262814\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-20436.17617920499\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-23036.67977230111\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-18887.50346388941\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-22378.05779519468\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-12.387921248391631\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:48.62065927732452\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-148.72388997540128\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-59.34297482360529\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-112.90660411870977\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1.3317074054240097\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:82.59736448174108\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:78.9267173519841\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.43875035876079\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:83.020668342369\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.03039856770548\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:85.09030658913184\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:77.91813929910919\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:78.10964905183508\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.83434661181894\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:78.2033171994983\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.59057645068759\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:77.46103538054948\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.27550939469943\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.726691848942615\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.50371742971283\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.94018948246659\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.80473577476586\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.98315211214635\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.23725299349303\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.9483933738595\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.62236896315787\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.867139468238136\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.37859735424779\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.13007334209362\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2932.2505512042158\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5146.134277476017\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5736.812684891072\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2444.436674215739\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4163.709564299166\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2077.4474906395326\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:41.031051696615016\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:51.89169967522107\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:66.07971342648926\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:29.92934663996535\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:71.54122252366597\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:51.95869601928314\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:90.57669300700474\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:91.04066349043444\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:86.12566814824669\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:88.21558249663705\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:91.24131210447767\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:85.74974139061754\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:79.9035167311288\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:79.6523780702159\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:80.27384356926565\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:79.71139504134631\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:79.31931460638793\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:78.6948778310613\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:60.59338233842448\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.11569576444496\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:67.94360977655514\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:67.7048962497959\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.612631755843594\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:68.35341348662867\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.825117542447295\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:48.51800295765752\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.5412703936287\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.04876031406618\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.88889105217583\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:58.759390880405846\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-507.4012204734616\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-239.51480751248027\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-447.012138817609\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-328.45690391306056\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-706.9228334629789\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-253.07327207380433\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:75.99845918921432\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:73.32430809290038\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.95029752774911\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:74.9467657531125\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.15440321607417\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:75.6209385404444\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.1402714727806\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.58181820388288\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:92.97823266686184\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:94.20517284490631\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:91.88840746926547\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.05238227303147\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:85.78274868739881\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:88.2909456486656\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:86.36286974223324\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:89.35553137538844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:88.36522273443363\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:87.02239505829212\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:78.00932707113836\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:77.62679095821083\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:77.18311147463425\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:77.62781401804058\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:77.20605945192612\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:77.70330601205228\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.86416312669373\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:48.3419339000075\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.918099164046865\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:48.65906698566145\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.93612618485453\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.382236318498364\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:77.01005193546496\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-62.805054787108986\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:74.61868057671825\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:74.1225810009631\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:74.38596142287138\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4.559648948170425\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:75.46786165218639\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:75.43550092841434\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:75.88445394409275\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:74.87112437767529\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.77291754984876\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:74.8597905615167\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:95.64852219359719\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:95.04230840056782\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:95.47287335045418\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:95.04945335118578\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:94.5553193900696\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.15628831860022\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:94.45967969254916\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:93.97066928904249\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:94.87483110029318\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:93.73214168986343\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:93.804892850049\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.92116316972144\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:79.75143957633593\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:79.99571231839676\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:79.3714947663864\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:80.09452074413885\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:79.43411259974336\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:80.01101539012299\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.15007904405618\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.30161465350994\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.49978938704052\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.23726119919643\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.06995233642107\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.48092008717329\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-166328.8421847296\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-55182.19109573545\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-53391.818258948355\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-207868.22801233747\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-69269.76627142435\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-189226.00807568704\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1466.5833782078807\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-620.9803134085532\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-228.04473714625587\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-493.96609914312216\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-294.6491857698529\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1491.9714477515015\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-34.46270688675443\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:52.30968618505671\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-24.141112982146474\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:23.631827374722103\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:41.79791703385758\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:65.72798130735814\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:60.81974124044203\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.76954649749284\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.80013652553326\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:59.38325542648351\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:57.75105619731149\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.808719969152754\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.20147865456422\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.04215658721467\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.58867244064292\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.222730224624776\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.83187936153042\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.20265319739111\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.42856254382242\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.355794131614914\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.62847505627277\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.06802437830807\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.73832292919369\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.54914500118711\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-142681.18362607123\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-114400.90233913268\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-172274.17153793588\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-90531.78809055481\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-173578.7609199542\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-118719.62798278664\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3463.9343045282026\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-504.8963167237146\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:23.028667373296496\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-337.57485464109595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2773.6476871138766\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-4687.797568030392\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.52341278394063\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.95559396247774\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:76.85531932505404\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.58065722888618\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:64.34540601580795\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:76.62672031292115\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:71.82840663114808\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:70.14672925286258\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:71.41941187417441\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.0462415517081\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:70.92491172259956\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:72.61848833919792\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:60.043208412620565\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:58.20739171324612\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.744340315778196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:62.86232321632481\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:60.394326730728906\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.80284002829574\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.03932895189058\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.84041262006458\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.56709250110261\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.908301702017305\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.50158471763838\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.54913028992472\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-201661.19618517286\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-210707.94351636377\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3992.700864462706\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-188310.6781222296\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-149345.89947639627\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-181069.69204805704\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-28.29293697438342\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-134.83164173303578\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1022.6739482113092\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:32.31958587682557\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1926.7134114078312\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-201.58548749648654\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.32601185010304\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.53109813168632\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.75240257765196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.88515541025558\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:76.59892944767309\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.2378598405584\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:71.67378055288435\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:72.04659571320735\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:72.3897642653415\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:71.66000419568603\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.90966261381986\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.53029101772323\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:64.16942193998511\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:70.98499182831874\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:69.81952666202993\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:69.0746196195589\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:71.69683242614482\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:68.5437445991898\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.20663361421621\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.85272047703336\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.10433561765274\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.786180278182115\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:54.12785462782643\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.3207782511581\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-60379.77981747747\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-8613.16606958989\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-11788.089111905289\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-20016.14275993185\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-43191.88604693041\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-15790.748109208775\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-150.78073145368137\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-368.01774969619504\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-82.22986969823813\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-73.79137190239369\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:4.79319785127873\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-416.20049172259394\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:81.9341039298274\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:76.52198614521794\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.46897110866692\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.06842430512486\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.29200212066807\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:77.18904078523411\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:75.83682185275241\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:76.53208237825369\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:76.4004847729084\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:76.49805416170305\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:76.0141090392315\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:76.51376652849106\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:71.75281899852767\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:72.80161555495386\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:71.59327775874036\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:72.05806572292619\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:71.6512186025615\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:71.95149582140647\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.53002159369096\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.74864032392524\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.044556006566104\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.563541239293386\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.33086724925735\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.01072199522885\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3301.6575914748173\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-6464.22253331394\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3250.395550739117\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-10848.136205650673\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-342.3183021815956\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-32648.200458499552\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.41906911205174\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.68691441992121\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:69.75546172512526\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:68.08594451164805\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:71.84493190383611\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.28886254478196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:91.12422535323645\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:83.28393050612569\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:90.0605532388409\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:91.33499136254767\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.37659306663336\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.93938494761973\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.51448173688283\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:78.36308497157597\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:78.6546578503106\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.78128312956733\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:78.49859779420287\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.55121451771288\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:72.8281344645976\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:72.85935267207189\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:72.91885786304519\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:72.79120934488643\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.81861885783239\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:72.85432330823679\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.688686996487014\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.23018656573584\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.71702421063791\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:60.607975693177394\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.052100050158145\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:61.08749250993662\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1072.198022792807\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.36914630947008\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-717.9374559551266\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1001.4150804379872\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-131.63260985209865\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-97.98419988465366\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46128785694745\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:57.74034769916459\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.44935721464284\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46117975131277\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.45674832211037\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.4760651118742\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.76976942868097\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.42227870413785\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:91.87670041248495\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.38267761670858\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.59007625048136\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:94.38417666394284\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:89.37169877053411\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:82.52209902772573\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:87.16379318260084\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:84.88054050776998\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.3448141179656\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:84.14137574651046\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:75.13661605340464\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:74.27762681992623\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:74.71847547800922\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:75.79731334373648\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:74.9238227229122\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:75.15399425493815\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:67.96381407313876\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:71.56152758568267\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:71.40974159593935\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:71.7849279126377\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:67.39073612259729\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:70.31387350425841\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-407461196.4539007\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-262791277.06855792\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1759953763.0417652\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-326653335.7762018\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1635533816.4696612\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-72688847.91174152\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-13138.210951351952\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-214254.53447442624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-20428.613298083965\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-387031.36550987494\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-53834.385610209196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-85968.38714623658\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:58.599891288718254\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:35.13551759757424\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-27.717026713516326\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:60.71914870312498\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:68.94800832085575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:52.18234948984182\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.028764022251494\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.252970628657614\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.25915990415242\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.73780615072348\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.274742058370414\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.21343256668183\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.99659134013104\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.52341422347031\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.520729382492306\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.656213559289554\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.20195385010531\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.129605882098765\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.836052613501664\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.56763442645658\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.42805474343686\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.35614327741735\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.93745301862323\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.9552645919664\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-82975.48118212544\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-11263.982158687943\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-52602.096579260855\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-34407.96002327127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-29519.806903812052\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-45725.83111702127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:19.097564829156756\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-76.9528049103757\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1143.6383781703653\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-442.39869692646863\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-720.9645372755984\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-522.885916419063\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:71.81830430613248\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.72854658747583\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.73961254440019\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:71.73082258308658\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.78374785339861\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.82719090306166\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:71.22294723376972\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:76.25773592761786\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:74.81515447016866\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:73.8367536389236\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:73.04466145070545\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:71.90087194326264\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.917812386561415\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.986971699740586\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.455345863380984\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.269758357505715\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.90798423469208\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.825171397932884\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.70261379388887\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.01310651022075\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.55000782841368\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.70225485989792\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.986632033384055\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:48.27805882931882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-361301.6449191046\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-87093.87310920878\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-297631.42799756204\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-121835.27935920877\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-182126.28684618796\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-343300.6011746454\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-121.33447904113335\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-742.0311190557818\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-49.66235735737685\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-835.3817405430137\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-423.31328966938855\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-479.44327415303974\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:71.68078555940549\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:71.40591289228675\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.55911052574598\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.38069475420448\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:71.18586604288942\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:71.97379082370875\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.97065611595802\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.5150698972932\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.62781231519836\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.58803805138203\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:76.94428906936736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:79.25071458209679\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.80395143007651\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:62.03058548711997\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.59361916944866\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:60.25198969646548\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:62.08724218902859\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:61.612236917817384\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.05689231906647\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.344622949964645\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.65519471734122\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.199464992170164\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.42815986554557\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.38496357977532\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-310221.5972683954\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-284044.09075797873\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-124501.80767952127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-322308.25091422873\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-373543.70013297873\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-161238.52642952127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-77.3711623874962\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:71.52509106905842\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-88.8784942897499\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-129.71349337422257\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-117.7901643387815\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-18.46817909403049\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:71.84321000126988\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:71.92012098851967\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:84.91894229131012\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:72.25357250870448\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:71.89941544341139\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:71.7674943478301\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:81.2323053842271\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:81.39314774315221\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:80.16302700912605\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:82.51074675596823\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:80.53684996703744\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:80.88319326499206\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:73.91367117845702\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:73.45116634459079\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:71.87248652520566\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:73.33287743248275\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:73.77900321526825\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:74.36619004553185\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.124476291157066\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.83848859619869\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.19396300599789\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.729828552597624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.231825276481246\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.535985361775886\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-54774.032614417105\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-158968.34206006204\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-107083.71685920877\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-111977.26340868794\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-112135.58860400044\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-91581.59075797872\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.5922961607047\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.35762580273375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:71.96305182338982\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:71.55248038500102\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:70.94623534298019\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:68.6305524421734\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:72.44090485328572\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:72.42875987850277\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:72.42177951232574\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:72.41320616622156\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:72.49329033754678\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:72.45667016440439\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:82.56357012417863\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:88.66317649940697\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:87.63051910136538\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:86.29759634053077\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:87.15539240785431\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:85.93112370857956\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:77.45284152791855\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:77.1304187434597\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:77.26775029919295\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:76.89981904200816\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:77.36782795148538\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:78.09118783971847\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.16839478042204\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.290083977418014\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.18193241059075\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.43935378141249\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.714408015293614\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.38148710907233\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:40.16851803935165\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:71.78878757876613\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:71.58596570140456\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:72.3373635534793\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-215.51219047384058\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-5106.572999345496\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46214777959248\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.45966209211718\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46011563226686\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46280653069017\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.45995513654489\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.46289436416986\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:72.46148663303624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:72.4614467087273\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:72.4614427162964\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:72.46149142395333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:72.461449902672\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:72.46149461789804\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:92.89913291245159\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:91.81680243441774\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:94.23696177360624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:93.27775702831593\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:92.3721153732357\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.2227640373851\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:84.0604777020014\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:80.64953129271807\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:83.9581506021491\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:83.18160105851854\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:81.81368200925976\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:82.43716491299693\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:65.39859910054504\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.96939608372507\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:65.98885884380792\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:68.57897842653725\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:63.880017085090415\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:70.31950028136174\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-11769.056702862583\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-18457.3025077417\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-47992.80188209528\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-24995.94876144325\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-14624.095402710827\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-5133.135653256056\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:63.52316031219265\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-160.5597780857432\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-132.75210911876295\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:52.94232605196905\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:65.54978076072074\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-168.21348973387714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:65.87766290556453\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:63.60444892946428\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:63.646022492830355\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:64.70710516821407\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:61.61245356120868\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:63.42398965330551\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.88580940963248\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.419621563948816\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.26049656521343\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.060966000137036\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.08836543924045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:49.194933948458605\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.919724317635946\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.43754455129563\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.271857632396014\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.527748029329715\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.04305983903701\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.833379614860455\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.52774016216244\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.47453518321046\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.10782083601253\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.67647168121299\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.47193322518005\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.72553087248988\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-19179.517616410252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-45533.154768226086\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-36538.69707785412\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-32713.78888069315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-29863.489947908973\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-25004.44435498393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-129.2608511363361\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:64.61144659442166\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-195.49803279158255\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-71.90299913392843\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-148.82970077959547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-93.21497157392209\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:69.75355006466708\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.13925820734673\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:70.37739167540349\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.29177603297012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.76173081822617\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:70.80281283368832\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.63967909842989\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.79332196721887\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:66.05453217846846\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.71362758828863\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:67.31257886281625\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.1578740637729\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.92229620102498\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.176531037916064\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.69531634371285\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.406527600272426\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.624387961694154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.848348979103555\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.463088052657014\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.630028713984785\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.949636103956706\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.649588732197124\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.86768665838137\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:51.45190005418914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-11673.581971513464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1570.916642533972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1903.5078900925657\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-10194.611634599401\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-14875.554424312944\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1392.1798489617963\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:69.985588372834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-12.90151035813858\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-54.72816992595122\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-24.412343857136175\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-0.3984911597742613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:46.89327265166033\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:81.15121723630467\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.1049632764971\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:81.95182678852615\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:81.98980080203056\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.24520533981052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:81.32463605433021\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:70.0961417903855\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:69.9388703649865\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:70.14027146301089\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:69.94805879908532\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:69.88721274315043\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:70.28675141345806\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.686873888011235\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.74238353690546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.49913383969835\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.241600581775785\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.51115905820525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.38317213925534\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.09569344444713\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:50.51429553722142\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.39866903666157\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.35358197246131\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.68127928146986\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.01128897249077\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2938.8625882196093\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2047.5053620394804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-177.48895266377338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1439.1522508986452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7655.626911136275\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3541.439034752812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:35.66808437530782\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:50.062958643697584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.995196785111425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:71.57558164228315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:35.633021795063904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:71.77269710528746\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:88.09930197806504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:87.05421444512992\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:88.65411720870516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:87.3714326309162\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:88.53407402715878\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:87.18003319698211\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:72.71458600993415\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:72.89639339379386\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:72.85717848814595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:72.799060605848\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:72.79481543998628\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:72.31582959305123\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.7716187636997\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.65660045642944\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:58.56523907870359\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.359655869204374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:57.96824628861519\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.9117730436032\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.63600939366646\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.50856454565922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.31543714263667\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.50867654215266\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.889167161815465\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.54661440518167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-345.8806775140424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-221.99324546976294\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:47.31539665384496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-611.0943895705202\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-373.74460477355524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-636.2213351202349\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:77.22949685310171\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:76.31956193276143\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.13364087098033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:4.026905808324788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:71.992734720427\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.4382677070732\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:90.87518134438399\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:89.3928964756623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:91.07839069303516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.86769841922559\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:89.44880311488166\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.93708979538616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:81.07686124982752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:81.56032891513983\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:80.6842456472681\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:82.4988347583159\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:81.543783750752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:82.23551899265172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:67.24415313925117\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.93888511894444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.99769935164514\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.6005068358894\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.01149067829874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.34893150570076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.71161689001618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.180006599436844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.12949846486485\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.51376833527741\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.3759175710339\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.36110175788473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:72.46155689982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.68345568290933\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:72.46567070061434\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:70.75877234727214\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:40.75459511473575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:72.47627779101649\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-254.613885210667\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46132137457906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46111156998703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.90016064219253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:73.67211285775998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:77.49124411244013\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:92.8709892211137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.22135007996744\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:91.76654986878658\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.9691443989322\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:91.3851066484425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:92.16153303923055\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:89.18002073787346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:89.95044749373992\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.6792776380659\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:88.6852058747136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.72037896408257\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:89.70402313016173\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:72.59582438931116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:72.60011477767247\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.57953745065664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:72.61587438666042\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.57323878500948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:72.58660556576777\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:52.42894257883373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.060210369580176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.64407587211089\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.10775889718129\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.83522822252871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.00800275379885\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-20682.794589259855\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-30212.12057920776\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-33033.7607405522\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-209994.26526609983\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-22481.928910900988\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-36330.3636399097\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-172.8040519805289\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2079.036941821412\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:33.65628306935208\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-169.02765387198036\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-105.24845340761075\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-149.31486826698267\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:66.46201020008331\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:65.53513484502798\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:62.830223640980364\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:74.16047231478424\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:70.86817416633275\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:74.45905715538301\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.47449921516567\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.52035900327495\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.39845758257324\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:58.172319771338856\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.09624003625413\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.5612236765471\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.04953571937985\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.99615893752217\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.502649973734485\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.078776627378296\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.434714803162464\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.83584029302646\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.10972935253706\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.21531793407339\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.08431734582682\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.73540340682492\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:47.741325164376704\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.10822257147243\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-120084.62742812245\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-204423.5676654969\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-285318.64671098423\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-201948.6850903859\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-293372.0330159433\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-138259.83316167496\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3218.889580663496\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1535.140772482088\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2760.7081686351316\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2834.577079933398\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2068.773913965909\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3124.657471298326\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:70.3562929697916\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.59669400651781\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:62.591553913903475\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:50.56663185557668\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:69.19523819142012\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:70.06220055716163\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:72.70876649059679\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:71.52426222044244\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:69.21545848649633\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:70.55835724757637\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:72.37031797990731\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:71.32662997131183\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.44668168166229\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.18601072953619\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.79146325574136\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.720409736424756\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.54718771297411\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.62809169238434\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.44715120754344\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.796424941032825\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.0746301709901\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.664688067372744\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.363535808876364\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.36227270957872\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-97036.7229058857\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-80766.74576166393\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-47023.060627148974\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-46857.65644472541\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-82712.62955782074\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-67846.19480490778\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-193.92740376076426\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1397.1617638923879\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-227.86848730135375\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1282.9610391147876\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-506.26228021485684\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-200.69168406832958\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:73.4291050380567\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.76644415381952\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.08215983849608\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.78082501141455\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:77.49057831705039\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.56308126703222\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:77.31790854335067\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:77.03687652499306\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:76.12488326444851\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:76.90973097738832\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.86903823824957\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:78.5368141506111\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.50702603910503\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:63.634618877530855\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:61.94447150594835\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:61.06872963994283\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.80366048564689\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:59.30378778776708\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.82101266406669\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.94018960154671\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.22592979313188\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.06936441270314\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:49.36012818285032\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.22429091853829\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-13939.597401119201\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10087.160459177245\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4983.8015498468685\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-25728.123826732593\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-18877.00780773839\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-25979.15915661294\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-47.39127941165408\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-79.11194448305736\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-28.338917866760195\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-19.389698221704176\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-13.086452589343157\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-194.36461576051465\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:84.20922425293001\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:88.65866299052234\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:81.95910733971095\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:84.47606752504035\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:79.30119256507326\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:84.32401347057007\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:81.52245145622814\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:80.08401850099001\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:82.48621411298653\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:80.3127850071946\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:81.89038583279313\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:80.80511329515042\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:77.30061356609407\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:77.28567898913431\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:77.77804043921924\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:77.37147269771971\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:77.08937427787869\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:78.23352545141657\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.83138335697571\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.29056705981259\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:52.10366960522448\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.892560108841465\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.519068559797574\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.116582375010985\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1768.6554907249408\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-714.2863631342414\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1378.36233684639\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2112.958354664375\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1099.569520281468\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1980.7691825103159\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-23.26543425085792\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:72.61442057817729\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.12203079269474\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:75.2279169358448\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:72.49414180563227\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:29.03940613763928\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:87.63851739460318\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:83.76326710748991\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:86.3965241198844\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:85.51553529111112\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:86.5298338322493\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:88.80997392443619\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:90.6735876321182\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:91.30375956671739\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:89.65712496974132\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:91.02649983015702\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:89.70525787807149\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:90.19497120404327\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:77.9128544875094\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:78.1269347114625\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:78.13358805923949\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:78.24663430297494\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:77.98041809963794\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:78.23995319323525\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.32768094711082\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.8042847938407\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.159999255722106\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.3800630953436\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.43221998075867\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.41639884620892\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-413.35316485922766\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-176.0672438886806\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-375.8260076867022\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:76.10475631846134\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-142.72115112196468\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-337.5028706423592\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:73.44009694947889\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:61.556920458520835\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:74.74428230707245\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:75.73460922455394\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:75.39684279308815\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:75.25080200064549\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:89.48153409317217\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:91.70528302824901\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:87.33405278037156\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:87.25840869947528\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:90.32742843983021\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:86.43326158594954\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:94.40045272322317\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:94.17671913984162\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:94.6457273365711\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:94.27738393942397\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:94.60418135972827\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:95.00182480606345\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:82.65303894495804\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:83.12848616740757\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:82.69142181274222\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:82.79116008316231\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:83.57474782479922\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:81.81546636107778\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:62.739562588597806\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:69.64302848469703\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:69.17053634716217\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:71.72012617334525\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:65.7997308414902\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:70.47240265664902\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-504552.35898714536\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-25282.92335889018\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-287396.8597628546\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-133125.71510693704\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-143757.40456006204\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-769582.2417996454\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-9985.234556806849\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2512.4453443161983\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-7751.93428418315\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1260.7188962030073\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4609.254985836381\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2960.946379316614\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-252.16134126210795\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-120.79397724593504\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-117.2043778560028\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-135.59680635108074\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-161.33340395182674\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-50.86644704742069\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:65.41584207374717\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:68.39612186471714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:65.69819327317607\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:69.97837991203446\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:68.82903075199414\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:66.55737780228293\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.9308481955735\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.873733137434066\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.564483527361276\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.0239450356639\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.08742027389806\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.495917906481225\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.12475697819505\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.956646729645236\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.44695537998227\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.22180919851771\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.24521907657924\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.224908838516804\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-452609.88059618796\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-487366.64935172873\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-301886.18267952127\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-528547.9990857713\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-509066.09804410464\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-616820.8180961879\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-789.2033475510617\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-480.2486839023888\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-4199.182913489376\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:72.53274580359552\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-12990.889507320757\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-457.068274207149\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:54.53121747272611\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:59.11983481488705\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:54.74284356672807\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:59.03909481868113\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:57.05246612652726\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:62.36803208964372\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:71.8909451442971\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:72.12194667452427\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:71.69421416178193\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:72.581286905693\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:71.79225744742685\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:72.10059850773914\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:65.90867523512003\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:71.78728345625977\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:67.34624249057755\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:68.10054570037234\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:69.50848570858238\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:69.44213322150227\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.554176796694456\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.85852550424583\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.66937578908095\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.16748390768906\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.93221098330192\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.71442262209523\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-717156.3649711879\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-844660.3016954786\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-749356.9509086879\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-31153.103659338984\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-36457.58160530252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-770189.8285128546\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-6196.70713167664\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-6476.161680830286\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-6562.312295250858\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-8340.678892744349\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-5796.542845381066\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-8084.419737470911\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.41546536168308\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:69.58516570317454\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:66.9005740806754\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:72.39295177519838\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.73309114845463\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:69.83188381337857\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:74.75762185005807\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:74.4135336907855\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:74.20120426197518\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:74.90666490826108\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:73.54911468083507\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:74.30029096238908\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:70.35699322807967\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:70.32714519470672\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:70.30238796163488\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:70.76152643883107\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:70.57171668284892\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:70.27528282222643\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.81835513475657\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:61.04481809481192\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:59.05842181497714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.16141585659287\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.24013169113344\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.67760380907638\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-107838.03814827127\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-288366.3238308954\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-228475.6358045213\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-68374.71413037456\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-214568.34413785458\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-31428.888935062052\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1375.3531354538939\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1482.4058749151568\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1321.70713167664\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2034.035724612838\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1469.1514549525918\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1426.031599653528\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:72.39871560540887\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:72.56165972086647\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:71.49578959477803\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:72.20050453482132\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:72.87346738074312\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:71.43207361042452\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:77.41978516768432\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:77.77268623770269\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:77.24004214771908\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:77.63848330581912\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:77.41507096399557\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:77.65686641395139\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:72.93431056212778\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:72.7786033053958\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:73.02191840841414\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:72.8918752959622\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:72.82022168262444\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:73.02704502786587\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:65.87911928799134\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:61.921434436753756\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:63.458158906000264\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:65.74173712467378\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:64.06587977828333\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:62.20669562277408\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-13045.39894482768\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-7343.739805830286\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-15017.929098792109\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-20439.9973767869\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-23697.327699052526\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2937.3036486037236\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-161.88902280009384\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:69.0740448739042\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-1.0770581292767867\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:66.94015304905115\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-122.18464790506567\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-125.1188335689247\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:72.46992242345667\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:72.55739107951112\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:72.45408256191077\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:72.51131889667917\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:72.45650327139901\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:82.52401854035608\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:78.85482613616708\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:78.89529982122312\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:78.58548790239931\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:78.79348147610588\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:78.93681606737246\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:78.87894092604718\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:73.15083480050377\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:73.12810132595571\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:73.26134391616328\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:73.00759394212066\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:72.99044554960643\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:73.10727784913576\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:67.67613855377721\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:68.22348718947553\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:65.76748044120693\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:68.4154694995324\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:69.54424605301932\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:69.21409991803932\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1933.9074236281374\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.1038435086009\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-260.1618347438515\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-4178.764321618046\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1169.820171383256\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4995.435057295129\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-1952.6408094040892\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:71.70211309706535\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-892.488310523067\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.4479171589099\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:57.603121057469785\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-121.64921185649034\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:72.46049303441089\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:72.47807418764624\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:73.30159910839312\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:79.0051513412414\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:72.46149366910858\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:83.49977654674281\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:89.17938104476207\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:92.05636419620075\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:94.03356716236418\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:92.71937501921346\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:93.37364248080081\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.729508767678\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:77.10738757917316\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:77.51927092917987\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:77.00564230728375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:77.07525804533181\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:76.99191862668833\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:77.27684426298285\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:72.60256381932912\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:72.60939204101021\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:72.67735941941763\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:72.66779330135613\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:72.64738706644359\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:72.68642204967044\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-2977244544.28684\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1908006914.814815\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6622391571.867612\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3501022052.5610714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-18701233516.07565\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-14019514873.364853\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-138872.76989370937\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1205080.1563115644\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-568981.782722924\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1136608.4005152925\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-500460.03581498715\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-567767.4078614436\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-295.0524330890676\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-254.8168677998115\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-330.8789611708188\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-721.6823399771473\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-253.1634066591496\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-722.6184249018195\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.961595231055085\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.40100589575403\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:62.94536517538172\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:59.38019034334579\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:59.067181660445115\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:61.52651906483187\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.54087942271508\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.741370323812035\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.76097467178707\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.00719566537555\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.19634069148906\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.83434939746128\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.73683682999408\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.26255457315203\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.21454631272995\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.681153985452255\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.27716473806165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.14196339523798\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-106073.61549756206\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-135512.35247672873\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-200006.49310172873\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-78331.8939425421\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-64626.93987907247\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-95167.0257784796\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2077.4742342901563\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-92.44981386982802\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-999.8773155482949\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-906.5493685133914\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-994.3595669793744\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-678.7930387131712\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.88602847091038\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.29726663548897\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.29734541357175\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.94952754508425\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.06329520280386\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:71.5823629317648\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:76.7388903033179\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:78.51961098899045\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:76.48854760366504\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:77.90925526496835\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:78.21709332595762\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:78.15094995771082\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:61.147272189927904\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.392626495296504\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:61.39386666863804\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:61.686577315026135\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.15793660651802\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:63.05517699772021\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.156631498824346\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.19194637216082\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.126208794640824\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.88535253470654\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.76584546698639\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:49.66644246947281\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-146784.37603889627\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-261516.47031527042\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-687114.1774711879\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-640067.7582003546\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-764007.6670545213\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-390657.04856493796\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2077.7541897821093\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1643.0878740675905\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3458.230314863489\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1935.6434923537233\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2363.2632154099483\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3527.29540885763\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:68.84649421306366\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:70.66652962689892\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.43895707795525\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.23533205501296\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:72.49070518687543\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:72.38094249609608\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.28509030002041\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:80.48160979604984\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:80.58238135631672\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:79.6755375521121\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:77.69502988004422\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:79.02965597555898\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:71.95280949556518\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:68.86930979547583\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:73.35678478035051\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:71.96876249320869\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:70.37272382853443\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:69.43045538461894\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.583604313949834\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.83582873881991\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.5452505409647\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.257216450522705\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.84755935652037\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:54.50885717597789\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-894066.4561170214\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-573685.0759086879\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-322079.6722628546\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-794459.4248670213\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-909133.1532579786\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-820795.9136746455\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-343.78090919332294\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-482.7919858567259\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:6.79555514180068\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-471.9792467482546\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:35.899827666316476\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-524.517673465377\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:72.15469359787924\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:72.33967359278313\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:72.389926113793\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:72.01634176703679\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:72.50584736877393\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:72.24860849861463\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:84.12573082391629\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:85.46431711849216\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:84.02452672486046\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:84.20353007772196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:82.08752829813413\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:83.23015625360352\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:76.5377241809881\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:77.24248726270253\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:76.50639270590082\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:76.44316377932861\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:77.06393555358603\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:76.60516879988806\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.24804954797946\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.37294732469851\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.41711818725692\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.141500029017166\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.72402164408126\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.90501219555559\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-599948.9735704787\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-516466.22617464536\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-698688.1358045213\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-571140.6097628546\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-423860.07383089536\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-746703.3355496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:23.904845900569395\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:51.77739102413938\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:23.950145430598692\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:71.36615523209808\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.95735069914443\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.3643121956088\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:72.44403412062132\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:72.4027396093869\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:72.50542732746794\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:72.39422295580142\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:72.54551133365497\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:72.41616296054248\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:91.64615738505778\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:89.99439876062767\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:90.53644827927387\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:90.72459901626522\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:91.54208621598774\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:89.69017277333013\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:79.43890534041903\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:79.5433929579008\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:79.5651282161075\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:78.2336226004705\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:79.36520657734762\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:79.66708513439124\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:62.30895124475631\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:61.24857566176296\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:61.207543160851486\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:62.732748916244965\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:60.8683293346254\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:60.64332031283066\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-100432.34153368794\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-306438.1011746454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-199643.8812472296\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-141517.65846631204\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-224094.32070035458\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-40496.11920295877\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.46576172803873\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.60441565908158\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.46546389269398\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.46576013106638\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:72.46616815750386\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:72.4559084085896\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:72.46153214674845\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:72.46146667088178\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:72.46153134826227\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:72.4615225649143\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:72.46153294523464\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:72.46146667088178\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:91.90815963332489\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:92.60573070290829\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:90.37369789659883\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:91.61684245408357\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:92.47527812498235\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.36820315449279\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:87.90374541841595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:87.96129310320127\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:88.39064561684856\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:87.20761927518438\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:87.41494212960099\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:87.56397264250727\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:73.21470511344778\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:74.63632187944778\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:74.00135564653773\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:73.17275961991649\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:72.81826268602676\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:74.72437015192259\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-28638.146063622007\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1886.472316348149\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-31116.555211373066\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-48722.895157665975\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-15177.632462161087\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-10958.913588166894\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-285.2379380294523\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-284.183943262243\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-143.07627279613783\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-133.68094093316745\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-327.8246190437094\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-203.90788575060446\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:63.364891286343465\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:64.17181423275935\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:68.20123434254653\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:68.552655014492\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:65.5086485018779\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:67.97428939923044\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.38230182104242\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.41810464511432\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.513690111226595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.80662946028443\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:52.135940140643115\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:51.37901619029759\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.06964327854679\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.62819856858516\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.0639852063218\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.82158720860854\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.2080686058265\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.62055776693026\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.150847474945365\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.21898485751861\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.916487088804175\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.218845727214244\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.357824962048944\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.84685523064705\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-86660.44881473477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-35914.44602587544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-89316.12265055532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-93260.08193043858\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-60363.345137311306\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-112441.28314079123\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-843.0200058235907\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-466.89864369806486\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-514.5143379650311\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-303.816473963131\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-346.3370257047709\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-44.09204141843779\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:72.77031075400193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:71.48846140802141\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:68.03173598010676\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.87943358530295\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:72.51924651170737\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.01408825566959\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.81423484518172\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:71.39420235034892\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:71.48125995511234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:69.3463267257967\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:71.50557136986555\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:68.4991398413788\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.92955752857282\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.93484380317541\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.29090974890312\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.719929596915605\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.09946768285254\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.366086195088734\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.693891783015204\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.815686827679606\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:51.170999152986575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.89810096424945\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.01115572745814\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.80860071257638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-29415.156356775453\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-20601.44664382634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-36484.01181917664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1476.8517595656374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-37298.16962829061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-16709.203440228062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-133.37619825082095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-331.0800750768495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-90.53408515274855\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-296.8990540109909\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-37.73465725828853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-203.82759039377584\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:83.26061526863852\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:80.41537863131204\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:81.6012275345782\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:82.93867485672588\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:81.00289276928014\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:81.84607753822239\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:71.30885811844053\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:71.09985805290529\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:71.12173493966236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:70.47657405794654\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:71.25233770638023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:71.65314471092255\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.87070463681145\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.15115002626692\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.33415905432592\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.18440573092425\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.28403495436489\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.092725379270675\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.93883949524074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.23438012929908\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.42968822206635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.698018236627384\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.996921334148524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.59426078701597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-13496.656264236728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1949.5121894998754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-16150.002056148882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1984.8103841145833\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-10133.882671383255\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3845.1830329624477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:35.42786119865375\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:73.5346619635703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:31.030009843121363\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-70.12244995604169\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-50.177413445931876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-46.67726756081609\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:88.98046482633286\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:88.59815459208191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:89.20567689611745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:89.27299764632615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:88.79119415068082\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:88.88750897912739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:71.99918615057112\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:71.89725158344206\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:72.00421530773924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:71.8835738251959\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:71.87508249771322\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:71.87927165681495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:60.950407660599296\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:62.373479585463464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.0177618296152\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:61.985401425237626\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:59.6917905400737\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:62.509188232128786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.428652216192305\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.25501491356908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.72131883752531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.4256717495039\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.4637018678999\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.531373319215334\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:62.18423490171079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1219.7106462843874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3951.136503828333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-20010.469001066598\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1823.92881136414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-958.4891112607892\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:72.3093289667645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:79.34369377680328\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.29938853717019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:72.90840730411598\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:15.408240048503952\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:73.38895800547678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:92.4268045869984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:91.39668249867863\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:92.09874586398156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:91.22611842961457\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:91.05850088140737\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:91.4223802756662\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:83.92700171516438\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:83.53537740530791\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:82.85514391177841\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:83.97102502091744\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:82.28833765096792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:83.13513024232348\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:71.72255179748656\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:71.56394453289192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.59311389058851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:71.50204334792609\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:71.0376520106133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:71.65320705860219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.713547046185475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.848772679754276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.02370241662477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.87424020268392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.69056269726102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.75668376367142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-17842.343118004763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:72.58100404431258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-34.89919110862545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-351.10696528820273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-8093.017556481327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:73.33900505769337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:72.44026560403871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.46876630001505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:60.55287264575162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:72.43896044550024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-140.1841960242642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:52.16447959695864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:91.93983935905874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.88594614698532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:91.99968564806255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:91.82841550937499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.21632723318864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.86495148332406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:90.27581339169197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:90.14918150085225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:89.98444634214502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:89.2122651624271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:89.80737829872997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:90.69857837190489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:72.67594459584794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:72.63865430492224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:72.65529899356682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:72.66314580179369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:72.64126779715596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:72.63158621799298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.69448109148429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.22403978291604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.32302681365475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.884883163339794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.35690463378356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.6320105680713\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-18653.03103279372\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-51877.22828100759\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-5957.069291459754\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-173352.17854625318\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-22742.80858201432\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3221.129630699789\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2.5553880525067463\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-569.3673004096094\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-113.47843198160001\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-91.98860079872036\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1127.333395916989\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-322.0824406079367\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:60.129656369370025\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:64.76424612791827\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:50.85948110272604\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:7.828295655061268\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:75.02432983277632\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:38.30177553755454\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.62949098852721\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.687774866895715\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.69580063638347\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:57.93492999573666\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:57.45270604427708\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.234519313976826\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.4408473280406\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.165235834526456\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.55706636359881\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.56212709381754\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.32755082330194\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.420341888027245\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.24894568917817\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.03913893466088\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.38558002465044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.483435448408834\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.98222209450954\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.956290471500374\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1123559.4408677074\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1265716.047969815\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-579882.8401394957\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-235512.9236742866\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-821327.7763132226\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-519899.3349488651\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-5940.910145013327\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-419.0834879405485\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-7078.82567336937\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2527.346839502724\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-12619.390765130755\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-5533.60900548239\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:44.34533106872094\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-74.3237694562468\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:7.610793072375088\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:23.415054323355733\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:30.85413945294254\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:22.762489332938596\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:77.02068316436852\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:76.73361234930532\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:77.72318091716139\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:76.79017795450909\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:77.00100971313914\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:77.20663077612625\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.63344695879964\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:59.38662669648562\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:60.44985767075215\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.60649476835902\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:58.85754967276433\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:59.73658302330638\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.039799687046774\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.37852354026478\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.02547907264179\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.25593051737376\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.85875415770298\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.4123893351631\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-406245.1520049544\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-337969.10577447887\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-454713.8766421775\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-167338.08475341075\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-362380.4842213179\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-275987.08734700206\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1357.2488209128473\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1220.856688640736\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2447.804088532408\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1583.0288005777004\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2735.452960841387\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2640.768951379567\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.37905849275671\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:51.20596884741757\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:49.33419824116243\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.25975870832484\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:73.45818743591144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:49.599613246953425\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:78.99751286451698\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:79.37632958405455\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:78.11496802646053\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:77.70895127374371\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:79.29746710157376\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:78.92396963304944\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:77.01929094426927\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:76.49141132796346\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:76.60645451763655\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:76.19106521032944\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:76.14803967529203\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:76.3109787784875\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.18026514914711\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.20327217974374\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.20210059037047\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.45045427091484\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:51.437710314384354\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.988282101632485\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-94403.08024193754\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-35746.636095490394\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-104226.41929268744\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-91140.22300064893\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-62927.089393561604\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-67579.87327635805\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1529.6657628013545\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-164.85042850082556\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-454.188157950357\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-593.310476871247\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-455.76543838983457\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1100.1505604872468\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:75.18231872501478\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:73.74002160731969\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:72.91177622533579\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:76.86996048505706\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:75.48297489130938\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:74.54098528346461\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:82.60319877865044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:85.43662992375775\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:81.88268590286974\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:84.48673336787942\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:84.17432234689323\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:86.04453326510433\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:77.7543494946098\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:76.75613760214279\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:77.54222399975673\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:77.8180952049598\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:77.36870651702134\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:77.55846113811994\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.395103255922386\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.11637850477118\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.31314363518483\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.96941622727094\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.02211589800081\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.17396256935887\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3272.7874688222896\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1477.1610876535035\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-6774.306007517521\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-12273.728917018929\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-24626.35784607595\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3029.6410902547873\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-52.46104059302026\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:28.74422776032096\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:71.29742815750053\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-172.42763901996838\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-297.9028641285156\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:33.71886145866603\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:80.43453693155044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:80.79243750436932\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:78.89072763534678\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:79.72106499358178\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:79.56306813453551\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:77.73605424931334\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:92.94274980569269\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:92.90577166128854\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:93.02110815460377\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:93.08716285888654\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:92.6684920628349\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:92.809190853573\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:78.44522554072176\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:78.75644978990087\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:78.47643134201061\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:78.37181240907329\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:78.40385470976737\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:78.42096277755532\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:61.66264483568658\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.72048898651856\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:59.56502448124525\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:59.2945053182609\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:61.05276484312483\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:62.0108190850539\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1088.8709312541173\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-289.61949215994946\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-5079.970083920574\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:77.46530311891091\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-432.6131943175885\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-931.0689542874096\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:71.6791155584409\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:73.99093715857107\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:67.14967818970376\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:75.06877740036323\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-143.94772271644044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:44.349345886585176\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:84.54304040887395\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:83.77932534150197\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:81.78003086078064\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:85.63829492616128\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:83.42368830086397\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:82.56737309309138\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:94.66721437712933\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:94.59731225379345\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:94.96816605816825\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:94.57421600726896\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:94.96979531960473\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:93.76360003853333\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:87.16915328880526\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:87.00807570612646\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:87.59944250644239\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:89.67757531749253\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:86.91457223207334\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:86.1099721463155\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:77.94912826736628\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:78.5573288936306\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:77.98219134046207\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:77.72885168703688\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:78.21901179982204\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:78.2174608739162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi hasil ke DataFrame dan menyimpannya ke CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"mlp_regression_hidden layer 123.csv\", index=False)\n",
        "print(\"All results have been saved to 'mlp_regression_hidden layer 123.csv'.\")"
      ],
      "metadata": {
        "id": "xyN3mIjETBY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0663212-00f9-4757-a3e6-48a5219dd01b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results have been saved to 'mlp_regression_hidden layer 123.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant hyperparameters and mean MAE\n",
        "hyperparameters = ['layers', 'neurons', 'activation', 'epochs', 'lr', 'batch_size']\n",
        "mean_mae_by_hyperparameter = results_df.groupby(hyperparameters)['mae'].mean().reset_index()\n",
        "\n",
        "# Plot mean MAE against each hyperparameter\n",
        "for param in hyperparameters:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
        "    plt.title(f'Mean MAE vs. {param.capitalize()}', fontsize=14)\n",
        "    plt.xlabel(param.capitalize(), fontsize=12)\n",
        "    plt.ylabel('Mean MAE', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "24meNS6jZF5f",
        "outputId": "1127caa5-36f6-4df2-e436-e741f8821c75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-19-24e299652439>:8: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}