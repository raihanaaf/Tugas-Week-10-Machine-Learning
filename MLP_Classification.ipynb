{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Estimation of Obesity Levels Based On Eating Habits and Physical Condition**"
      ],
      "metadata": {
        "id": "7uHiZuuyUg16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 10 Machine Learning\n",
        "\n",
        "Raihana Fawaz (1103210102)"
      ],
      "metadata": {
        "id": "ZJAVL-YoUuGQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sb4WGLZAUL2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "XxRETIDtU6Sn",
        "outputId": "988a2cdb-bf28-4839-b027-aa9f8e1dbe3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
              "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
              "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
              "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
              "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
              "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
              "\n",
              "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
              "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
              "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
              "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
              "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
              "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
              "\n",
              "                  MTRANS           NObeyesdad  \n",
              "0  Public_Transportation        Normal_Weight  \n",
              "1  Public_Transportation        Normal_Weight  \n",
              "2  Public_Transportation        Normal_Weight  \n",
              "3                Walking   Overweight_Level_I  \n",
              "4  Public_Transportation  Overweight_Level_II  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff4573c6-1a28-4b78-9dee-7b55e55a746d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>64.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>56.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>77.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>87.0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Walking</td>\n",
              "      <td>Overweight_Level_I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.78</td>\n",
              "      <td>89.8</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Overweight_Level_II</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff4573c6-1a28-4b78-9dee-7b55e55a746d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff4573c6-1a28-4b78-9dee-7b55e55a746d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff4573c6-1a28-4b78-9dee-7b55e55a746d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b06df9a-191a-432d-8ce6-50225ed1facc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b06df9a-191a-432d-8ce6-50225ed1facc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b06df9a-191a-432d-8ce6-50225ed1facc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2111,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.3459682737322405,\n        \"min\": 14.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 1402,\n        \"samples\": [\n          25.526746,\n          26.740655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09330481986792,\n        \"min\": 1.45,\n        \"max\": 1.98,\n        \"num_unique_values\": 1574,\n        \"samples\": [\n          1.760175,\n          1.688436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.191171745204688,\n        \"min\": 39.0,\n        \"max\": 173.0,\n        \"num_unique_values\": 1525,\n        \"samples\": [\n          120.702935,\n          64.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_history_with_overweight\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAVC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FCVC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5339265785033023,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 810,\n        \"samples\": [\n          2.987148,\n          2.939727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7780386488418594,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 635,\n        \"samples\": [\n          1.468948,\n          2.9948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CAEC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Frequently\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMOKE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CH2O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6129534517968702,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1268,\n        \"samples\": [\n          2.395387,\n          1.983973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8505924308367011,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1190,\n        \"samples\": [\n          1.655488,\n          2.433918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TUE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6089272596763761,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1129,\n        \"samples\": [\n          1.416353,\n          0.878258\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CALC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Sometimes\",\n          \"Always\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MTRANS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Walking\",\n          \"Bike\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NObeyesdad\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Normal_Weight\",\n          \"Overweight_Level_I\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6NtFNjPU-9Q",
        "outputId": "f823e096-732a-4128-fdc7-1a19d4d9e74b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2111 entries, 0 to 2110\n",
            "Data columns (total 17 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Gender                          2111 non-null   object \n",
            " 1   Age                             2111 non-null   float64\n",
            " 2   Height                          2111 non-null   float64\n",
            " 3   Weight                          2111 non-null   float64\n",
            " 4   family_history_with_overweight  2111 non-null   object \n",
            " 5   FAVC                            2111 non-null   object \n",
            " 6   FCVC                            2111 non-null   float64\n",
            " 7   NCP                             2111 non-null   float64\n",
            " 8   CAEC                            2111 non-null   object \n",
            " 9   SMOKE                           2111 non-null   object \n",
            " 10  CH2O                            2111 non-null   float64\n",
            " 11  SCC                             2111 non-null   object \n",
            " 12  FAF                             2111 non-null   float64\n",
            " 13  TUE                             2111 non-null   float64\n",
            " 14  CALC                            2111 non-null   object \n",
            " 15  MTRANS                          2111 non-null   object \n",
            " 16  NObeyesdad                      2111 non-null   object \n",
            "dtypes: float64(8), object(9)\n",
            "memory usage: 280.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PjWBh1oEVDRL",
        "outputId": "88ff05c5-922a-47e5-f1fb-8b38f5d13ce7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Age       Height       Weight         FCVC          NCP  \\\n",
              "count  2111.000000  2111.000000  2111.000000  2111.000000  2111.000000   \n",
              "mean     24.312600     1.701677    86.586058     2.419043     2.685628   \n",
              "std       6.345968     0.093305    26.191172     0.533927     0.778039   \n",
              "min      14.000000     1.450000    39.000000     1.000000     1.000000   \n",
              "25%      19.947192     1.630000    65.473343     2.000000     2.658738   \n",
              "50%      22.777890     1.700499    83.000000     2.385502     3.000000   \n",
              "75%      26.000000     1.768464   107.430682     3.000000     3.000000   \n",
              "max      61.000000     1.980000   173.000000     3.000000     4.000000   \n",
              "\n",
              "              CH2O          FAF          TUE  \n",
              "count  2111.000000  2111.000000  2111.000000  \n",
              "mean      2.008011     1.010298     0.657866  \n",
              "std       0.612953     0.850592     0.608927  \n",
              "min       1.000000     0.000000     0.000000  \n",
              "25%       1.584812     0.124505     0.000000  \n",
              "50%       2.000000     1.000000     0.625350  \n",
              "75%       2.477420     1.666678     1.000000  \n",
              "max       3.000000     3.000000     2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17f77c44-012d-47e8-b3d7-7c2e83ad5eab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "      <td>2111.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24.312600</td>\n",
              "      <td>1.701677</td>\n",
              "      <td>86.586058</td>\n",
              "      <td>2.419043</td>\n",
              "      <td>2.685628</td>\n",
              "      <td>2.008011</td>\n",
              "      <td>1.010298</td>\n",
              "      <td>0.657866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.345968</td>\n",
              "      <td>0.093305</td>\n",
              "      <td>26.191172</td>\n",
              "      <td>0.533927</td>\n",
              "      <td>0.778039</td>\n",
              "      <td>0.612953</td>\n",
              "      <td>0.850592</td>\n",
              "      <td>0.608927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>19.947192</td>\n",
              "      <td>1.630000</td>\n",
              "      <td>65.473343</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.658738</td>\n",
              "      <td>1.584812</td>\n",
              "      <td>0.124505</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.777890</td>\n",
              "      <td>1.700499</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>2.385502</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.768464</td>\n",
              "      <td>107.430682</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.477420</td>\n",
              "      <td>1.666678</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.980000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f77c44-012d-47e8-b3d7-7c2e83ad5eab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17f77c44-012d-47e8-b3d7-7c2e83ad5eab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17f77c44-012d-47e8-b3d7-7c2e83ad5eab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a6aafe6-9d55-47c3-9318-06a1fb0f09e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a6aafe6-9d55-47c3-9318-06a1fb0f09e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a6aafe6-9d55-47c3-9318-06a1fb0f09e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 737.7175023586611,\n        \"min\": 6.3459682737322405,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          24.312599908574136,\n          22.77789,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.8299972253056,\n        \"min\": 0.09330481986792,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.7016773533870204,\n          1.700499,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 718.4335873262646,\n        \"min\": 26.191171745204688,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          86.58605812648035,\n          83.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FCVC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.6275281444425,\n        \"min\": 0.5339265785033023,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          2.4190430615821885,\n          2.385502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.4871624512587,\n        \"min\": 0.7780386488418594,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          2.6856280497394596,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CH2O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.7109998154965,\n        \"min\": 0.6129534517968702,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.0080114040738986,\n          2.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FAF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 745.9653105606202,\n        \"min\": 0.0,\n        \"max\": 2111.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.0102976958787304,\n          1.0,\n          2111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TUE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 746.1043827244515,\n        \"min\": 0.0,\n        \"max\": 2111.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2111.0,\n          0.657865923732828,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "8dTZZUFMVHYE",
        "outputId": "6a9cb67c-bfa8-428e-d82d-2176e165c010"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gender                            0\n",
              "Age                               0\n",
              "Height                            0\n",
              "Weight                            0\n",
              "family_history_with_overweight    0\n",
              "FAVC                              0\n",
              "FCVC                              0\n",
              "NCP                               0\n",
              "CAEC                              0\n",
              "SMOKE                             0\n",
              "CH2O                              0\n",
              "SCC                               0\n",
              "FAF                               0\n",
              "TUE                               0\n",
              "CALC                              0\n",
              "MTRANS                            0\n",
              "NObeyesdad                        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAVC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FCVC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NCP</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CAEC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOKE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CH2O</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TUE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CALC</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MTRANS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NObeyesdad</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psRsbSTZVLEO",
        "outputId": "1412be20-f3cd-4ca2-cb39-efc823117f23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight',\n",
              "       'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE',\n",
              "       'CALC', 'MTRANS', 'NObeyesdad'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan encoding pada kolom kategorikal menggunakan LabelEncoder\n",
        "label_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "VYAZvW9-VcL-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan fitur (X) dan target (y)\n",
        "X = df.drop(['NObeyesdad'], axis=1)  # Menghapus kolom target\n",
        "y = df['NObeyesdad']  # Kolom target"
      ],
      "metadata": {
        "id": "Xz5Cg6iIVaKF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data menjadi training dan testing (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hlhwFJ0tVfRz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-Uzki0k_VjYk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi data ke tensor\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Untuk klasifikasi, y harus bertipe long (integer)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "SbU94sWGVlzb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyusun model MLP untuk klasifikasi\n",
        "class MLPClassification(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons, activation):\n",
        "        super(MLPClassification, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.neurons = neurons\n",
        "        self.activation = activation\n",
        "\n",
        "        # Membuat layer input ke layer tersembunyi\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(self.input_size, self.neurons))\n",
        "\n",
        "        # Menambahkan hidden layers\n",
        "        for _ in range(self.hidden_layers - 1):\n",
        "            layers.append(self.activation())\n",
        "            layers.append(nn.Linear(self.neurons, self.neurons))\n",
        "\n",
        "        layers.append(nn.Linear(self.neurons, len(y.unique())))  # Jumlah kelas output (misalnya, 2 atau lebih)\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "TSOuzRr7VnsC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup perangkat (GPU jika tersedia)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Av-ah7C7Vrdr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter yang akan diuji\n",
        "hidden_layers = [1, 2, 3]\n",
        "neurons = [4, 8, 16, 32, 64]\n",
        "activations = [nn.Sigmoid, nn.Softmax, nn.ReLU, nn.Tanh]\n",
        "epochs_list = [1,10,25,50,100,250]\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16,32,64,128,256,512]\n",
        "\n",
        "# Menyimpan hasil\n",
        "results = []"
      ],
      "metadata": {
        "id": "811dMZirVzgN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan eksperimen dengan kombinasi hyperparameter\n",
        "for layers in hidden_layers:\n",
        "    for neuron in neurons:\n",
        "        for activation in activations:\n",
        "            for epochs in epochs_list:\n",
        "                for lr in learning_rates:\n",
        "                    for batch_size in batch_sizes:\n",
        "                        # Membuat dan memindahkan model ke perangkat (GPU atau CPU)\n",
        "                        model = MLPClassification(input_size=X_train_tensor.shape[1],\n",
        "                                                  hidden_layers=layers,\n",
        "                                                  neurons=neuron,\n",
        "                                                  activation=activation).to(device)\n",
        "\n",
        "                        # Mendefinisikan loss function dan optimizer\n",
        "                        criterion = nn.CrossEntropyLoss()  # Untuk klasifikasi multi-kelas\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                        # Training loop\n",
        "                        for epoch in range(epochs):\n",
        "                            model.train()\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(X_train_tensor.to(device))\n",
        "                            loss = criterion(outputs, y_train_tensor.to(device))\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                        # Evaluasi model setelah pelatihan\n",
        "                        model.eval()\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(X_test_tensor.to(device))\n",
        "                            _, predicted = torch.max(outputs, 1)  # Mengambil kelas dengan probabilitas tertinggi\n",
        "                            accuracy = accuracy_score(y_test_tensor.cpu(), predicted.cpu())\n",
        "\n",
        "                        # Menyimpan hasil\n",
        "                        results.append({\n",
        "                            'layers': layers,\n",
        "                            'neurons': neuron,\n",
        "                            'activation': activation.__name__,\n",
        "                            'epochs': epochs,\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'accuracy': accuracy\n",
        "                        })\n",
        "                        print(f\"Layers: {layers}, Neurons: {neuron}, Activation: {activation.__name__}, Epochs: {epochs}, LR: {lr}, Batch Size: {batch_size}, Accuracy:{accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKexrvwNWAW7",
        "outputId": "d6edb09e-b175-4116-cff6-d67c294303b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.07565011820330969\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.23167848699763594\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.3475177304964539\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.37115839243498816\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.33569739952718675\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7446808510638298\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8274231678486997\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8676122931442081\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.39952718676122934\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.28132387706855794\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.817966903073286\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5153664302600472\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3333333333333333\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.06619385342789598\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.04491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.37825059101654845\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.4160756501182033\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4728132387706856\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.26713947990543735\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.83451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.07565011820330969\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.8676122931442081\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7115839243498818\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3215130023640662\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6808510638297872\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.8652482269503546\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.05673758865248227\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.04491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.3049645390070922\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.4066193853427896\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.06619385342789598\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.018912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5153664302600472\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.44680851063829785\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.49645390070921985\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3049645390070922\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3617021276595745\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.6170212765957447\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.817966903073286\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.8770685579196218\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6146572104018913\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.25295508274231676\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7304964539007093\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3191489361702128\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.23167848699763594\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.42789598108747046\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.05673758865248227\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.03309692671394799\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.23404255319148937\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.028368794326241134\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5271867612293144\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6335697399527187\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.28132387706855794\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7399527186761229\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.09692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.23404255319148937\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7730496453900709\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3404255319148936\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.35697399527186763\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9030732860520094\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.44680851063829785\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5484633569739953\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.04964539007092199\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.037825059101654845\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.375886524822695\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.3806146572104019\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.4160756501182033\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5200945626477541\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5271867612293144\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6690307328605201\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6855791962174941\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.4373522458628842\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.07565011820330969\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.23404255319148937\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.40189125295508277\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7730496453900709\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3877068557919622\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6146572104018913\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.05200945626477541\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.03546099290780142\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.05673758865248227\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.35933806146572106\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.25295508274231676\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.6524822695035462\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.39243498817966904\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.42080378250591016\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9030732860520094\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4846335697399527\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5697399527186762\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6855791962174941\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6855791962174941\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3404255319148936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3404255319148936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.4160756501182033\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.23167848699763594\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.04018912529550828\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.04018912529550828\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.3049645390070922\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.37115839243498816\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3333333333333333\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.07565011820330969\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.49645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7399527186761229\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6430260047281324\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.41371158392434987\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.425531914893617\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.41371158392434987\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.42789598108747046\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.44208037825059104\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.04964539007092199\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8676122931442081\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8936170212765957\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6832151300236406\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.3475177304964539\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2789598108747045\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.23404255319148937\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.425531914893617\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3877068557919622\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.4066193853427896\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8676122931442081\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.04964539007092199\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.026004728132387706\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.09692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.3664302600472813\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.05200945626477541\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3877068557919622\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4846335697399527\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6855791962174941\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.42789598108747046\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3877068557919622\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7446808510638298\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8226950354609929\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7399527186761229\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5484633569739953\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.2718676122931442\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7943262411347518\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.43498817966903075\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.39952718676122934\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3617021276595745\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.26713947990543735\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.05200945626477541\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.07565011820330969\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.44680851063829785\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5839243498817966\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.3049645390070922\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6170212765957447\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6170212765957447\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9030732860520094\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7115839243498818\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.44208037825059104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.42080378250591016\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.38534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5271867612293144\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6524822695035462\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6430260047281324\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6430260047281324\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.375886524822695\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.02364066193853428\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.3829787234042553\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.03309692671394799\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.8037825059101655\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7730496453900709\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.33569739952718675\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.25295508274231676\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.30260047281323876\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.04018912529550828\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.07328605200945626\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.037825059101654845\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.026004728132387706\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.05673758865248227\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.2978723404255319\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4373522458628842\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.3191489361702128\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5839243498817966\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.37825059101654845\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5839243498817966\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2695035460992908\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.30969267139479906\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.25295508274231676\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8226950354609929\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9030732860520094\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.23404255319148937\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2907801418439716\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6832151300236406\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.425531914893617\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.47044917257683216\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.40189125295508277\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.09692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5484633569739953\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.06619385342789598\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.07328605200945626\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3900709219858156\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5839243498817966\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.3262411347517731\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.83451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6572104018912529\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.2718676122931442\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.47044917257683216\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.41371158392434987\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.4160756501182033\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9858156028368794\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8983451536643026\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6524822695035462\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6572104018912529\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6808510638297872\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.037825059101654845\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.26004728132387706\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.3333333333333333\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.07328605200945626\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6855791962174941\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6737588652482269\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.26713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8652482269503546\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5130023640661938\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.47044917257683216\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8817966903073287\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8108747044917257\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.44208037825059104\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.4231678486997636\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.40189125295508277\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.05200945626477541\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.016548463356973995\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.44680851063829785\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.43498817966903075\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.20094562647754138\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.06619385342789598\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.24113475177304963\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.6146572104018913\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.2718676122931442\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.83451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8274231678486997\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.375886524822695\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.4302600472813239\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5200945626477541\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.524822695035461\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.49645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.25295508274231676\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8936170212765957\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8770685579196218\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.8652482269503546\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6926713947990544\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.32860520094562645\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.37115839243498816\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4373522458628842\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.04964539007092199\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.0591016548463357\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.09692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.35933806146572106\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.22695035460992907\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.3617021276595745\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.08747044917257683\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.061465721040189124\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.48226950354609927\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7943262411347518\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5484633569739953\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5200945626477541\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.2978723404255319\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8037825059101655\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6737588652482269\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6572104018912529\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6690307328605201\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3262411347517731\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7730496453900709\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.44680851063829785\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5224586288416075\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.42789598108747046\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9030732860520094\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.32860520094562645\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.37825059101654845\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4066193853427896\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.05200945626477541\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.028368794326241134\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1702127659574468\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.4515366430260047\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.43498817966903075\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.39952718676122934\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.24349881796690306\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.26713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.6170212765957447\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.6713947990543735\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5697399527186762\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8274231678486997\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.83451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8605200945626478\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6832151300236406\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6643026004728132\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.425531914893617\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.4160756501182033\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.41371158392434987\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.20567375886524822\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.4066193853427896\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5153664302600472\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.08983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8794326241134752\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6170212765957447\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7021276595744681\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6973995271867612\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7115839243498818\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6997635933806147\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6903073286052009\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.3806146572104019\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.3640661938534279\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.46335697399527187\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.375886524822695\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.03546099290780142\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.08037825059101655\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.06855791962174941\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.5295508274231678\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.5484633569739953\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.32860520094562645\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.35933806146572106\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.3073286052009456\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5555555555555556\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.6572104018912529\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7541371158392435\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.35224586288416077\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.35933806146572106\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8014184397163121\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8557919621749409\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.7186761229314421\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7304964539007093\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6879432624113475\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.42789598108747046\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.4562647754137116\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.10401891252955082\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.2695035460992908\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9078014184397163\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8581560283687943\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8226950354609929\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8368794326241135\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5673758865248227\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.3475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.2364066193853428\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6430260047281324\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6595744680851063\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.3262411347517731\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.33569739952718675\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7446808510638298\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7304964539007093\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.75177304964539\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.4657210401891253\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.026004728132387706\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.07092198581560284\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.0425531914893617\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.04964539007092199\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.07801418439716312\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.3049645390070922\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.5366430260047281\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.3215130023640662\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.07328605200945626\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.26713947990543735\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.6737588652482269\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5910165484633569\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.6028368794326241\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7848699763593381\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.6335697399527187\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.6146572104018913\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.6335697399527187\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.42080378250591016\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.19621749408983452\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.06382978723404255\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8037825059101655\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7494089834515366\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8132387706855791\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7588652482269503\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7683215130023641\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7115839243498818\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7257683215130024\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7092198581560284\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.4491725768321513\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.4444444444444444\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.4397163120567376\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8888888888888888\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5626477541371159\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.2293144208037825\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.8652482269503546\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.8841607565011821\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6784869976359338\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6359338061465721\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6761229314420804\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.27423167848699764\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.40425531914893614\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.8936170212765957\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.983451536643026\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7399527186761229\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5035460992907801\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.508274231678487\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.45390070921985815\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.4988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.49645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.5106382978723404\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.09219858156028368\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.2860520094562648\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5200945626477541\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5200945626477541\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.2978723404255319\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.08274231678486997\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.6099290780141844\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.47044917257683216\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6288416075650118\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5531914893617021\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.8037825059101655\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.8085106382978723\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6264775413711584\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.6430260047281324\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.37825059101654845\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.33569739952718675\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.3806146572104019\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.32860520094562645\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.22458628841607564\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.09692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13947990543735225\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8226950354609929\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.789598108747045\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7612293144208038\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8274231678486997\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.723404255319149\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7163120567375887\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.4799054373522459\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.9148936170212766\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8274231678486997\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.851063829787234\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8321513002364066\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8463356973995272\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8486997635933806\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5650118203309693\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5697399527186762\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9125295508274232\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6382978723404256\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6619385342789598\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6501182033096927\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.640661938534279\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.3735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.19858156028368795\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.3191489361702128\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3971631205673759\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.8865248226950354\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.8959810874704491\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7470449172576832\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7423167848699763\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.7328605200945626\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7304964539007093\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.46099290780141844\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.037825059101654845\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.04728132387706856\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.06619385342789598\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.05673758865248227\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.2198581560283688\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.5437352245862884\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5342789598108747\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.541371158392435\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.34988179669030733\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.41843971631205673\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.30023640661938533\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.29550827423167847\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.3947990543735225\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.23877068557919623\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.17966903073286053\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.09456264775413711\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.054373522458628844\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.5721040189125296\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5981087470449172\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.624113475177305\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5957446808510638\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.6312056737588653\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.6477541371158393\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5791962174940898\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.6737588652482269\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7565011820330969\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7872340425531915\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.6122931442080378\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6193853427895981\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5862884160756501\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6052009456264775\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.4444444444444444\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.36879432624113473\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.3546099290780142\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1016548463356974\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.2458628841607565\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.8392434988179669\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.8628841607565012\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.7659574468085106\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.8747044917257684\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.8156028368794326\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7990543735224587\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.7919621749408984\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7281323877068558\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7139479905437353\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7044917257683215\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.706855791962175\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5177304964539007\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.47044917257683216\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5011820330969267\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.0851063829787234\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.2576832151300236\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.8723404255319149\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8250591016548463\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.83451536643026\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8297872340425532\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8534278959810875\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8416075650118203\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5768321513002365\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5508274231678487\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.574468085106383\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.25059101654846333\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.24822695035460993\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.21513002364066194\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.2553191489361702\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.8652482269503546\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.7210401891252955\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.9243498817966903\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.8912529550827423\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9739952718676123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6572104018912529\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6524822695035462\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6666666666666666\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6453900709219859\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6548463356973995\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.408983451536643\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.43498817966903075\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.3120567375886525\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.34515366430260047\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.32387706855791965\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.900709219858156\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.9054373522458629\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.8439716312056738\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9810874704491725\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9716312056737588\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7446808510638298\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7375886524822695\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.735224586288416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7446808510638298\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.46808510638297873\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.5460992907801419\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.47754137115839246\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.491725768321513\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.07328605200945626\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.09219858156028368\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.491725768321513\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.7872340425531915\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6619385342789598\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.41371158392434987\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.35224586288416077\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6288416075650118\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.5602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.6808510638297872\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.6264775413711584\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.5177304964539007\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8628841607565012\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8936170212765957\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.04018912529550828\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.37115839243498816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.47754137115839246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.2553191489361702\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.24822695035460993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.37115839243498816\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.42789598108747046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6122931442080378\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6643026004728132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.6808510638297872\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.6643026004728132\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.6737588652482269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.16784869976359337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.3546099290780142\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2695035460992908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.2576832151300236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2198581560283688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.4846335697399527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5106382978723404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.4231678486997636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.3262411347517731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.4657210401891253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.1702127659574468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.16784869976359337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.03546099290780142\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.15602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.24113475177304963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.20803782505910165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.2789598108747045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.28841607565011823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6193853427895981\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.4940898345153664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.42080378250591016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9621749408983451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.6832151300236406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.5933806146572104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.6382978723404256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.6477541371158393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.607565011820331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.17494089834515367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.19148936170212766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.22695035460992907\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.2695035460992908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.17494089834515367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.42789598108747046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.2624113475177305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.3333333333333333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.5508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.5200945626477541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.6382978723404256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5721040189125296\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6784869976359338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9598108747044918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9716312056737588\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9787234042553191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9479905437352246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9148936170212766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.8865248226950354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9030732860520094\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.3971631205673759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.41371158392434987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.34278959810874704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.3829787234042553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.23404255319148937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.06382978723404255\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.08747044917257683\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6122931442080378\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.40425531914893614\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.08747044917257683\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.817966903073286\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.900709219858156\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7446808510638298\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5011820330969267\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.37115839243498816\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.2553191489361702\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6122931442080378\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.06855791962174941\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.32387706855791965\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.6028368794326241\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.900709219858156\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5484633569739953\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.09929078014184398\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.2553191489361702\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6784869976359338\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.6028368794326241\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9763593380614657\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7872340425531915\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7399527186761229\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7990543735224587\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.35224586288416077\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.7163120567375887\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.723404255319149\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5602836879432624\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8297872340425532\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8226950354609929\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.4657210401891253\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6193853427895981\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6643026004728132\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.789598108747045\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8132387706855791\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8557919621749409\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8085106382978723\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.8439716312056738\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8676122931442081\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8250591016548463\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.8912529550827423\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.8841607565011821\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.900709219858156\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.061465721040189124\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.23877068557919623"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.41134751773049644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5957446808510638"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.2695035460992908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.1938534278959811\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.29550827423167847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.35224586288416077\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.4326241134751773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.41371158392434987\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.35224586288416077\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8108747044917257\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7872340425531915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.41134751773049644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3475177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.425531914893617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.30969267139479906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.2718676122931442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.41134751773049644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.4799054373522459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.4728132387706856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.4491725768321513\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9196217494089834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8628841607565012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5484633569739953\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.5626477541371159\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.22458628841607564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.16312056737588654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5011820330969267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.2860520094562648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.4160756501182033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.34278959810874704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.2293144208037825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.2978723404255319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.541371158392435\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5862884160756501\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6666666666666666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.48226950354609927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9385342789598109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9692671394799054\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7565011820330969\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.7281323877068558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7163120567375887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.75177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6903073286052009\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.6926713947990544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.21749408983451538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3191489361702128\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3877068557919622\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.21749408983451538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.30023640661938533\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3120567375886525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.35224586288416077\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.3877068557919622\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.2222222222222222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.44680851063829785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6477541371158393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.5886524822695035\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5531914893617021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7044917257683215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6052009456264775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9787234042553191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8368794326241135\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9598108747044918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9243498817966903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9243498817966903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9196217494089834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9432624113475178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.4799054373522459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.491725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.43498817966903075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.46335697399527187\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.15130023640661938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2553191489361702\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.09219858156028368\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.75177304964539\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6879432624113475\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6761229314420804\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.07801418439716312\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8652482269503546\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8983451536643026\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.48699763593380613\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.41371158392434987\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7186761229314421\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6713947990543735\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2553191489361702\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8439716312056738\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.32387706855791965\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.29550827423167847\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5768321513002365\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6099290780141844\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7281323877068558\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.24113475177304963\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.491725768321513\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.83451536643026\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.900709219858156\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8676122931442081\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5886524822695035\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7210401891252955\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7092198581560284\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6761229314420804\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.7163120567375887\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.7163120567375887\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.735224586288416\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9787234042553191\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8983451536643026\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9054373522458629\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.38534278959810875\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.38534278959810875\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7423167848699763\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7092198581560284\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6666666666666666\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6312056737588653\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6122931442080378\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4657210401891253\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.40425531914893614\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8676122931442081\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8416075650118203\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6217494089834515\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.4491725768321513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5177304964539007\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9148936170212766\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7092198581560284\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.32860520094562645\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.5366430260047281\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5484633569739953\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6666666666666666\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6430260047281324\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.8156028368794326\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6359338061465721\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6099290780141844\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6524822695035462\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.07565011820330969\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.23877068557919623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6453900709219859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.574468085106383\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6170212765957447\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.35697399527186763\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.06382978723404255\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.3073286052009456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.2718676122931442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.4160756501182033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8297872340425532\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7872340425531915\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7754137115839244\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8486997635933806\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.4326241134751773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.4846335697399527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.3971631205673759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.5059101654846335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5011820330969267\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5366430260047281\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.91725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6004728132387707\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6170212765957447\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.607565011820331\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6288416075650118\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3073286052009456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.16312056737588654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.1938534278959811\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.40189125295508277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.15839243498817968\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.3664302600472813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.40189125295508277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.43498817966903075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.3546099290780142\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6193853427895981\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.5768321513002365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.5271867612293144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.6052009456264775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9267139479905437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9243498817966903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7943262411347518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8132387706855791\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7990543735224587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7825059101654847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8250591016548463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8392434988179669\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.30023640661938533\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3120567375886525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.41371158392434987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3664302600472813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.3404255319148936\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.11583924349881797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.38534278959810875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.35933806146572106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.2647754137115839\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.36879432624113473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.36879432624113473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.42080378250591016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6264775413711584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.557919621749409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5839243498817966\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.5815602836879432\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5981087470449172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6784869976359338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9361702127659575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9148936170212766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.933806146572104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.557919621749409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5791962174940898\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5531914893617021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5957446808510638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.15130023640661938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.19621749408983452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.06619385342789598\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.07801418439716312\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.24113475177304963\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.07092198581560284\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.24113475177304963\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.735224586288416\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.24349881796690306\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.29550827423167847\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6146572104018913\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6170212765957447\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6430260047281324\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.806146572104019\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8156028368794326\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7801418439716312\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8250591016548463\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8297872340425532\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3546099290780142\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3806146572104019\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.27423167848699764\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.41371158392434987\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7210401891252955\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.25295508274231676\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.40425531914893614\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.04018912529550828\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.48699763593380613\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5177304964539007\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.806146572104019\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.06855791962174941\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.05200945626477541\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.6335697399527187\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.6312056737588653\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.5484633569739953\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9078014184397163\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9054373522458629\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6666666666666666\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.07565011820330969\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6430260047281324\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.6855791962174941\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8132387706855791\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.789598108747045\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8085106382978723\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8534278959810875\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.4657210401891253\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.5011820330969267\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5650118203309693\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5650118203309693\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.6713947990543735\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.607565011820331\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.6217494089834515\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.6879432624113475\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.607565011820331\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.7754137115839244\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.817966903073286\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7281323877068558\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8392434988179669\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.75177304964539\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.3546099290780142\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1016548463356974\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5200945626477541\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.24113475177304963\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6028368794326241\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.75177304964539\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6430260047281324\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7872340425531915\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6312056737588653\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.40425531914893614\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.37115839243498816\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.7210401891252955\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8912529550827423\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8274231678486997\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8463356973995272\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6855791962174941\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.22458628841607564\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.27423167848699764\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.6855791962174941\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.5177304964539007\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.6548463356973995\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.8297872340425532\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7848699763593381\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.83451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.41843971631205673\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.3049645390070922\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2765957446808511\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.061465721040189124\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.2695035460992908\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.32860520094562645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.35697399527186763\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.425531914893617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6335697399527187\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6832151300236406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6335697399527187\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.27423167848699764\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.34278959810874704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.3900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.42789598108747046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.45390070921985815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.46099290780141844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8463356973995272\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.83451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8416075650118203\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8132387706855791\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8321513002364066\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5200945626477541\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.48699763593380613\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5200945626477541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.3806146572104019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.35933806146572106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.40189125295508277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.4231678486997636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.42080378250591016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.4491725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.4728132387706856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.508274231678487\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5130023640661938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.4657210401891253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9078014184397163\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9148936170212766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8888888888888888\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9125295508274232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.900709219858156\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.6973995271867612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7139479905437353\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7163120567375887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6713947990543735\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3333333333333333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.3309692671394799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.2978723404255319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3309692671394799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18203309692671396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.41134751773049644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.425531914893617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.35697399527186763\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.2127659574468085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.5602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5342789598108747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.524822695035461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.5531914893617021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5862884160756501\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5626477541371159\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.8794326241134752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9125295508274232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.851063829787234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.851063829787234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8297872340425532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8676122931442081\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8534278959810875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.39243498817966904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.4326241134751773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.39243498817966904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.4491725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3971631205673759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.425531914893617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.23404255319148937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.33569739952718675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.45390070921985815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.40189125295508277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.4397163120567376\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.5650118203309693\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.6690307328605201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.6217494089834515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.6855791962174941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6028368794326241\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9125295508274232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.8865248226950354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.8936170212765957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.8936170212765957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8983451536643026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9054373522458629\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6288416075650118\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.624113475177305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6217494089834515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.640661938534279\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6453900709219859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6052009456264775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.2127659574468085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2624113475177305\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.24113475177304963\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.23404255319148937\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.40189125295508277\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7494089834515366\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.723404255319149\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7163120567375887\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5886524822695035\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5177304964539007\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.0851063829787234\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6359338061465721\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8652482269503546\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8723404255319149\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7872340425531915\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.7825059101654847\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7494089834515366\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.46335697399527187\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.3664302600472813\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.30260047281323876\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.4728132387706856\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8936170212765957\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8888888888888888\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9054373522458629\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.24822695035460993\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5650118203309693\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6643026004728132\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6453900709219859\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.6288416075650118\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.41371158392434987\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8156028368794326\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8274231678486997\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.83451536643026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.8628841607565012\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.3947990543735225\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.10401891252955082\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.07328605200945626\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.05673758865248227\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.40425531914893614\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.4160756501182033\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.08983451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.07801418439716312\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.07565011820330969\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4491725768321513\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7494089834515366\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7328605200945626\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5839243498817966\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6122931442080378\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.30969267139479906\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.061465721040189124\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6619385342789598\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7186761229314421\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9148936170212766\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9078014184397163\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8983451536643026\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.9125295508274232\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.3971631205673759\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.640661938534279\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.6855791962174941\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.6643026004728132\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.7423167848699763\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.7494089834515366\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.7966903073286052\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.7423167848699763\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9030732860520094\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9078014184397163\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.28132387706855794\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.7186761229314421\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.7754137115839244\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.8108747044917257\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9763593380614657\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6808510638297872\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.39952718676122934\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7399527186761229\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.7470449172576832\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7825059101654847\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7754137115839244\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8557919621749409\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8392434988179669\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8321513002364066\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8439716312056738\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3829787234042553\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.2293144208037825\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.3191489361702128\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.35224586288416077\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.3735224586288416\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.3309692671394799\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.2789598108747045\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5200945626477541\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4988179669030733\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.0851063829787234\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1773049645390071\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.5650118203309693\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.5484633569739953\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.5886524822695035\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6997635933806147\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.7210401891252955\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.48699763593380613\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.42789598108747046\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.6950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.6217494089834515\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.6288416075650118\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.6524822695035462\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.8085106382978723\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6619385342789598\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.7021276595744681\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8439716312056738\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8108747044917257\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8132387706855791\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5484633569739953\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.3215130023640662\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.6524822695035462\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.6855791962174941\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.8085106382978723\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.91725768321513\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9716312056737588\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6619385342789598\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6477541371158393\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.6784869976359338\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7163120567375887\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.7139479905437353\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8392434988179669\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.817966903073286\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7990543735224587\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8723404255319149\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.491725768321513\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.4799054373522459\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.09692671394799054\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.29314420803782504\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.25059101654846333\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1536643026004728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.2458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.34988179669030733\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.31678486997635935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3640661938534279\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.41843971631205673\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.4231678486997636\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6643026004728132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6430260047281324\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.41134751773049644\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.42789598108747046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.3971631205673759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.34278959810874704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.40425531914893614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.5035460992907801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.5130023640661938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5342789598108747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.4846335697399527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.4515366430260047\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8463356973995272\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8368794326241135\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.851063829787234\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8321513002364066\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8486997635933806\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.5791962174940898\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5366430260047281\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.2222222222222222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.24822695035460993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.41843971631205673\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.45390070921985815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.48226950354609927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5153664302600472\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.3971631205673759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.46335697399527187\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.541371158392435\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5200945626477541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.4373522458628842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8983451536643026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8699763593380615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.91725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8557919621749409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8983451536643026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.75177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7777777777777778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.7990543735224587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7706855791962175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7706855791962175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3262411347517731\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.35224586288416077\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.32860520094562645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3262411347517731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.3664302600472813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.44208037825059104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.4846335697399527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.4657210401891253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.3664302600472813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.5957446808510638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6099290780141844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.47044917257683216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.5130023640661938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5697399527186762\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.6288416075650118\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.8581560283687943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.8605200945626478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8817966903073287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4799054373522459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5106382978723404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.4562647754137116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5059101654846335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.4846335697399527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5531914893617021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.2860520094562648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.3120567375886525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.39243498817966904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.34988179669030733\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.47754137115839246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.4160756501182033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.5791962174940898\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.5200945626477541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.6572104018912529\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.5957446808510638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.49645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6359338061465721\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.8628841607565012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.8605200945626478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.8699763593380615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8652482269503546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.8676122931442081\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8605200945626478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.8983451536643026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.8817966903073287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6595744680851063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.7044917257683215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6832151300236406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6666666666666666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6761229314420804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6879432624113475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.19621749408983452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.29314420803782504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.24113475177304963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.07092198581560284\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3404255319148936\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.43498817966903075\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.4491725768321513\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.06855791962174941\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.17966903073286053\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.19858156028368795\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.12529550827423167\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.47754137115839246\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.375886524822695\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.640661938534279\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.6903073286052009\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.6761229314420804\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6690307328605201\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.6808510638297872\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.7257683215130024\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.3877068557919622\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.3900709219858156\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1938534278959811\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.3333333333333333\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.7446808510638298\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.6335697399527187\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.49645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.524822695035461\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.6264775413711584\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8723404255319149\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8888888888888888\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8794326241134752\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.8888888888888888\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.8676122931442081\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.8652482269503546\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5366430260047281\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5508274231678487\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5531914893617021\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.2458628841607565\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.26713947990543735\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2222222222222222\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.4326241134751773\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5295508274231678\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6832151300236406\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.6146572104018913\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6737588652482269\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9101654846335697\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8983451536643026\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9267139479905437\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.6170212765957447\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.6666666666666666\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.6382978723404256\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.6170212765957447\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.4066193853427896\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.3475177304964539\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5862884160756501\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.7777777777777778\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.817966903073286\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.6170212765957447\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.6572104018912529\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.7919621749408984\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.706855791962175\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6335697399527187\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.75177304964539\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.7565011820330969\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.4491725768321513\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.34515366430260047\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.4397163120567376\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.48936170212765956\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5673758865248227\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.8794326241134752\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.789598108747045\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.6524822695035462\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.83451536643026\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7754137115839244\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.8699763593380615\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.8416075650118203\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.7990543735224587\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9219858156028369\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8912529550827423\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8841607565011821\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.8983451536643026\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.5555555555555556\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.5697399527186762\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.5437352245862884\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.5626477541371159\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.3617021276595745\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.04964539007092199\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.21040189125295508\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.054373522458628844\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.2364066193853428\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.5153664302600472\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.44208037825059104\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.458628841607565\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.4846335697399527\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.47044917257683216\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.19148936170212766\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.2127659574468085\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.09456264775413711\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.44680851063829785\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.5933806146572104\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.5130023640661938\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.557919621749409\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5791962174940898\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7115839243498818\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5981087470449172\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6359338061465721\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.5957446808510638\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.7092198581560284\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.7210401891252955\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.7186761229314421\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.6619385342789598\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.475177304964539\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.4940898345153664\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.4373522458628842\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.4444444444444444\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.48226950354609927\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.21513002364066194\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1607565011820331\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.6666666666666666\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.6643026004728132\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.6784869976359338\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.6193853427895981\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.6926713947990544\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.7375886524822695\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.735224586288416\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.6595744680851063\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.7092198581560284\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8534278959810875\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8747044917257684\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8581560283687943\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8959810874704491\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.8628841607565012\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.8794326241134752\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.8770685579196218\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.8605200945626478\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.8794326241134752\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5059101654846335\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5224586288416075\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.5390070921985816\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5650118203309693\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.2553191489361702\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18203309692671396\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.30023640661938533\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2978723404255319\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.2033096926713948\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.7304964539007093\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.7683215130023641\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.8014184397163121\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.7943262411347518\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.806146572104019\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.7706855791962175\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.6217494089834515\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.6359338061465721\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.6359338061465721\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.6524822695035462\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.6501182033096927\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.624113475177305\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.36879432624113473\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.32387706855791965\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.2860520094562648\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.37825059101654845\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.33569739952718675\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.3073286052009456\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.7825059101654847\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.7423167848699763\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.7446808510638298\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.7825059101654847\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.75177304964539\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.8085106382978723\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.8156028368794326\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.8297872340425532\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.8108747044917257\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.8534278959810875\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.7494089834515366\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.7541371158392435\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.7635933806146572\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.7588652482269503\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.4562647754137116\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.4657210401891253\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.425531914893617\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.35933806146572106\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.46808510638297873\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.7659574468085106\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.7730496453900709\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.7966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.7612293144208038\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.7423167848699763\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.8037825059101655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.8203309692671394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9739952718676123\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9692671394799054\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9196217494089834\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5342789598108747\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.6004728132387707\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.5910165484633569\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.5721040189125296\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.5200945626477541\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.09929078014184398\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.35224586288416077\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.009456264775413711\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6737588652482269\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.5768321513002365\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.6572104018912529\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.6524822695035462\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.7470449172576832\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.6784869976359338\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8368794326241135\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.4160756501182033\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.3120567375886525\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.8581560283687943\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.5862884160756501\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.6170212765957447\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.607565011820331\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6099290780141844\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.23877068557919623\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.33569739952718675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.37115839243498816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.32860520094562645\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.09929078014184398\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.475177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.6430260047281324\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.5839243498817966\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.49645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.49645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.2907801418439716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.24822695035460993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.25295508274231676\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14420803782505912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8817966903073287\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8297872340425532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.7494089834515366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8226950354609929\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.35933806146572106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.43498817966903075\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.3144208037825059\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.30969267139479906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.29314420803782504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.08037825059101655\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.12529550827423167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.16548463356973994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.29550827423167847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.425531914893617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.3829787234042553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.8392434988179669\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8297872340425532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.5673758865248227\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.4940898345153664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.5839243498817966\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.41371158392434987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.4444444444444444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.18203309692671396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.31678486997635935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.45390070921985815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9621749408983451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9479905437352246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8817966903073287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.6052009456264775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.6997635933806147\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9196217494089834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.29550827423167847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.23167848699763594\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.28368794326241137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.09456264775413711\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.49645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.5626477541371159\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7139479905437353\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7210401891252955\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7281323877068558\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.789598108747045\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.7588652482269503\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.83451536643026\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.39952718676122934\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.46335697399527187\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.24349881796690306\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8463356973995272\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.7210401891252955\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8416075650118203\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8652482269503546\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8132387706855791\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6217494089834515\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8274231678486997\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.37825059101654845\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.26713947990543735\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.061465721040189124\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.21513002364066194\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.08983451536643026\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.08747044917257683\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.09219858156028368\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.06855791962174941\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6146572104018913\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.4988179669030733\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.3900709219858156\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.5271867612293144\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.4397163120567376\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.25295508274231676\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.09692671394799054\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.08274231678486997\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.06382978723404255\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.4397163120567376\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.48936170212765956\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8368794326241135\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6903073286052009\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7281323877068558\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7777777777777778\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.7494089834515366\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.43498817966903075\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.2789598108747045\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.35224586288416077\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8912529550827423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5815602836879432\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5342789598108747\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.2198581560283688\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.42080378250591016\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.48699763593380613\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5650118203309693\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9716312056737588\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.806146572104019\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.806146572104019\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8676122931442081\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7635933806146572\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.7163120567375887\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.851063829787234\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.34515366430260047\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.2695035460992908\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.10401891252955082\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.557919621749409\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.5177304964539007\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.4988179669030733\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9054373522458629\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.43498817966903075\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.3191489361702128\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.723404255319149\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7919621749408984\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7990543735224587\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7257683215130024\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.7801418439716312\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.36879432624113473\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3049645390070922\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.3664302600472813\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.39952718676122934\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8486997635933806\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9054373522458629\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7328605200945626\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8014184397163121\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8652482269503546\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.26713947990543735\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.40425531914893614\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.08747044917257683\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.04728132387706856\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6288416075650118\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.6052009456264775\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6619385342789598\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7021276595744681\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7115839243498818\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.25295508274231676\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.12056737588652482\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.3475177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.4231678486997636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8628841607565012\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8865248226950354\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8865248226950354\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.4515366430260047\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.3309692671394799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.31678486997635935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.1016548463356974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.1867612293144208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.2458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5224586288416075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.3073286052009456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9598108747044918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9385342789598109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.6832151300236406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.6903073286052009\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.5295508274231678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7021276595744681\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.6572104018912529\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.7139479905437353\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.2576832151300236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.2765957446808511\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.2198581560283688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.475177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.2860520094562648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.6382978723404256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7635933806146572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9645390070921985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9479905437352246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9527186761229315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9196217494089834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9361702127659575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.31678486997635935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.46099290780141844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5035460992907801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.29314420803782504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.04728132387706856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.15602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.09929078014184398\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.10638297872340426\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.028368794326241134\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6808510638297872\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.4397163120567376\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6312056737588653\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6052009456264775\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3049645390070922\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3144208037825059\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3144208037825059\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8156028368794326\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8841607565011821\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.7706855791962175\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8368794326241135\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8557919621749409\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8250591016548463\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.541371158392435\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.24113475177304963\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9078014184397163\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8912529550827423\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7801418439716312\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7470449172576832\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6430260047281324\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7304964539007093\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7612293144208038\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.7115839243498818\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.09929078014184398\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.39243498817966904\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.3735224586288416\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.39243498817966904\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6146572104018913\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6855791962174941\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.6453900709219859\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6122931442080378\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.607565011820331\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.6784869976359338\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.054373522458628844\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.2364066193853428\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.07092198581560284\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.08747044917257683\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.25059101654846333\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.23877068557919623\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.2198581560283688\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.2695035460992908\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6501182033096927\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.6572104018912529\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7399527186761229\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6524822695035462\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.37825059101654845\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3971631205673759\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.3073286052009456\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.4066193853427896\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.34515366430260047\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.42080378250591016\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8581560283687943\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.83451536643026\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.4515366430260047\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.41371158392434987\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.24349881796690306\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3120567375886525\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.23877068557919623\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.34515366430260047\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.3735224586288416\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.4302600472813239\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.7872340425531915\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.7588652482269503\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.706855791962175\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.7541371158392435\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.7801418439716312\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8274231678486997\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.2789598108747045\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.34515366430260047\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.21513002364066194\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.21513002364066194\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.2198581560283688\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.39243498817966904\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6903073286052009\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5862884160756501\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.607565011820331\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.5555555555555556\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.5011820330969267\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.3947990543735225\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.4491725768321513\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.49645390070921985\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.4373522458628842\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.25295508274231676\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6997635933806147\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.6288416075650118\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.5130023640661938\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.6713947990543735\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.7021276595744681\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.706855791962175\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6312056737588653\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.640661938534279\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.31678486997635935\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.17966903073286053\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.574468085106383\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.6761229314420804\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7825059101654847\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.44208037825059104\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.40425531914893614\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.4231678486997636\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8156028368794326\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.640661938534279\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6548463356973995\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.6052009456264775\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.6146572104018913\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.6619385342789598\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3049645390070922\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.40189125295508277\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.31678486997635935\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.44208037825059104\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5815602836879432\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5910165484633569\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.6312056737588653\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.6288416075650118\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.15839243498817968\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.09692671394799054\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.23877068557919623\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.15602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.1702127659574468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6217494089834515\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7281323877068558\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6903073286052009\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7304964539007093\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7399527186761229\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.6973995271867612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.24113475177304963\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.18203309692671396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.29550827423167847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2198581560283688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.08274231678486997\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.25059101654846333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.1536643026004728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.2647754137115839\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.26713947990543735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.2718676122931442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.24822695035460993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.950354609929078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8936170212765957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.4728132387706856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.34278959810874704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.4515366430260047\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.4326241134751773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.20803782505910165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.24822695035460993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.3404255319148936\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.42789598108747046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.4491725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.45390070921985815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.35697399527186763\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9385342789598109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9550827423167849\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8203309692671394\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8321513002364066\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.7541371158392435\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.7825059101654847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.706855791962175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.6690307328605201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.1276595744680851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.32387706855791965\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.12529550827423167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.43498817966903075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.3333333333333333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.22458628841607564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.2458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9267139479905437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9408983451536643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9432624113475178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9196217494089834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9290780141843972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.3829787234042553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.41134751773049644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.375886524822695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.43498817966903075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.4657210401891253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.40189125295508277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6524822695035462\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6548463356973995\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6146572104018913\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6430260047281324\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.3971631205673759\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.46335697399527187\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.05200945626477541\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8865248226950354\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8534278959810875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8250591016548463\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.624113475177305\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6335697399527187\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6052009456264775\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6028368794326241\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3120567375886525\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8439716312056738\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8463356973995272\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8652482269503546\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.36879432624113473\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4988179669030733\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5342789598108747\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5342789598108747\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8392434988179669\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8156028368794326\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8108747044917257\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8297872340425532\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8203309692671394\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.7706855791962175\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.2364066193853428\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.09456264775413711\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.061465721040189124\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.10638297872340426\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.36879432624113473\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.3333333333333333\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.2695035460992908\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.26004728132387706\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.08037825059101655\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.3144208037825059\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.34278959810874704\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.2364066193853428\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3735224586288416\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6808510638297872\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.7494089834515366\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7304964539007093\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.4373522458628842\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5035460992907801\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.49645390070921985\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.44208037825059104\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3971631205673759\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.08037825059101655\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.3640661938534279\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.5342789598108747\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8699763593380615\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6382978723404256\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6832151300236406\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.6761229314420804\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.6903073286052009\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.6926713947990544\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.24113475177304963\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.26713947990543735\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.2222222222222222\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.42080378250591016\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.40189125295508277\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.3947990543735225\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.37825059101654845\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.5011820330969267\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6099290780141844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.8747044917257684\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.47044917257683216\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.36879432624113473\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.39243498817966904\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.3806146572104019\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.3664302600472813\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6288416075650118\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6572104018912529\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.5886524822695035\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.5933806146572104\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.524822695035461\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.5910165484633569\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.40425531914893614\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6099290780141844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.6099290780141844\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.6170212765957447\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7115839243498818\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.6761229314420804\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8628841607565012\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8274231678486997\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8274231678486997\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.851063829787234\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8392434988179669\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.817966903073286\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.40189125295508277\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.32860520094562645\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.3617021276595745\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.43498817966903075\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.33569739952718675\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.4231678486997636\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5555555555555556\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.48699763593380613\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5862884160756501\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.12529550827423167\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.4302600472813239\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.6643026004728132\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.789598108747045\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.8581560283687943\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.3333333333333333\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.15839243498817968\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.900709219858156\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.3664302600472813\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.5177304964539007\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.43498817966903075\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.2978723404255319\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8983451536643026\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.8439716312056738\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.8085106382978723\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.8392434988179669\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.8912529550827423\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.8983451536643026\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.8463356973995272\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.3073286052009456\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.06855791962174941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13002364066193853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.09219858156028368\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.07801418439716312\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.1536643026004728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.30023640661938533\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.21513002364066194\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.38534278959810875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.41371158392434987\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.17257683215130024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.12056737588652482\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.2789598108747045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.16784869976359337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.4066193853427896\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.35224586288416077\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.2624113475177305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6288416075650118\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.6501182033096927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.735224586288416\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7115839243498818\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.6524822695035462\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.3947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.28841607565011823\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.26713947990543735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.36879432624113473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.07328605200945626\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.2127659574468085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.16784869976359337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.25295508274231676\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.15602836879432624\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.17257683215130024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.30969267139479906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.3333333333333333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.8628841607565012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8699763593380615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8676122931442081\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8747044917257684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8676122931442081\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5437352245862884\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.48699763593380613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.47044917257683216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5602836879432624\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.14657210401891252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.17257683215130024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.2127659574468085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.11347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.3829787234042553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.375886524822695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.3191489361702128\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.47754137115839246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9030732860520094\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9125295508274232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9125295508274232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.8557919621749409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8747044917257684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8368794326241135\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.851063829787234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.19621749408983452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.12529550827423167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.1702127659574468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.23877068557919623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.5460992907801419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.44208037825059104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.30969267139479906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.3120567375886525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.3309692671394799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9054373522458629\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.8794326241134752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9219858156028369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9148936170212766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.4302600472813239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.42080378250591016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.46099290780141844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5555555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.4397163120567376\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.16548463356973994\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.07092198581560284\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.08274231678486997\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.3191489361702128\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.17966903073286053\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6879432624113475\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.6666666666666666\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.6950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.6193853427895981\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5910165484633569\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5390070921985816\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.5437352245862884\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.5271867612293144\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.23167848699763594\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.09929078014184398\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7801418439716312\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8037825059101655\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.7966903073286052\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.7825059101654847\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.8085106382978723\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.8085106382978723\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.8156028368794326\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.48936170212765956\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.09219858156028368\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.24113475177304963\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9101654846335697\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8770685579196218\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5271867612293144\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5177304964539007\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.5035460992907801\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.17257683215130024\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6453900709219859\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.7304964539007093\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6832151300236406\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.7044917257683215\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.7612293144208038\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6713947990543735\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.3309692671394799\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.3900709219858156\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.91725768321513\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.900709219858156\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9054373522458629\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.9054373522458629\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.900709219858156\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.5035460992907801\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.4562647754137116\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.08983451536643026\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.0591016548463357\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.0425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.09219858156028368\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.1016548463356974\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.037825059101654845\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.41371158392434987\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.32387706855791965\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.3617021276595745\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.3333333333333333\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.37825059101654845\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.27423167848699764\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.21040189125295508\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.13947990543735225\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.04491725768321513\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1276595744680851\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.3049645390070922\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.34278959810874704\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.4302600472813239\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3900709219858156\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.3664302600472813\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.557919621749409\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.6548463356973995\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.7163120567375887\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.7163120567375887\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.5886524822695035\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.5910165484633569\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.557919621749409\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.3640661938534279\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.3877068557919622\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.39952718676122934\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.35697399527186763\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.47044917257683216\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.5437352245862884\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.5957446808510638\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.4397163120567376\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.9078014184397163\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.8652482269503546\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.8794326241134752\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.8841607565011821\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.806146572104019\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.8014184397163121\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.8321513002364066\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.7872340425531915\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.817966903073286\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.4515366430260047\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.3735224586288416\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.39952718676122934\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5059101654846335\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.42789598108747046\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.4491725768321513\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.5011820330969267\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6335697399527187\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.624113475177305\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6784869976359338\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6430260047281324\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.6595744680851063\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.48699763593380613\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.28368794326241137\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5035460992907801\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.4373522458628842\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.5437352245862884\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.5319148936170213\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6548463356973995\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6926713947990544\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.7044917257683215\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.7115839243498818\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.7399527186761229\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.7328605200945626\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.6997635933806147\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.7328605200945626\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.34278959810874704\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.36879432624113473\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.3617021276595745\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.41843971631205673\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.6382978723404256\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.6903073286052009\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7092198581560284\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.6572104018912529\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.4562647754137116\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.47754137115839246\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.46808510638297873\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.20094562647754138\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.2978723404255319\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.42080378250591016\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.09692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.6193853427895981\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.6028368794326241\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.5862884160756501\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.5839243498817966\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.3120567375886525\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.19621749408983452\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.31678486997635935\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.29550827423167847\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.24113475177304963\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.32860520094562645\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.31678486997635935\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.30969267139479906\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9219858156028369\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.4160756501182033\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.41371158392434987\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.48226950354609927\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.24349881796690306\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.25059101654846333\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.7328605200945626\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.6146572104018913\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.5531914893617021\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.6028368794326241\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.5981087470449172\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.6382978723404256\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.2364066193853428\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.8699763593380615\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.8841607565011821\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.9716312056737588\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.3144208037825059\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.3664302600472813\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.2907801418439716\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.375886524822695\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.12529550827423167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.16312056737588654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.07801418439716312\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.29550827423167847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.2293144208037825\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.1347517730496454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.4326241134751773\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.16312056737588654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.2458628841607565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.14184397163120568\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.21749408983451538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.2765957446808511\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.39952718676122934\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.2789598108747045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.3073286052009456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.3262411347517731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.6548463356973995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.6761229314420804\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.6997635933806147\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.6619385342789598\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.6572104018912529\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.2765957446808511\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.3617021276595745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.3262411347517731\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.3735224586288416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.1182033096926714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.24349881796690306\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.17494089834515367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.28368794326241137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.1867612293144208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.24349881796690306\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.475177304964539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.2576832151300236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.375886524822695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.30969267139479906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.33569739952718675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.83451536643026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8368794326241135\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8463356973995272\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.8534278959810875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.5697399527186762\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.6004728132387707\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.4515366430260047\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.5957446808510638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.5059101654846335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.5981087470449172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.13711583924349882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13947990543735225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.14420803782505912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.16312056737588654\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.3333333333333333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.2364066193853428\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.38534278959810875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.28132387706855794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.48226950354609927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.3049645390070922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.35933806146572106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.8841607565011821\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.8794326241134752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.8817966903073287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8747044917257684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.8936170212765957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.8486997635933806\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.8912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.8770685579196218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.8794326241134752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.8605200945626478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.1867612293144208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.09929078014184398\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.17494089834515367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.1773049645390071\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.13238770685579196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.18912529550827423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.44680851063829785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.44208037825059104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.4160756501182033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.30260047281323876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.3900709219858156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.40425531914893614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.8628841607565012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.8605200945626478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.8581560283687943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.8794326241134752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.8723404255319149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.8250591016548463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.8888888888888888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9078014184397163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.8959810874704491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.91725768321513\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.8817966903073287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9101654846335697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.5035460992907801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.5106382978723404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.5721040189125296\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.5390070921985816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.46808510638297873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.18439716312056736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.2624113475177305\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.08037825059101655\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.08983451536643026\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.11583924349881797\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.0851063829787234\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.16784869976359337\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.5153664302600472\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.4397163120567376\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.42789598108747046\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.10401891252955082\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1938534278959811\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.07565011820330969\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.09692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.13002364066193853\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.2647754137115839\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.17494089834515367\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.1773049645390071\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.3380614657210402\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.5130023640661938\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.3049645390070922\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.4066193853427896\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.7139479905437353\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.7044917257683215\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.706855791962175\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.7092198581560284\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.7706855791962175\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.7304964539007093\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.458628841607565\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.35933806146572106\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.4515366430260047\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.11347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.19148936170212766\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.14420803782505912\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1607565011820331\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.5650118203309693\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.3546099290780142\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.3404255319148936\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.6643026004728132\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.5460992907801419\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.3475177304964539\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.8983451536643026\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.9078014184397163\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.5673758865248227\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5862884160756501\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.5200945626477541\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.5555555555555556\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.22695035460992907\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.18912529550827423\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.2033096926713948\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.2127659574468085\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.14657210401891252\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.28132387706855794\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.3333333333333333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.7612293144208038\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.6761229314420804\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.19858156028368795\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9385342789598109\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.6264775413711584\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.6619385342789598\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.6855791962174941\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.6808510638297872\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.6832151300236406\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.14184397163120568\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.35224586288416077\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.23404255319148937\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.20567375886524822\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.29314420803782504\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.15130023640661938\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.3333333333333333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.7919621749408984\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.9078014184397163\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.3617021276595745\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9314420803782506\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.8534278959810875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.8747044917257684\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.8605200945626478\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.8486997635933806\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.8581560283687943\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.48936170212765956\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.425531914893617\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.4562647754137116\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.12056737588652482\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.900709219858156\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.5011820330969267\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.7966903073286052\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.35224586288416077\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9243498817966903\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9432624113475178\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.9125295508274232\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5602836879432624\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.5886524822695035\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.607565011820331\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.5768321513002365\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:0.15602836879432624\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:0.12293144208037825\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:0.13238770685579196\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:0.2553191489361702\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:0.13711583924349882\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:0.10874704491725769\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:0.10401891252955082\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:0.2576832151300236\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:0.2364066193853428\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:0.30260047281323876\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.40425531914893614\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:0.34988179669030733\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:0.5035460992907801\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:0.45390070921985815\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:0.475177304964539\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:0.14893617021276595\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:0.20803782505910165\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:0.1702127659574468\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:0.1182033096926714\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:0.2458628841607565\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:0.18203309692671396\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:0.1347517730496454\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:0.07328605200945626\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:0.18439716312056736\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:0.16312056737588654\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:0.1111111111111111\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:0.4846335697399527\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:0.4066193853427896\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:0.4160756501182033\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:0.41371158392434987\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:0.41134751773049644\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:0.3617021276595745\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:0.46099290780141844\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:0.3829787234042553\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:0.3073286052009456\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.38534278959810875\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:0.5839243498817966\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.5271867612293144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:0.541371158392435\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.35224586288416077\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:0.5224586288416075\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:0.7186761229314421\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:0.7399527186761229\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:0.7470449172576832\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:0.7588652482269503\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:0.7423167848699763\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:0.7423167848699763\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:0.524822695035461\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:0.48699763593380613\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:0.4846335697399527\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:0.4373522458628842\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:0.4657210401891253\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:0.24822695035460993\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:0.09692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:0.1536643026004728\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:0.22458628841607564\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:0.1867612293144208\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:0.4491725768321513\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:0.4515366430260047\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:0.6359338061465721\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:0.6359338061465721\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:0.5390070921985816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:0.5271867612293144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:0.7635933806146572\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:0.8037825059101655\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:0.7541371158392435\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:0.7659574468085106\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:0.789598108747045\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:0.933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:0.9361702127659575\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:0.9196217494089834\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:0.5460992907801419\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:0.5508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:0.5555555555555556\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:0.541371158392435\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:0.5106382978723404\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:0.508274231678487\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:0.2978723404255319\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:0.3215130023640662\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:0.2860520094562648\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:0.2765957446808511\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:0.2718676122931442\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:0.21749408983451538\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:0.47754137115839246\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:0.5130023640661938\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:0.491725768321513\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:0.5366430260047281\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:0.6477541371158393\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:0.6997635933806147\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.6430260047281324\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.6690307328605201\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:0.6926713947990544\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:0.6808510638297872\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:0.9148936170212766\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:0.8676122931442081\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:0.8817966903073287\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:0.8841607565011821\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:0.9078014184397163\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:0.8959810874704491\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:0.966903073286052\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:0.9763593380614657\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:0.9621749408983451\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:0.6737588652482269\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:0.6737588652482269\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:0.6879432624113475\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:0.7021276595744681\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:0.6997635933806147\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:0.37825059101654845\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:0.47044917257683216\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:0.4562647754137116\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:0.37115839243498816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:0.40189125295508277\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:0.5886524822695035\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:0.5933806146572104\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:0.4988179669030733\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:0.5390070921985816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:0.5484633569739953\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.6950354609929078\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:0.6879432624113475\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:0.6973995271867612\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:0.607565011820331\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.7399527186761229\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:0.9408983451536643\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:0.8936170212765957\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:0.8676122931442081\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:0.9101654846335697\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:0.9479905437352246\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:0.8557919621749409\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:0.8416075650118203\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:0.8723404255319149\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:0.8652482269503546\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:0.8747044917257684\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:0.8628841607565012\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:0.4799054373522459\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:0.44680851063829785\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:0.4444444444444444\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:0.4940898345153664\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:0.4728132387706856\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:0.5531914893617021\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:0.6170212765957447\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:0.5295508274231678\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:0.6217494089834515\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:0.5910165484633569\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:0.5721040189125296\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.7635933806146572\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:0.7825059101654847\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:0.7139479905437353\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:0.7872340425531915\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:0.7683215130023641\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.7730496453900709\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:0.900709219858156\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:0.9030732860520094\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:0.9290780141843972\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:0.9101654846335697\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:0.9267139479905437\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:0.9550827423167849\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:0.9645390070921985\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:0.9456264775413712\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:0.9598108747044918\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:0.9527186761229315\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:0.9692671394799054\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:0.9574468085106383\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:0.5791962174940898\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:0.5697399527186762\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:0.5981087470449172\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:0.5981087470449172\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:0.6453900709219859\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:0.6122931442080378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi hasil ke DataFrame dan menyimpannya ke CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"mlp_classification_hidden layer 123.csv\", index=False)\n",
        "print(\"All results have been saved to 'mlp_classification_hidden layer 123.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssurJ2AKV77a",
        "outputId": "48c96608-0c68-4ffa-9f69-9f380072cc53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results have been saved to 'mlp_classification_hidden layer 123.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Mengambil DataFrame hasil eksperimen\n",
        "# Pastikan 'results_df' sudah ada setelah eksekusi kode sebelumnya\n",
        "results_df = pd.read_csv(\"mlp_classification_hidden layer 123.csv\")\n",
        "\n",
        "# Calculate mean accuracy for each hyperparameter combination\n",
        "# Changed 'mae' to 'accuracy' to calculate and plot accuracy\n",
        "mean_accuracy_by_hyperparameter = results_df.groupby(['layers', 'neurons', 'activation', 'epochs', 'lr', 'batch_size'])['accuracy'].mean().reset_index()\n",
        "\n",
        "# Plot mean accuracy vs. each hyperparameter\n",
        "hyperparameters = ['layers', 'neurons', 'activation', 'epochs', 'lr', 'batch_size']\n",
        "\n",
        "# Create bar plots for each hyperparameter\n",
        "for param in hyperparameters:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    # Changed 'mae' to 'accuracy' in sns.barplot and ylabel\n",
        "    sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
        "    plt.title(f'Mean Accuracy vs. {param.capitalize()}', fontsize=14) # Changed title to reflect Accuracy\n",
        "    plt.xlabel(param.capitalize(), fontsize=12)\n",
        "    plt.ylabel('Mean Accuracy', fontsize=12) # Changed ylabel to reflect Accuracy\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bq1AdHMibnBz",
        "outputId": "44826178-f30f-4a96-ff47-394494919386"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAI3CAYAAACRaGpaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaaUlEQVR4nO3deVyU5f7/8fcMqxiIG6hoQmq55RKGkuZ2SLJzTNvUzI3MPJllopaeb25tHk2NMssyl0xNj7ZqHteyc0zTo6al5b6VCu6CoDAw9+8Pf0wRqNwjzAzD6/l48MC55pq5Pvd4AfOe+76v22IYhiEAAAAAQKFZ3V0AAAAAAJQ0BCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAABQIs2ZM0cWi0Vz5sxxdykASiGCFAD8weHDh2WxWGSxWFSlShVlZ2cX2O+XX35x9IuMjHRtkcXkpZdeksVikZ+fn5KTk91dDlykb9++jrl8tS+CCgDk5+vuAgDAE/n6+iolJUXLly/X/fffn+/+mTNnymr1ns+iDMPQ7NmzZbFYlJ2drQ8//FAvvPCCu8uCC/Xr10/Vq1cv8L4mTZq4thgAKAEIUgBQgLvuuks7duzQrFmz8gWp7OxszZs3T3Fxcfr222/dVGHRWrt2rQ4fPqwnn3xSCxcu1KxZswhSpcwTTzyhFi1auLsMACgxvOfjVAAoQmXKlFH37t311Vdf6eTJk3nuW7ZsmVJSUvT4449f9fGGYWjWrFlq2bKlQkJCFBQUpGbNmmnWrFn5+h4/flxjxoxRixYtFBYWpoCAAEVGRmrgwIH5xpZ+PxTr0KFDeuutt1S3bl0FBASoZs2aGjdunOx2u+ntnTlzpiTpySef1COPPKK9e/fqv//971X779ixQ4899piqV6+ugIAAVa1aVffee6+WLl2ar+8XX3yhDh06qGLFigoMDFRkZKR69eqlnTt3Ovq0bdtWFoulwLFyt/fw4cOOtj+eG7N06VK1bNlSwcHBjsMss7KyNHXqVMXHx6tGjRoKCAhQWFiYHnzwQf3www9X3a7r1dqzZ09ZLBZt3ry5wMePHj1aFotFH3/88VXHkKTatWsrODhYGRkZBd5///33y2KxaO/evZIku92uDz74QDExMapQoYLKlCmj6tWrq1OnTlq3bt01xypqY8eOlcVi0bp16zRz5kzdfvvtCgwMVEREhIYMGaK0tLQCH7d06VK1a9dO5cqVU5kyZdS4cWNNmTLlqofPmpljkrRq1SrdddddCgoKUsWKFdWnTx+dOXMmX79vvvlGHTt2VLVq1RQQEKDw8HDdfffdev/9951/UQCUSgQpALiKxx9/XNnZ2froo4/ytM+aNUsVKlRQly5dCnycYRh67LHH1K9fP506dUo9evTQE088ofT0dPXr10/Dhg3L0/8///mPJk+erPDwcD366KN65plnVKtWLb377ruKjY3VhQsXChxn+PDhevnllxUbG6u///3vkq68yR01apSp7Tx79qw+++wz1a9fX9HR0erdu7ek38PVn33yySeKiYnR4sWL1bx5cw0dOlR//etfdezYsXyPGTp0qLp06aKtW7eqS5cuGjJkiFq1aqU1a9ZozZo1puosyOLFi/Xggw8qLCxMAwcOVMeOHR3b9NxzzykzM1P33XefhgwZorZt22r58uW666679L///S/fcxWm1gEDBkiSPvjgg3yPz8nJ0ezZs1WxYkU9+OCD16y7Z8+eunjxoj7//PN8950+fVorVqxQ8+bNdeutt0qSRo4cqf79++vs2bPq0aOHnnvuObVv3167du0qktfRGVOmTNGzzz6rO++8U88995yqVq2qpKQkdejQQTabLV/f+++/Xz/++KN69Oihp59+WpcuXdLQoUP1yCOPyDCMPP3NzDFJ+vLLL9WpUydVq1ZNAwcOVK1atTR37lx17tw5T7+vvvpKf/nLX7Rp0ybFx8dr6NChuv/++5WZmZnv5xwArssAADgcOnTIkGTEx8cbhmEYDRs2NBo0aOC4/8SJE4avr6/xzDPPGIZhGAEBAUbNmjXzPMf7779vSDISEhKMrKwsR3tmZqbRqVMnQ5KxZcsWR3tKSoqRlpaWr5YPP/zQkGS88soredr79OljSDKioqKM48ePO9pPnTplhIaGGsHBwUZmZmaht/mtt94yJBnjx483DMMw7Ha7ERkZaQQFBRkXLlzI0zc5OdkoW7asUbZsWWPbtm35nuvXX391/Hvp0qWGJOP22283Tp8+naefzWYzkpOTHbfbtGljXO1PUu72Hjp0yNE2e/ZsQ5JhtVqN1atX53vM5cuXjd9++y1f+86dO42bbrrJiIuLy9Nuptb69esbwcHBxsWLF/P0W7ZsmSHJeO655wrcjj/at2+fIcno2LFjvvumTp1qSDLefvttR1uFChWMatWqGenp6fn6nzlz5rrjXUvu69uvXz9jzJgxBX5dunTJ0X/MmDGGJMPf39/YsWOHo91utxs9evQwJBmTJk1ytO/fv9/w9fU1wsLCjKNHjzraL1++bLRq1cqQZMydO9fRbmaO5c4DX19fY/369Y727Oxso23btoYkY+PGjY72Bx980JBkbN++Pd/z/vn/HQCuhyAFAH/w5yA1ZcoUQ5Lx/fffG4ZhGP/85z8NScYPP/xgGEbBQapRo0ZG2bJljYyMjHzP/+OPPxqSjKFDh163FrvdboSEhBht27bN0577xnfWrFn5HpN7348//liYzTUMwzAaN25sWK3WPG9QX3zxRUOS8d577+XpO2HCBEOSMXr06Os+b8eOHQ1Jxtdff33dvs4GqQceeOC6z/1nnTp1Mvz9/fOEXDO1vvnmm4Yk44MPPsjT3qVLF0OSsWvXrkLVERsba/j6+hopKSl52mNiYgw/Pz/j1KlTjrYKFSoYkZGRxuXLlwv13Gbkvr7X+jp37pyjf26QeuKJJ/I91+HDhw0fHx+jYcOGjraXXnrJkGRMmDAhX//vvvvOkGS0b9/e0WZmjuXOg969e1/1vrfeesvRlhuk9uzZc93nBoDr4dA+ALiGnj17ys/Pz3Fu0+zZs9W0adOrrmKWkZGhn376SaGhoZowYYLGjh2b52vhwoWSpN27d+d53Keffqr4+HhVrlxZvr6+slgsslqtSk1N1fHjxwscKzo6Ol9b7qpr58+fL9T2bdmyRTt27FC7du3yrNh2tcP7cs8N6tChw3Wfe/PmzQoICFCbNm0KVYszYmJirnrf9u3b1aNHD918883y9/d3LOW9dOlSZWVl6fTp007V2rt3b5UpU0YzZsxwtKWkpGjZsmW66667VL9+/ULV3qtXL2VnZ+c5n2rfvn3avHmz7r33XlWqVMnR3r17dx0+fFgNGzbUqFGj9PXXX+vSpUuFGqewNm7cKOPKB6z5vkJDQ/P1v/vuu/O11axZUzVq1NCuXbuUlZUlSY5z0tq2bZuvf2xsrAIDA7V9+3ZHm5k5lquwPwvdu3eXJLVo0UKDBg3SZ599lmceAIAZrNoHANdQuXJlderUSQsXLtQjjzyiPXv2aOrUqVftf+7cORmGoWPHjmncuHFX7Zeenu749+TJkzVs2DBVrlxZHTp0UPXq1VWmTBlJUlJSkjIzMwt8jpCQkHxtvr5Xfq3n5OQUavtyg1JucMpVp04dtWjRQt9//7127dqlBg0aSJLjfK2IiIjrPveFCxcUERFRrMvEh4eHF9i+YcMGtW/fXtKVN+R16tTRTTfdJIvFos8//1w7duzI87qaqTU0NFRdu3bVhx9+qJ07d6phw4aaM2eOsrOz1b9//0LX3q1bNz333HOaN2+eBg8eLEmO83R69eqVp++bb76pqKgozZ49W6+88opeeeUVBQYGqmvXrpo8eXKe0OUqV3vtw8PDdfjwYaWlpalixYpKTU29an+LxaLw8HAdO3bM0WZmjuUq7M/CI488os8//1xTpkzR9OnTNW3aNFksFrVr106TJ09mmXcAprBHCgCuo1+/fkpNTVXfvn0VGBioxx577Kp9c9/QRUdHX/XTfcMw9M0330i6spT6yy+/rKpVq2rnzp2aP3++Y0/WmDFjHJ/qF4dLly459ob06dMn30VYv//+e0l590rl7pn44xvfqwkNDVVycnKhVhHMDTAFreB2tcU2JF11pb9XX31VmZmZWrNmjb788ktNnjxZ48aN09ixY1WlSpUbqlWSY3GP3L1SM2fOVEhIiLp27Vqox0tShQoVdN9992nLli3as2ePJGnevHkqV66cOnXqlKevr6+vhg0bpl27dunYsWNasGCB7r77bs2dO/ea87E4paSkXLXdYrEoODhY0u8/EwX1NwxDKSkpeYKQmTnmjM6dO+vbb7/VuXPn9O9//1tPPPGE1q1bp3vvvbfQe3IBQCJIAcB1xcfHKyIiQseOHVOXLl1Uvnz5q/YNDg5WvXr19MsvvxTqTdnp06d14cIFxcbGKiwsLM99W7ZsKfLDt/5oyZIlunDhgpo0aaJ+/foV+BUYGKiPPvrIEehyD6VbtWrVdZ8/JiZGmZmZhbrWVu5r+uc3z3a7XTt27DC7aTpw4IAqVKigVq1a5WnPyMjQtm3bbqhW6cqhYY0aNdK8efO0atUq7du3T4899piCgoJM1Zm752nevHn67rvvdOjQIT388MMKDAy86mOqVaumRx99VCtWrFDt2rW1Zs2aYp0nV1PQ8vhHjhzRr7/+qgYNGsjf31+S1LRpU0kqcJn2TZs26fLly3n2BJmZYzciODhY9957r95//3317dtXKSkp2rRpU7GOCcC7EKQA4Dp8fHz0+eef67PPPtP48eOv2//ZZ59VRkaG+vfvn+cQvlyHDh1yXBMpLCxMZcqU0bZt2/JcU+jcuXN65plnimwbCpK7p2nKlCn64IMPCvx64IEHdPr0aX355ZeSruy5uummmzR58uQ857Xk+mMQevrppyVJgwcP1tmzZ/P0y87OzrOH4s4775R05fpQfzRlyhQdOnTI9LbVrFlT586d065duxxtOTk5GjZsmE6dOpWvv5lacw0YMEBnz55VQkKCJJk6rC/XX//6V5UvX17z58/X3LlzJeU/rC8zM1MbNmzI99j09HRdvHhRfn5+eQ5JPHDggHbv3p1vCfKiNnfuXP3444+O24Zh6B//+IdycnLUt29fR3uPHj3k6+urKVOm5DnfLysry3HR5z/2NzPHzPrPf/5T4GGvuddru1aABYA/4xwpACiEZs2aqVmzZoXqO2DAAH3//ff68MMP9d133ykuLk7VqlVTSkqKdu/erU2bNmnBggWKjIyU1WrVwIEDNXnyZDVu3FidOnVSamqq/v3vf6tmzZqqVq1asWzP/v379Z///EeRkZEFLgKQKyEhQR9//LFmzpyphx9+WGFhYZo7d666d++umJgY3X///brtttt0+vRpbdq0SZGRkY5rI913330aNmyYJk2apDp16uiBBx5QWFiYjh07prVr12rYsGF67rnnHONMnDhRY8eO1fbt21WrVi1t2bJFO3fuVJs2bQq9pyjXM888o1WrVqlVq1bq2rWrAgMDtW7dOh07dkxt27bNt3fETK25evbsqeeff17Hjx9XdHS0Y8+LGQEBAeratavee+89zZ49WzVr1lTr1q3z9Ll06ZJatmypW2+9VdHR0br55pt18eJFLVu2TMnJyRo2bJgCAgIc/f/yl7/oyJEjOnTokOMCxYXxwQcfaMWKFQXe16JFC91777152uLj4xUbG6vu3burcuXKWrt2rbZs2aIWLVrk+RCgVq1amjBhgoYOHapGjRqpa9euKlu2rJYuXao9e/aoc+fO6tmzp6O/mTlm1rPPPqvjx4+rVatWioyMlMVi0fr167V582a1aNEi3x5MALgm1y8UCACe68/Ln19PQcuf51q0aJERFxdnlC9f3vDz8zMiIiKMtm3bGpMnT86ztHVWVpbx6quvGnXq1DECAgKMm2++2Rg6dKiRlpZm1KxZM9/zF7QceK7cpam/+eaba9Y9cuRIQ5IxZsyYa/bLyckxatSoYVit1jzXAPrhhx+Mrl27GuHh4Yafn59RtWpVo2PHjsayZcvyPccnn3xitGvXzihXrpwREBBgREZGGr169TJ27tyZp9/27duNv/zlL0ZQUJAREhJidO7c2di3b981lz+fPXv2VWtfsmSJcccddxhBQUFGpUqVjK5duxoHDhy45utX2Fpz9ezZ05BkTJ8+/Zqv47WsX7/escz4yJEj892flZVlTJgwwejQoYNRvXp1w9/f3wgPDzdat25tLFiwwLDb7Xn616xZ86rbV5DCLH8+ePBgR/8/zrEZM2YYDRo0MAICAoyqVasagwcPNlJTUwsc54svvjDatGljBAcHGwEBAcbtt99uTJ482bDZbAX2L8wcu9Y8+Oabb/LN8YULFxpdu3Y1atWqZQQFBRnlypUzGjdubEyYMKHAa7kBwLVYDONPlxMHAACFcvvtt+vQoUM6fvx4gSvHeaOxY8dq3Lhx+uabb665NxMAvB3nSAEA4IR///vf2rlzpx577LFSE6IAAL/jHCkAAEx499139euvv+qDDz5QYGCgRowY4e6SAABuQJACAMCECRMm6LffftNtt92mWbNmKSoqyt0lAQDcgHOkAAAAAMAkzpECAAAAAJMIUgAAAABgUqk/R8put+v48eMKDg6WxWJxdzkAAAAA3MQwDKWlpalatWqyWq+9z6nUB6njx4+rRo0a7i4DAAAAgIf49ddfVb169Wv2KfVBKjg4WNKVF6u0XgfEZrNp1apV6tChg/z8/NxdDtyAOQDmAJgDkJgHYA6kpqaqRo0ajoxwLaU+SOUezhcSElKqg1RQUJBCQkJK5Q8MmANgDoA5gCuYB2AOXFGYU35YbAIAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwydfdBQAAAAAl2S9r5rm7hCKTY0hSsPasWyQfi7uruXH14noW23OzRwoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkjwtS06ZNU2RkpAIDA9W8eXNt3rz5mv3Pnz+vp59+WlWrVlVAQIBuvfVWLV++3EXVAgAAACiNfN1dwB8tWrRIiYmJmj59upo3b66kpCTFx8drz549CgsLy9c/KytL99xzj8LCwrRkyRJFREToyJEjCg0NdX3xAAAAAEoNjwpSU6ZMUf/+/ZWQkCBJmj59ur766ivNmjVLI0aMyNd/1qxZOnv2rDZs2CA/Pz9JUmRkpCtLBgAAAFAKecyhfVlZWdq6davi4uIcbVarVXFxcdq4cWOBj/nyyy8VGxurp59+WuHh4WrYsKFee+015eTkuKpsAAAAAKWQx+yROn36tHJychQeHp6nPTw8XLt37y7wMQcPHtTXX3+txx57TMuXL9f+/fs1cOBA2Ww2jRkzpsDHZGZmKjMz03E7NTVVkmSz2WSz2Ypoa0qW3O0urdsP5gCYA2AO3IhfNmZev1MJYTeyJUm7NqTLavGYt4lOqxcb4JJxcgyXDOMSdiPv95LO7O80M/1L9E+I3W5XWFiY3n//ffn4+Cg6OlrHjh3T66+/ftUgNX78eI0bNy5f+6pVqxQUFFTcJXu01atXu7sEuBlzAMwBMAcgSUfOf+vuEorEIZetPxbsqoFc5tAl79imAyYXocvIyCh0X48JUpUqVZKPj49SUlLytKekpKhKlSoFPqZq1ary8/OTj4+Po61evXpKTk5WVlaW/P398z1m5MiRSkxMdNxOTU1VjRo11KFDB4WEhBTR1pQsNptNq1ev1j333OM41wylC3MAzAEwB5znbXukjpz/VjVD27BHyoQ96xa5ZBxXsBtXQlRUmTRZLe6u5sbd1rabqf65R6sVhsf8hPj7+ys6Olpr165Vly5dJF3Z47R27VoNGjSowMe0bNlSCxYskN1ul9V65XSvvXv3qmrVqgWGKEkKCAhQQED+Hyo/P79S/4eD1wDMATAHwBwwz2r1onOz7Ve+WS2+slo95m2i01w1l328IHD8mdXiHdtldg6Y6e8xi01IUmJiombMmKEPP/xQv/zyi5566imlp6c7VvHr3bu3Ro4c6ej/1FNP6ezZsxo8eLD27t2rr776Sq+99pqefvppd20CAAAAgFLAoz5q6Natm06dOqXRo0crOTlZTZo00YoVKxwLUBw9etSx50mSatSooZUrV2rIkCFq1KiRIiIiNHjwYL3wwgvu2gQAAAAApYBHBSlJGjRo0FUP5Vu3bl2+ttjYWH3//ffFXBUAAAAA/M6jDu0DAAAAgJKAIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACb5ursAAABKsotLFrm7hCKRLUl+gUr/4lOveXNw08Pd3F0CAC/GHikAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkzwySE2bNk2RkZEKDAxU8+bNtXnz5qv2nTNnjiwWS56vwMBAF1YLAAAAoLTxuCC1aNEiJSYmasyYMdq2bZsaN26s+Ph4nTx58qqPCQkJ0YkTJxxfR44ccWHFAAAAAEobjwtSU6ZMUf/+/ZWQkKD69etr+vTpCgoK0qxZs676GIvFoipVqji+wsPDXVgxAAAAgNLG190F/FFWVpa2bt2qkSNHOtqsVqvi4uK0cePGqz7u4sWLqlmzpux2u+644w699tpratCgQYF9MzMzlZmZ6bidmpoqSbLZbLLZbEW0JSVL7naX1u0HcwDMgRuR7e4Cikj2n757A1fNZ7vde141u5H9+3e7m4spAq6aAzmGS4ZxCbuR93tJZ3YOmOlvMQzDY16m48ePKyIiQhs2bFBsbKyj/fnnn9e3336rTZs25XvMxo0btW/fPjVq1EgXLlzQpEmT9J///Ee7du1S9erV8/UfO3asxo0bl699wYIFCgoKKtoNAgAAAFBiZGRkqEePHrpw4YJCQkKu2dej9kg5IzY2Nk/ouuuuu1SvXj299957evnll/P1HzlypBITEx23U1NTVaNGDXXo0OG6L5a3stlsWr16te655x75+fm5uxy4AXMAzAHnpX/xqbtLKBLZkr7zC1RL2+WS/+bg/yvb+UGXjPPLxszrdyoh7Ea2jpz/VjVD28hqKfkzoV5sgEvG2bNukUvGcQW7IR26FKyoMmmyWtxdzY27rW03U/1zj1YrDI/6CalUqZJ8fHyUkpKSpz0lJUVVqlQp1HP4+fmpadOm2r9/f4H3BwQEKCAg/w+Vn59fqX/zwGsA5gCYA+Z51B/SIuAr79kmV81lqzXHJeO4xP8/nM9q8ZXVWvJngqvmgI8XBI4/s1q8Y7vMzgEz/T1qsQl/f39FR0dr7dq1jja73a61a9fm2et0LTk5Ofrpp59UtWrV4ioTAAAAQCnncR81JCYmqk+fPmrWrJliYmKUlJSk9PR0JSQkSJJ69+6tiIgIjR8/XpL00ksvqUWLFqpdu7bOnz+v119/XUeOHNETTzzhzs0AAAAA4MU8Lkh169ZNp06d0ujRo5WcnKwmTZpoxYoVjiXNjx49Kqv19x1p586dU//+/ZWcnKzy5csrOjpaGzZsUP369d21CQAAAAC8nMcFKUkaNGiQBg0aVOB969aty3P7jTfe0BtvvOGCqgAAAADgCo86RwoAAAAASgKCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATPJ1dwEAUJK9t2+hu0soEpYcKVxlNPvAJzJ83F1N0RhQp7u7SwAAeDH2SAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwyakg1bFjRy1YsECXLl0q6noAAAAAwOM5FaQOHjyonj17Kjw8XH369NGaNWtkGEZR1wYAAAAAHsmpILVnzx5t2rRJCQkJWrVqleLj41W9enUNHz5c27dvL+ISAQAAAMCzOH2O1J133qk333xTx44d0/Lly9W+fXu99957io6OVsOGDTVx4kT99ttvRVkrAAAAAHiEG15swmq1Kj4+Xh999JGOHj2qhx9+WD///LNGjBihyMhIxcXF6auvviqKWgEAAADAIxTJqn3r16/X3//+d9WuXVuLFy927JGaPHmyTp06pfvvv1+jR48uiqEAAAAAwO18nX3gzz//rHnz5unjjz/W0aNHFRYWpj59+qhXr15q0qSJo9/gwYP15JNPatq0aXrppZeKomYAAAAAcCunglSTJk30008/KSAgQJ07d9Y777yj+Ph4Wa0F7+Bq166dPvjggxsqFAAAAAA8hVNBKjQ0VO+//74eeeQRhYSEXLd/586ddejQIWeGAgAAAACP41SQWrdunan+QUFBqlmzpjNDAQAAAIDHcWqxiW3btumdd9656v3vvPMO15MCAAAA4LWcClL/93//pzVr1lz1/q+//lovvvii00UBAAAAgCdzKkht3bpVd99991Xvv/vuu7VlyxaniwIAAAAAT+ZUkEpLS5Ov79VPr7Jarbpw4YLTRQEAAACAJ3MqSNWpU0erVq266v0rVqzQLbfc4nRRAAAAAODJnApS/fr101dffaXExESdP3/e0X7+/HkNGTJEK1asUL9+/YqqRgAAAADwKE4tf/7ss89q+/btSkpK0ltvvaVq1apJko4fPy673a5evXppyJAhRVooAAAAAHgKp4KUxWLR7Nmz1bt3b33yySc6ePCgpCsX3n3ooYfUtm3boqwRAAAAADyKU0EqV7t27dSuXbuiqgUAAAAASgSnzpECAAAAgNLM6T1SP/74o6ZOnapt27bpwoULstvtee63WCw6cODADRcIAAAAAJ7GqT1S69atU0xMjJYtW6Zq1arp4MGDuuWWW1StWjUdOXJEN910k1q3bl3UtQIAAACAR3AqSI0ePVq33HKL9uzZo9mzZ0uS/vGPf2j9+vXasGGDfvvtN3Xt2rVICwUAAAAAT+FUkNq2bZv69eunkJAQ+fj4SJJycnIkSc2bN9eAAQM0atQop4uaNm2aIiMjFRgYqObNm2vz5s2FetzChQtlsVjUpUsXp8cGAAAAgOtxKkj5+voqODhYkhQaGio/Pz+dPHnScf8tt9yin3/+2amCFi1apMTERI0ZM0bbtm1T48aNFR8fn+f5C3L48GENGzZMd999t1PjAgAAAEBhORWkateurX379km6sqhE3bp19dlnnznu/+qrr1SlShWnCpoyZYr69++vhIQE1a9fX9OnT1dQUJBmzZp11cfk5OToscce07hx43TLLbc4NS4AAAAAFJZTq/bdd999mjVrlsaPHy9fX18lJiYqISFBderUkSQdOHBA48ePN/28WVlZ2rp1q0aOHOlos1qtiouL08aNG6/6uJdeeklhYWHq16+f/vvf/15zjMzMTGVmZjpup6amSpJsNptsNpvpmr1B7naX1u0Hc+BGWHLcXUHRyN0Ob9keyXXzOdsloxS/7D999waumgN2u/e8anYj+/fv9ut0LgFcNQdyDJcM4xJ2I+/3ks7sHDDT32IYhumXyWazKTU1VRUqVJDFYpEkzZs3T5988ol8fHz0t7/9TX379jX7tDp+/LgiIiK0YcMGxcbGOtqff/55ffvtt9q0aVO+x6xfv17du3fX9u3bValSJfXt21fnz5/X559/XuAYY8eO1bhx4/K1L1iwQEFBQaZrBgAAAOAdMjIy1KNHD124cEEhISHX7Gt6j5TNZtMvv/ySJ0RJUs+ePdWzZ0/z1d6AtLQ09erVSzNmzFClSpUK9ZiRI0cqMTHRcTs1NVU1atRQhw4drvtieSubzabVq1frnnvukZ+fn7vLgRswB5w3+8An7i6hSFhypLD9ZXSy9iUZPu6upmgk1HrIJeOkf/GpS8YpbtmSvvMLVEvbZecvMulhynZ+0CXj/LIx8/qdSgi7ka0j579VzdA2slpK/kyoFxvgknH2rFvkknFcwW5Ihy4FK6pMmqyW6/f3dLe17Waqf+7RaoVh+ifEarUqOjpakydP1rPPPmv24ddUqVIl+fj4KCUlJU97SkpKgedcHThwQIcPH1anTp0cbbkXBvb19dWePXtUq1atPI8JCAhQQED+Hyo/P79S/waS1wDMAfO8JXTkMny8Z5tcNZdL/lvNvHzlPdvkqjlgtXrRMbH//3A+q8VXVmvJnwmumgM+XhA4/sxq8Y7tMjsHzPQ3vdiEj4+Patasmec8o6Li7++v6OhorV271tFmt9u1du3aPIf65apbt65++uknbd++3fF1//33q127dtq+fbtq1KhR5DUCAAAAgFMfNTzzzDN6++231a9fP1WoUKFIC0pMTFSfPn3UrFkzxcTEKCkpSenp6UpISJAk9e7dWxERERo/frwCAwPVsGHDPI8PDQ2VpHztAAAAAFBUnApSOTk5CggIUK1atfTwww8rMjJSZcqUydPHYrFoyJAhpp+7W7duOnXqlEaPHq3k5GQ1adJEK1asUHh4uCTp6NGjslqdWrUdAAAAAIqEU0Fq2LBhjn/PnDmzwD7OBilJGjRokAYNGlTgfevWrbvmY+fMmePUmAAAAABQWE4FqUOHDhV1HQAAAABQYjgVpGrWrFnUdQAAAABAicHJRgAAAABgklN7pKKiovJcjLcgFotFBw4ccKooAAAAAPBkTgWpNm3a5AtSOTk5OnLkiL777js1bNhQTZs2LZICAQAAAMDTOBWkrrUy3o4dOxQfH6/HHnvM2ZoAAAAAwKMV+TlSjRs31oABA/TCCy8U9VMDAAAAgEcolsUmwsPD9fPPPxfHUwMAAACA2xV5kDpz5oxmzpyp6tWrF/VTAwAAAIBHcOocqfbt2xfYfv78ee3evVtZWVn66KOPbqgwAAAAAPBUTgUpu92eb9U+i8WiqKgoxcXF6fHHH1fdunWLpEAAAAAA8DROBal169YVcRkAAAAAUHIUy2ITAAAAAODNnApSb731luLj4696f8eOHfXuu+86XRQAAAAAeDKngtTMmTNVv379q95fv359vf/++04XBQAAAACezKkgdeDAAdWrV++q99etW1cHDhxwuigAAAAA8GROBSl/f38lJydf9f4TJ07IauX0KwAAAADeyam006JFC82ZM0dpaWn57rtw4YJmz56tFi1a3HBxAAAAAOCJnFr+fMyYMWrTpo2aNGmi5557Tg0aNJAk7dy5U0lJSTpx4oQWLFhQpIUCAAAAgKdwKkg1b95cS5cu1YABAzR48GDHxXkNw1BUVJS+/PJLxcbGFmmhAAAAAOApnApSknTPPfdo//79+uGHHxwLS9SqVUt33HGHI1gBAAAAgDdyOkhJktVqVXR0tKKjo4uqHgAAAADweE4tNvHxxx+rb9++V70/ISFB//rXv5ytCQAAAAA8mlNB6o033lBAQMBV7y9TpozeeOMNp4sCAAAAAE/mVJDas2ePmjZtetX7GzdurN27dztdFAAAAAB4MqeClGEYOn/+/FXvP3funGw2m7M1AQAAAIBHcypINW3aVB9//LGysrLy3ZeZmakFCxZcc48VAAAAAJRkTgWpESNGaOfOnWrXrp2WLl2qgwcP6uDBg/ryyy/Vtm1b7dq1SyNGjCjqWgEAAADAIzi1/HnHjh01c+ZMDR48WF26dHG0G4ah4OBgzZgxQ3/961+LqkYAAAAA8ChOX0eqb9++evDBB7V69eo8F+Tt0KGDgoODi6xAAAAAAPA0N3RB3pCQED300EP52rdv36558+Zp0qRJN/L0gEc7v2Kqu0soMtmGRVINXVjznnwthrvLKRKh9z7j7hIAAIAXc+ocqYIcPnxYr732mho0aKA77riD60gBAAAA8Fo3tEfqzJkz+te//qX58+dr48aN8vPzU5s2bTRw4EB16tSpqGoEAAAAAI9iOkhdunRJX3zxhebPn69Vq1ZJkpo3by5Jmjdvnh5++OGirRAAAAAAPEyhD+1buXKlevfurfDwcPXs2VOXLl3StGnTlJycrFmzZskwDFmtRXakIAAAAAB4rELvkerYsaOioqL02muv6ZFHHlF4eLjjvrNnzxZLcQAAAADgiQq9C6lKlSo6dOiQPvzwQ82fP1/Hjx8vzroAAAAAwGMVOkj99ttvWrVqlRo0aKBx48bp5ptvVuvWrTV9+nSdOnWqOGsEAAAAAI9S6CBltVoVFxenOXPmKCUlRfPnz1doaKgGDx6sli1bymKx6D//+Y+OHTtWnPUCAAAAgNs5tTpEYGCgunXrpi+//FInTpzQ1KlTFRsbq7feeks333yzoqOjNW7cuKKuFQAAAAA8wg0vs1ehQgUNHDhQ69ev18GDBzVu3DhlZGTopZdeKor6AAAAAMDjFOl65ZGRkXrxxRf1yy+/aMuWLUX51AAAAADgMYrtwk9NmzYtrqcGAAAAALfiCroAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACb5OvvAlStXaubMmTp48KDOnTsnwzDy3G+xWHTgwIEbLhAAAAAAPI1TQer111/XiBEjFB4erpiYGN1+++1FXRcAAAAAeCyngtSbb76p9u3ba/ny5fLz8yvqmgAAAADAozl1jtS5c+f08MMPE6IAAAAAlEpOBamYmBjt2bOnqGsBAAAAgBLBqSD1zjvv6NNPP9WCBQuKuh4AAAAA8HhOnSPVrVs3ZWdnq1evXnrqqadUvXp1+fj45OljsVi0Y8eOIikSAAAAADyJU3ukKlSooDp16qh169a64447FBYWpooVK+b5qlChgtNFTZs2TZGRkQoMDFTz5s21efPmq/b99NNP1axZM4WGhqps2bJq0qSJPvroI6fHBgAAAIDrcWqP1Lp164q4jN8tWrRIiYmJmj59upo3b66kpCTFx8drz549CgsLy9e/QoUK+r//+z/VrVtX/v7+WrZsmRISEhQWFqb4+PhiqxMAAABA6eXUHqniNGXKFPXv318JCQmqX7++pk+frqCgIM2aNavA/m3bttUDDzygevXqqVatWho8eLAaNWqk9evXu7hyAAAAAKWFU3ukctlsNu3evVsXLlyQ3W7Pd3/r1q1NPV9WVpa2bt2qkSNHOtqsVqvi4uK0cePG6z7eMAx9/fXX2rNnjyZMmFBgn8zMTGVmZjpup6amOrbFZrOZqtdb5G53ad1+Z2UbFneXUGRyt8WbtslV89mS45Jhil3udnjL9kiumwPZLhml+GX/6bs3cNUcsNu951WzG9m/f8//1q7EcdUcyDFcMoxL2I2830s6s3PATH+LYRimXya73a6RI0fqnXfeUUZGxlX75eSY+4t8/PhxRUREaMOGDYqNjXW0P//88/r222+1adOmAh934cIFRUREKDMzUz4+PnrnnXf0+OOPF9h37NixGjduXL72BQsWKCgoyFS9AAAAALxHRkaGevTooQsXLigkJOSafZ3aI/Xaa6/p9ddf14ABA9SqVSv16tVLEyZMUGhoqN555x1ZLBZNnDjRqeKdERwcrO3bt+vixYtau3atEhMTdcstt6ht27b5+o4cOVKJiYmO26mpqapRo4Y6dOhw3RfLW9lsNq1evVr33HMPF1k24cKa99xdQpHJNizaZKuu5n6/ydfiHR9BlYsb4JJxZh/4xCXjFDdLjhS2v4xO1r4kw+f6/UuChFoPuWSc9C8+dck4xS1b0nd+gWppu3xjh6t4kLKdH3TJOL9szLx+pxLCbmTryPlvVTO0jayWkj8T6sUGuGScPesWuWQcV7Ab0qFLwYoqkyarFxyoclvbbqb65x6tVhhO/YTMmTNHXbt21bvvvqszZ85IkqKjo9W+fXv16dNHsbGx+vrrrxUXF2fqeStVqiQfHx+lpKTkaU9JSVGVKlWu+jir1aratWtLkpo0aaJffvlF48ePLzBIBQQEKCAg/w+Vn59fqQ8RvAbmeEvg+CNfi+E12+WquewtoSOX4eM92+SqOVDy32rm5Svv2SZXzQGr1YuOif3/h/NZLb6yWkv+THDVHPDxgsDxZ1aLd2yX2Tlgpr9Ti0389ttvat++vSQ5Qsnly5clSf7+/urZs6dTS5D7+/srOjpaa9eudbTZ7XatXbs2z6F+12O32/OcBwUAAAAARcmpjxoqVqyoixcvSpJuuukmhYSE6ODBg3n6nDt3zqmCEhMT1adPHzVr1kwxMTFKSkpSenq6EhISJEm9e/dWRESExo8fL0kaP368mjVrplq1aikzM1PLly/XRx99pHfffdep8QEAAADgepwKUk2bNtX//vc/x+127dopKSlJTZs2ld1u11tvvaXGjRs7VVC3bt106tQpjR49WsnJyWrSpIlWrFih8PBwSdLRo0dltf6+Iy09PV0DBw7Ub7/9pjJlyqhu3bqaN2+eunUzdzwkAAAAABSWU0HqySef1Jw5c5SZmamAgAC9+uqrat26tVq3bi3DMFS+fHl9/PHHThc1aNAgDRo0qMD7/nwx4FdeeUWvvPKK02MBAAAAgFlOBan7779f999/v+N2/fr1deDAAa1bt04+Pj666667VKFChSIrEgAAAAA8SZEtx1KuXDl17ty5qJ4OAAAAADyWU6v2SVcutrtw4UINGDBADzzwgH766SdJVy6O++mnn+ZbwhwAAAAAvIVTQer8+fNq2bKlevTooY8//lhffvmlTp06JenKKn7PPvus3nzzzSItFAAAAAA8hVNBasSIEdq1a5dWrlypgwcPyjB+v4Cnj4+PHn74YS1fvrzIigQAAAAAT+JUkPr888/1zDPP6J577pHFkv+Sx7feeqsOHz58o7UBAAAAgEdyKkhduHBBUVFRV73fZrMpOzvb6aIAAAAAwJM5FaRq1aqlbdu2XfX+VatWqX79+k4XBQAAAACezKkg9cQTT2jWrFlatGiR4/woi8WizMxM/d///Z9WrFihAQMGFGmhAAAAAOApnLqO1ODBg7Vr1y49+uijCg0NlST16NFDZ86cUXZ2tgYMGKB+/foVZZ0AAAAA4DGcClIWi0UzZsxQnz59tGTJEu3bt092u121atVS165d1bp166KuEwAAAAA8hlNBKlerVq3UqlWroqoFAAAAAEoEp86RAgAAAIDSrNB7pO6//35TT2yxWPTFF1+YLggAAAAAPF2hg9SyZcsUGBioKlWqOFbqu5aCLtQLAAAAAN6g0EEqIiJCx44dU6VKldSjRw91795dVapUKc7aAAAAAMAjFfocqV9//VXffPONmjZtqpdfflk1atRQXFycZs+erbS0tOKsEQAAAAA8iqnFJtq0aaP33ntPycnJWrJkiSpWrKhBgwYpLCxMDz74oJYsWaLMzMziqhUAAAAAPIJTq/b5+fmpc+fOWrRokVJSUhzhqlu3bpo4cWJR1wgAAAAAHuWGlj/PzMzUypUr9cUXX+iHH35QYGCgIiMji6g0AAAAAPBMpoOU3W7XypUr1bdvX4WHh+vRRx/VpUuXNGPGDJ08eVK9evUqjjoBAAAAwGMUetW+DRs2aMGCBVq8eLHOnDmjFi1a6LXXXlPXrl1VqVKl4qwRAAAAADxKoYNUq1atVKZMGd1333169NFHHYfwHT16VEePHi3wMXfccUeRFAkAAAAAnqTQQUqSLl26pE8++USffvrpNfsZhiGLxaKcnJwbKg4AAAAAPFGhg9Ts2bOLsw4AAAAAKDEKHaT69OlTnHUAAAAAQIlxQ8ufAwAAAEBpRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASR4ZpKZNm6bIyEgFBgaqefPm2rx581X7zpgxQ3fffbfKly+v8uXLKy4u7pr9AQAAAOBGeVyQWrRokRITEzVmzBht27ZNjRs3Vnx8vE6ePFlg/3Xr1unRRx/VN998o40bN6pGjRrq0KGDjh075uLKAQAAAJQWHhekpkyZov79+yshIUH169fX9OnTFRQUpFmzZhXYf/78+Ro4cKCaNGmiunXr6oMPPpDdbtfatWtdXDkAAACA0sKjglRWVpa2bt2quLg4R5vValVcXJw2btxYqOfIyMiQzWZThQoViqtMAAAAAKWcr7sL+KPTp08rJydH4eHhedrDw8O1e/fuQj3HCy+8oGrVquUJY3+UmZmpzMxMx+3U1FRJks1mk81mc7Lyki13u0vr9jsr27C4u4Qik7st3rRNrprPlhyXDFPscrfDW7ZHct0cyHbJKMUv+0/fvYGr5oDd7j2vmt3I/v273c3FFAFXzYEcwyXDuITdyPu9pDM7B8z096ggdaP++c9/auHChVq3bp0CAwML7DN+/HiNGzcuX/uqVasUFBRU3CV6tNWrV7u7hBKmhrsLKHKbbNXdXULRWb7cJcOEq4xLxnGVsP3esz3L97hmDsiv4L83JdV33rQ9Lvo94I2OnP/W3SUUiUMumwLBrhrIZQ5d8o5tOmDy90BGRkah+3pUkKpUqZJ8fHyUkpKSpz0lJUVVqlS55mMnTZqkf/7zn1qzZo0aNWp01X4jR45UYmKi43ZqaqpjgYqQkJAb24ASymazafXq1brnnnvk5+fn7nJKjAtr3nN3CUUm27Bok626mvv9Jl+Ld3wEVS5ugEvGmX3gE5eMU9wsOVdC1Mnal2T4uLuaopFQ6yGXjJP+xacuGae4ZetKiGppu+xZbw5uQNnOD7pknF82Zl6/UwlhN7J15Py3qhnaRlZLyZ8J9WIDXDLOnnWLXDKOK9iNKyEqqkyarF5woMptbbuZ6p97tFpheNRPiL+/v6Kjo7V27Vp16dJFkhwLRwwaNOiqj5s4caJeffVVrVy5Us2aNbvmGAEBAQoIyP9D5efnV+pDBK+BOd4SOP7I12J4zXa5ai57S+jIZfh4zza5ag541B/SIuAr79kmV80Bq9WLjon9/4fzWS2+slpL/kxw1Rzw8YLA8WdWi3dsl9k5YKa/x/2EJCYmqk+fPmrWrJliYmKUlJSk9PR0JSQkSJJ69+6tiIgIjR8/XpI0YcIEjR49WgsWLFBkZKSSk5MlSTfddJNuuukmt20HAAAAAO/lcUGqW7duOnXqlEaPHq3k5GQ1adJEK1ascCxAcfToUVmtvy82+O677yorK0sPP/xwnucZM2aMxo4d68rSAQAAAJQSHhekJGnQoEFXPZRv3bp1eW4fPny4+AsCAAAAgD/wqOtIAQAAAEBJQJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkj7wgb0mwZPMpd5dQdOzZ8pP0xdbTktU7psTDMZXdXQIAAAC8GHukAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADDJ44LUtGnTFBkZqcDAQDVv3lybN2++at9du3bpoYceUmRkpCwWi5KSklxXKAAAAIBSy6OC1KJFi5SYmKgxY8Zo27Ztaty4seLj43Xy5MkC+2dkZOiWW27RP//5T1WpUsXF1QIAAAAorTwqSE2ZMkX9+/dXQkKC6tevr+nTpysoKEizZs0qsP+dd96p119/Xd27d1dAQICLqwUAAABQWvm6u4BcWVlZ2rp1q0aOHOlos1qtiouL08aNG4tsnMzMTGVmZjpup6amSpJsNptsNlvhn8ieXWQ1uZ09J+93L2Dq/9JJ2Yal2Mdwldxt8aZtcsUckCSLl/zY5G6Ht2yP5Lo54C1/DbL/9N0buGoO2L3oPYHdyP79u93NxRQBV82BHMMlw7iE3cj7vaQzOwfM9PeYIHX69Gnl5OQoPDw8T3t4eLh2795dZOOMHz9e48aNy9e+atUqBQUFFfp5/IqsIs/hd2qru0soMsuXu2KUGq4YxKU22aq7u4Si45pJoHCVcck4rhK233u2Z/ke18wB+QW6ZhwX+c6btsdFvwe80ZHz37q7hCJxyGVTINhVA7nMoUvesU0HTP4eyMjIKHRfjwlSrjJy5EglJiY6bqempqpGjRrq0KGDQkJCCv08X2w9XRzluYc9R36ntspWOVqy+ri7miLRObpSsY9xYc17xT6Gq2QbFm2yVVdzv9/ka/GOj6DKxQ1wyTizD3ziknGKmyXnSog6WfuSDO/4NaCEWg+5ZJz0Lz51yTjFLVtXQlRL22WveXNQtvODLhnnl42Z1+9UQtiNbB05/61qhraR1VLyZ0K9WNec+rFn3SKXjOMKduNKiIoqkyarFxyoclvbbqb65x6tVhge8xNSqVIl+fj4KCUlJU97SkpKkS4kERAQUOD5VH5+fvLzM7GfyeoxL13Rsfp4zXaZ+r90krcEjj/ytRhes12umAOSvCZ05DJ8vGebXDUHvOO35u985T3b5Ko5YLV60TGx//9wPqvFV1YveE/gqjng4wWB48+sFu/YLrNzwEx/j1lswt/fX9HR0Vq7dq2jzW63a+3atYqNjXVjZQAAAACQl0d91JCYmKg+ffqoWbNmiomJUVJSktLT05WQkCBJ6t27tyIiIjR+/HhJVxao+Pnnnx3/PnbsmLZv366bbrpJtWvXdtt2AAAAAPBuHhWkunXrplOnTmn06NFKTk5WkyZNtGLFCscCFEePHpXV+vtOtOPHj6tp06aO25MmTdKkSZPUpk0brVu3ztXlAwAAACglPCpISdKgQYM0aNCgAu/7cziKjIyUYXjH+RwAAAAASg6POUcKAAAAAEoKghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwySOD1LRp0xQZGanAwEA1b95cmzdvvmb/xYsXq27dugoMDNTtt9+u5cuXu6hSAAAAAKWRxwWpRYsWKTExUWPGjNG2bdvUuHFjxcfH6+TJkwX237Bhgx599FH169dPP/zwg7p06aIuXbpo586dLq4cAAAAQGnhcUFqypQp6t+/vxISElS/fn1Nnz5dQUFBmjVrVoH933zzTd17770aPny46tWrp5dffll33HGH3n77bRdXDgAAAKC08HV3AX+UlZWlrVu3auTIkY42q9WquLg4bdy4scDHbNy4UYmJiXna4uPj9fnnnxfYPzMzU5mZmY7bFy5ckCSdPXtWNput0LVmpJ0rdF+PZ8+RX0aGbGnnJauPu6spEmfOFP9nBKnpl4t9DFfJNizKsGXonO2yfC2Gu8spEjlnzrhknMsXMlwyTnGz5EgZGYYuX7gkwzt+DeiMi+ZAeoZ3zIEcSRl+dp2zXZaXTAFlumgOpKZlXr9TCWE3spWRkaFUv7OyWjzqbaJTzpwJcMk4Fy5ecsk4rmA3pIzLPkq1X5LV4u5qbpzZvwVpaWmSJMO4/vshj/oJOX36tHJychQeHp6nPTw8XLt37y7wMcnJyQX2T05OLrD/+PHjNW7cuHztUVFRTlYNwDM97+4C4GbPqZ+7SwAAuN2TTj0qLS1N5cqVu2YfjwpSrjBy5Mg8e7DsdrvOnj2rihUrymLxgtjthNTUVNWoUUO//vqrQkJC3F0O3IA5AOYAmAOQmAdgDhiGobS0NFWrVu26fT0qSFWqVEk+Pj5KSUnJ056SkqIqVaoU+JgqVaqY6h8QEKCAgLy7eUNDQ50v2ouEhISUyh8Y/I45AOYAmAOQmAco3XPgenuicnnUYhP+/v6Kjo7W2rVrHW12u11r165VbGxsgY+JjY3N01+SVq9efdX+AAAAAHCjPGqPlCQlJiaqT58+atasmWJiYpSUlKT09HQlJCRIknr37q2IiAiNHz9ekjR48GC1adNGkydP1l//+lctXLhQW7Zs0fvvv+/OzQAAAADgxTwuSHXr1k2nTp3S6NGjlZycrCZNmmjFihWOBSWOHj0qq/X3HWl33XWXFixYoBdffFH/+Mc/VKdOHX3++edq2LChuzahxAkICNCYMWPyHfKI0oM5AOYAmAOQmAdgDphhMQqzth8AAAAAwMGjzpECAAAAgJKAIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgDkwRpEAABcH0EKACBJOn/+vCTJYrG4txAAHsUwDD5gAQpAkCqlcnJy3F0CPBx/NEuX7du3q1OnTvrxxx/dXQo8CL8HSrfMzExJUnZ2Nh+wlEKHDx/WjBkzNHPmTK1atcrd5Xgkj7sgL4rf3r17tXTpUvXo0UNVq1Z1dzlws71792rmzJk6efKkmjRpovvuu0916tSRxWKRYRj88SwFduzYoZiYGD333HNq1KhRnvuYA6XD/v37tWTJEl24cEGNGjVSp06ddNNNN/F7oBTbtWuXRo0apbS0NPn4+Ogf//iHWrRoIX9/f3eXBhf46aef1K5dO9WpU0enTp1SSkqKunfvrpdeeon3jn/AHqlSZv/+/YqNjdXw4cM1depUnT592t0lwY1+/vlnxcTE6Mcff1RaWprGjBmjgQMH6oMPPpAkx5soeK9du3YpNjZWI0eO1MSJE2UYhs6ePatDhw5J4jC/0mDXrl268847tWLFCm3YsEG9e/dW3759tXLlSkn8HiiN9u3bp7vuukuVK1dW06ZNFRwcrLZt2+q1117T0aNH3V0eitnFixc1YMAA9ejRQxs3btT69eu1ePFiffrpp3r88cd14MABd5foMSwGvx1LjfT0dD377LOy2+268847NWjQIA0bNkzPP/+8KlWq5O7y4GJZWVnq16+fypQpo/fff1/SlaD94osv6siRI3r00Uf17LPPurlKFKczZ86oRYsWCg4O1rZt2yRJjz/+uH788UcdP35cderU0ZtvvqnGjRsTqLzUpUuX1LVrV9WsWVNvv/22JGnbtm0aMGCAQkNDNXDgQD3wwANurhKuNmrUKG3evNkRpiVp6tSpGjdunJ544gkNGTJE4eHhbqwQxeny5ctq2bKlnn/+eXXr1s3RvnfvXrVs2VKtWrXSkiVL5OPj48YqPQN7pEoRq9Wq6Oho3XvvvRo4cKAWLlyoSZMmaeLEieyZKoX8/f2VkpLieINsGIZq166tiRMnqm7dulqyZImWLl3q5ipRnCpWrKh7771XZcuW1dixYxUTE6MTJ05owIABeuedd2Sz2dSlSxfHp4987uZ9ypQpo7Nnzzo+TLPb7brjjjv00UcfKTs7W++//7527Njh5irhapcuXXL8Ozs7W5L0zDPP6NVXX9Xbb7+tzz77TNKV+QLvkpOTo5ycHKWkpGjPnj2OdpvNpltvvVVr167V6tWrNX78eDdW6TkIUqVImTJl1KdPH8enC127dtXHH3+sSZMmacKECTpz5oykK78Ycw/rgXfKycmRzWZT9erVdfbsWccJxXa7XTfffLNGjRql7OxszZ8/382VorjkvgGaOnWqYmJiNH36dIWFhWnOnDnq37+/unTpog0bNuimm27SK6+8IonD/LxJ7v9/WlqaAgICdPLkSUlXwnJ2drbq1q2radOmaefOnZo9e7Y7S4Ub3Hzzzdq4caOOHz8uX19fZWVlSZIGDBig559/XsOHD9evv/4qq5W3kd4id9VWHx8flS1bVkOHDtWMGTO0bNkySZKfn59sNpsaNWqkkSNHatmyZTp79myp/4CNn4BSpmzZspKuvJE2DEPdunXTggULNHnyZE2YMEHHjx/XsGHDNGzYMGVkZLi5WhS13NUafXx85Ofnpz59+uizzz7Te++9J4vFIqvVqpycHN1yyy0aP368Fi9erF27drm5ahSl9PR0paWl6eLFi462yZMna/jw4Xr88ccVFhYm6fe5UrduXaWnp7ulVhSP7du3q3PnzkpPT1dwcLAGDhyo6dOn69NPP5WPj4+sVqtsNpvq16+viRMnau7cuZwXU8r8/e9/V9OmTfXQQw/pzJkz8vf31+XLlyVJTz75pMqXL68tW7a4uUoUlYJWbb3vvvvUsmVLTZw40bFin5+fnySpUqVKSk1NVWBgYKn/gI0gVUrlHtdqt9vVvXt3ffzxx0pKSlL79u01depUjRo1SkFBQW6uEkVp7969SkpK0okTJxxtbdq00YQJEzRkyBDHAhO5cyM4OFi33XabI3yj5Pv555/14IMPqk2bNqpXr57mz5/vCExDhw7V3/72N8cfRR8fH8dqbfXr15fEoX3eYMeOHbrrrrvUoEEDx892ly5d9PTTT6tHjx5aunSprFar4w1TaGioqlSpwu8BL7Z371698MILSkhI0Jtvvql9+/bJ399fY8aMkd1uV7du3XT27FkFBgZKkgICAlS2bFnHHEHJlrtqa2xsbJ5VW2+77Tb169dP5cuX14svvqiFCxdKunKI38GDBxUWFsaldCTJQKlmt9sNu91uGIZhtG/f3qhQoYLx448/urkqFLV9+/YZFSpUMCwWizFy5Ejj1KlTjvvS09ONcePGGRaLxXjxxReNbdu2GWfOnDFGjBhh1K5d2zh58qQbK0dR2bVrl1GxYkVjyJAhxvz5843ExETDz8/P+OGHHwrsb7PZjBdffNGoWrWqsW/fPtcWi2KxY8cOo2zZssbw4cPztGdnZxunT582nn76acPPz8949913jRMnThiXLl0yRowYYTRu3Ng4e/asm6pGcdq1a5dRrlw549577zUeeugho1y5ckb79u2NuXPnGoZhGEuXLjViYmKMqKgoY+XKlcbXX39tvPjii0aVKlWMI0eOuLl63KidO3caZcqUMUaPHm0YxpX3hGfOnDH279/v6LNx40bj73//u+Hr62s0btzYaNGihVG+fPmr/u0obVi1D8rJydHw4cOVlJSk7du357uODEq2q63WOHz4cFWuXFnSlT2T8+bN0wsvvCAfHx8FBwcrNTVVS5cu1R133OHmLcCNOnv2rB599FHVrVtXb775pqO9Xbt2uv322/XWW2/luVbQ6tWrNXXqVP3vf//T8uXL1bRpU3eVjiKSnJyspk2bqnHjxlqxYoVycnI0bNgw7dmzR0eOHNFTTz2lhg0b6qefftKwYcMUERGh4OBgnThxQitXrmQOeKFrrdx68OBBPfHEE3ryySf1yy+/6OWXX9aaNWtUvnx5+fn5ae7cufxtKOGut2prrVq19Pbbb6tx48a6ePGidu7cqTVr1qhy5cr6y1/+otq1a7t5CzwDF+SFJKlBgwbatm0bIcoL5a7WWLFiRXXr1k2VKlVS9+7dJckRpqxWq3r37q3WrVvr6NGjysjI0O23366IiAg3V4+iYLPZdP78eT388MOSrgRnq9WqqKgonT17VpLyrN4YFRXlOD+mbt26bqsbRSs2Nla//vqrvvjiC02fPl02m01NmjRRVFSUkpKS1K5dOyUlJalNmzbavXu3DMNQixYtVLNmTXeXjmKQu3JrVFSUpLwrt44ZM0Zz585VjRo11LFjRy1YsEC7d+9WSEiI/P39uWSKF8hdtXX79u0aO3asli9frooVK2rAgAGqXLmyJk6cqE6dOunrr79W7dq11aJFC7Vo0cLdZXsc9khBkrhyvZdLT0/Pc47DokWL9Oijj2ro0KF64YUXVKlSJWVnZ+v48eO6+eab3Vgpisu+fftUp04dSVeClZ+fn0aNGqUjR45o7ty5jn4ZGRkKCgpSTk4O1wjxMidOnNCIESO0ePFitWrVSh9//LEqVqwoSZo/f76efvppzZs3T3/729/cXCmKW05Ojux2uwYMGKC0tDTNmzdP/v7+MgxDVqtVBw8eVM+ePVWjRg0tWrRIEu8TvEnuh2nSlfNj58+fr2bNmmnmzJl5rg/WsGFDNWvWTHPmzHFTpZ6PPVKQxLLG3u6PqzVarVZ169ZNhmGoR48eslgseu655zRp0iTHm+qgoCDmhJfJDVF2u91xkrhhGI5lryVp/Pjx8vf31+DBg+Xry58Hb1O1alWNHz9eERERiouLU8WKFR1vjh977DGNHTtW3377LUHKi+V+QJL71adPH/3lL3/Re++9p2effVYWiyXPyq3t27fXrl271KBBA/4meIH09HTZ7XYZhqGQkBBJV1ZtrVatmqKiovKs2urj48OqrYXAX0qgFMldiS13tUaLxaJevXrpyy+/1IEDB/S///2P1bm8nNVqzfPJcu6nkqNHj9Yrr7yiH374gRDlxapVq6YRI0Y4VmCzWCwyDENnz55V5cqVORfKi+3du1dLly5Vjx49VLVqVUl5V24NCgrSE088wcqtXurnn3/WkCFDdOrUKaWkpGjixInq3r27fHx8NHToUGVlZV131VbCdH78tQRKmT+eC9OtWze9//772r59u7Zt26bbb7/dzdXBFXL/IPr6+qpGjRqaNGmSJk6cqC1btqhx48buLg/FLPeT6FwWi0VvvfWWTp8+rZYtW7qpKhSn/fv3KzY2VufOndOZM2eUmJjoOM/pqaeeUnp6up588kkdOXJEDz74oGrWrKnFixfLZrMRpLzAzz//rNatW6t3795q1qyZtm7dqoSEBDVo0EBNmjSRdOWcuVzZ2dkaN26cvvvuO40fP14SRy5dDedIAaUUqzXi1Vdf1ahRoxQSEqI1a9aoWbNm7i4JLrZw4UJ98803Wrx4sdauXcseKS/Eyq2lG6u2Fi/2SAGlGKs1lm7x8fEaNWqUNmzY4Dh8A6VL/fr1NW/ePP33v/9VgwYN3F0OigErt5ZurNpavNgjBZRiHPOMP6/oiNInKysrz2E98D6s3Fq6sWpr8WGPFFCKEaJAiAIhyvuxcmvpxqqtxYdXCgAAoBRg5dbSjVVbi57V3QUAAADANSwWi2PZ+27duunuu+/WqVOntG3bNscKbvBeuWf0sGpr0SB2AgAAlCK5F94dPny4vvnmG23fvp3LX5QSuXuh/Pz8NGPGDIWEhGj9+vWszugk9kgBAACUQqzcWnrFx8dLkjZs2MClL24Aq/YBAACUQqzcWrqxauuNI0gBAAAAgEkc2gcAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAOCEOXPmyGKxaMuWLe4uBQDgBgQpAIDHyg0rV/v6/vvv3V0iAKCU8nV3AQAAXM9LL72kqKiofO21a9d2QzUAABCkAAAlQMeOHdWsWTN3lwEAgAOH9gEASrTDhw/LYrFo0qRJeuONN1SzZk2VKVNGbdq00c6dO/P1//rrr3X33XerbNmyCg0NVefOnfXLL7/k63fs2DH169dP1apVU0BAgKKiovTUU08pKysrT7/MzEwlJiaqcuXKKlu2rB544AGdOnUqT58tW7YoPj5elSpVUpkyZRQVFaXHH3+8aF8IAIBLsUcKAODxLly4oNOnT+dps1gsqlixouP23LlzlZaWpqefflqXL1/Wm2++qfbt2+unn35SeHi4JGnNmjXq2LGjbrnlFo0dO1aXLl3S1KlT1bJlS23btk2RkZGSpOPHjysmJkbnz5/Xk08+qbp16+rYsWNasmSJMjIy5O/v7xj3mWeeUfny5TVmzBgdPnxYSUlJGjRokBYtWiRJOnnypDp06KDKlStrxIgRCg0N1eHDh/Xpp58W86sGAChOBCkAgMeLi4vL1xYQEKDLly87bu/fv1/79u1TRESEJOnee+9V8+bNNWHCBE2ZMkWSNHz4cFWoUEEbN25UhQoVJEldunRR06ZNNWbMGH344YeSpJEjRyo5OVmbNm3Kc0jhSy+9JMMw8tRRsWJFrVq1ShaLRZJkt9v11ltv6cKFCypXrpw2bNigc+fOadWqVXme65VXXimKlwYA4CYc2gcA8HjTpk3T6tWr83z9+9//ztOnS5cujhAlSTExMWrevLmWL18uSTpx4oS2b9+uvn37OkKUJDVq1Ej33HOPo5/dbtfnn3+uTp06FXheVm5gyvXkk0/mabv77ruVk5OjI0eOSJJCQ0MlScuWLZPNZruBVwEA4EnYIwUA8HgxMTHXXWyiTp06+dpuvfVW/etf/5IkR7C57bbb8vWrV6+eVq5cqfT0dF28eFGpqalq2LBhoWq7+eab89wuX768JOncuXOSpDZt2uihhx7SuHHj9MYbb6ht27bq0qWLevTooYCAgEKNAQDwPOyRAgDgBvj4+BTYnnsIoMVi0ZIlS7Rx40YNGjRIx44d0+OPP67o6GhdvHjRlaUCAIoQQQoA4BX27duXr23v3r2OBSRq1qwpSdqzZ0++frt371alSpVUtmxZVa5cWSEhIQWu+HcjWrRooVdffVVbtmzR/PnztWvXLi1cuLBIxwAAuA5BCgDgFT7//HMdO3bMcXvz5s3atGmTOnbsKEmqWrWqmjRpog8//FDnz5939Nu5c6dWrVql++67T5JktVrVpUsXLV26VFu2bMk3zp8Xm7iec+fO5XtMkyZNJF1ZOh0AUDJxjhQAwOP9+9//1u7du/O133XXXbJar3wmWLt2bbVq1UpPPfWUMjMzlZSUpIoVK+r555939H/99dfVsWNHxcbGql+/fo7lz8uVK6exY8c6+r322mtatWqV2rRpoyeffFL16tXTiRMntHjxYq1fv96xgERhfPjhh3rnnXf0wAMPqFatWkpLS9OMGTMUEhLiCG8AgJKHIAUA8HijR48usH327Nlq27atJKl3796yWq1KSkrSyZMnFRMTo7fffltVq1Z19I+Li9OKFSs0ZswYjR49Wn5+fmrTpo0mTJigqKgoR7+IiAht2rRJo0aN0vz585WamqqIiAh17NhRQUFBpmpv06aNNm/erIULFyolJUXlypVTTEyM5s+fn2dMAEDJYjHMHqMAAIAHOXz4sKKiovT6669r2LBh7i4HAFBKcI4UAAAAAJhEkAIAAAAAkwhSAAAAAGAS50gBAAAAgEnskQIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJP+HxoLuX3goFgDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-970f26a18a19>:19: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_accuracy_by_hyperparameter, x=param, y='accuracy', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Mengambil DataFrame hasil eksperimen\n",
        "# Pastikan 'results_df' sudah ada setelah eksekusi kode sebelumnya\n",
        "results_df = pd.read_csv(\"mlp_classification_hidden layer 123.csv\")\n",
        "\n",
        "# Plot accuracy untuk setiap kombinasi hyperparameter\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Mengubah 'mse' menjadi 'accuracy' pada parameter y\n",
        "sns.barplot(data=results_df, x='activation', y='accuracy', hue='neurons', palette='pastel')\n",
        "\n",
        "# Menambahkan judul dan label\n",
        "plt.title('Accuracy untuk Berbagai Kombinasi Hyperparameter', fontsize=16) # Mengubah judul menjadi Accuracy\n",
        "plt.xlabel('Fungsi Aktivasi', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12) # Mengubah label y menjadi Accuracy\n",
        "plt.legend(title='Jumlah Neuron', title_fontsize='13', loc='upper right')\n",
        "\n",
        "# Menampilkan grafik\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "fIq8ZjcWB4SK",
        "outputId": "f11ca87a-94ee-455c-b186-86f625b67365"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}